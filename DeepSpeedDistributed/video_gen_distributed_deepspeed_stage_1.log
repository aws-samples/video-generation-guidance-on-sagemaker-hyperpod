[2024-07-03 07:47:53,941] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[2024-07-03 07:48:01,661] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'
  warnings.warn(
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
/fsx/ubuntu/miniconda3/envs/videogen/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  return register_model(fn_wrapper)
[2024-07-03 07:48:18,439] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,441] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,460] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,460] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,565] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,565] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,567] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-03 07:48:18,583] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
[2024-07-03 07:48:22,087] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,089] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,131] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,132] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,163] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,182] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,182] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,190] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-03 07:48:22,190] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 6
Local process index: 2
Device: cuda:2

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 4
Local process index: 0
Device: cuda:0

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.
07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.
07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 5
Local process index: 1
Device: cuda:1

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

07/03/2024 07:48:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 7
Local process index: 3
Device: cuda:3

Mixed precision type: fp16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}

{'time_embedding_act_fn', 'timestep_post_act', 'resnet_out_scale_factor', 'class_embeddings_concat', 'conv_out_kernel', 'encoder_hid_dim_type', 'dropout', 'cross_attention_norm', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'addition_time_embed_dim', 'time_embedding_type', 'conv_in_kernel', 'class_embed_type', 'time_embedding_dim', 'projection_class_embeddings_input_dim', 'transformer_layers_per_block', 'mid_block_type', 'num_attention_heads', 'resnet_time_scale_shift', 'upcast_attention', 'addition_embed_type', 'attention_type', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'resnet_skip_time_act', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.
Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: 
 ['conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']
{'attention_type', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'resnet_skip_time_act', 'time_embedding_dim', 'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'upcast_attention', 'encoder_hid_dim', 'timestep_post_act', 'class_embed_type', 'conv_in_kernel', 'transformer_layers_per_block', 'cross_attention_norm', 'reverse_transformer_layers_per_block', 'time_embedding_act_fn', 'dropout', 'num_attention_heads', 'addition_time_embed_dim', 'conv_out_kernel', 'addition_embed_type', 'mid_block_type', 'time_embedding_type', 'encoder_hid_dim_type', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.
07/03/2024 07:48:25 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
07/03/2024 07:48:25 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
{'motion_module_resolutions', 'motion_module_decoder_only', 'class_embed_type', 'upcast_attention', 'resnet_time_scale_shift', 'task_type', 'unet_use_cross_frame_attention', 'motion_module_mid_block', 'use_inflated_groupnorm', 'mode', 'motion_module_type', 'motion_module_kwargs'} was not found in config. Values will be initialized to default values.
07/03/2024 07:48:25 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
07/03/2024 07:48:25 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: 
 ['conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']
07/03/2024 07:48:31 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
07/03/2024 07:48:31 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
07/03/2024 07:48:31 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
07/03/2024 07:48:31 - INFO - src.models.unet_3d - loaded temporal unet's pretrained weights from pretrained_weights/sd-image-variations-diffusers/models--lambdalabs--sd-image-variations-diffusers/snapshots/42bc0ee1726b141d49f519a6ea02ccfbf073db2e/unet ...
{'mode', 'unet_use_cross_frame_attention', 'motion_module_decoder_only', 'upcast_attention', 'task_type', 'motion_module_type', 'motion_module_resolutions', 'class_embed_type', 'motion_module_mid_block', 'motion_module_kwargs', 'use_inflated_groupnorm', 'resnet_time_scale_shift'} was not found in config. Values will be initialized to default values.
07/03/2024 07:48:31 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:31 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:32 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:32 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:38 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:38 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:38 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:38 - INFO - src.models.unet_3d - Loaded 0.0M-parameter motion module
07/03/2024 07:48:38 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 5
07/03/2024 07:48:38 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 7
07/03/2024 07:48:38 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 6
07/03/2024 07:48:38 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 4
07/03/2024 07:48:45 - INFO - __main__ - Missing key for pose guider: 2
[2024-07-03 07:48:45,826] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.3, git-hash=unknown, git-branch=unknown
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 2
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 3
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
07/03/2024 07:48:45 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
libfabric:497485:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:50402:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:50403:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:50404:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:50405:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:497488:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:497487:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
libfabric:497486:1719992926::efa:domain:efa_domain_hmem_info_init_cuda():173<warn> Failed to register CUDA buffer with the EFA device, FI_HMEM transfers that require peer to peer support will fail.
[2024-07-03 07:48:47,044] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-07-03 07:48:47,047] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-07-03 07:48:47,047] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-07-03 07:48:47,262] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-07-03 07:48:47,262] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-07-03 07:48:47,262] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2024-07-03 07:48:47,262] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500,000,000
[2024-07-03 07:48:47,262] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500,000,000
[2024-07-03 07:48:47,262] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: False
[2024-07-03 07:48:47,262] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[2024-07-03 07:48:50,795] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2024-07-03 07:48:50,796] [INFO] [utils.py:782:see_memory_usage] MA 4.73 GB         Max_MA 5.12 GB         CA 5.62 GB         Max_CA 6 GB 
[2024-07-03 07:48:50,796] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 47.8 GB, percent = 12.8%
[2024-07-03 07:48:50,929] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2024-07-03 07:48:50,930] [INFO] [utils.py:782:see_memory_usage] MA 4.73 GB         Max_MA 5.52 GB         CA 6.41 GB         Max_CA 6 GB 
[2024-07-03 07:48:50,930] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 47.8 GB, percent = 12.8%
[2024-07-03 07:48:50,930] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
[2024-07-03 07:48:51,062] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2024-07-03 07:48:51,063] [INFO] [utils.py:782:see_memory_usage] MA 4.73 GB         Max_MA 4.73 GB         CA 6.41 GB         Max_CA 6 GB 
[2024-07-03 07:48:51,063] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 47.8 GB, percent = 12.8%
[2024-07-03 07:48:51,069] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2024-07-03 07:48:51,069] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-07-03 07:48:51,069] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-07-03 07:48:51,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]
[2024-07-03 07:48:51,071] [INFO] [config.py:1000:print] DeepSpeedEngine configuration:
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   amp_enabled .................. False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   amp_params ................... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   bfloat16_enabled ............. False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   bfloat16_immediate_grad_update  False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   checkpoint_parallel_write_pipeline  False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   checkpoint_tag_validation_enabled  True
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   checkpoint_tag_validation_fail  False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fee02156f80>
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   communication_data_type ...... None
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   curriculum_enabled_legacy .... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   curriculum_params_legacy ..... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   data_efficiency_enabled ...... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   dataloader_drop_last ......... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   disable_allgather ............ False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   dump_state ................... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   dynamic_loss_scale_args ...... None
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_enabled ........... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_gas_boundary_resolution  1
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_layer_num ......... 0
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_max_iter .......... 100
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_stability ......... 1e-06
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_tol ............... 0.01
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   eigenvalue_verbose ........... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   elasticity_enabled ........... False
[2024-07-03 07:48:51,072] [INFO] [config.py:1004:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   fp16_auto_cast ............... True
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   fp16_enabled ................. True
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   fp16_master_weights_and_gradients  False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   global_rank .................. 0
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   grad_accum_dtype ............. None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   gradient_accumulation_steps .. 1
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   gradient_clipping ............ 1.0
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   gradient_predivide_factor .... 1.0
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   graph_harvesting ............. False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   initial_dynamic_scale ........ 65536
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   load_universal_checkpoint .... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   loss_scale ................... 0
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   memory_breakdown ............. False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   mics_hierarchial_params_gather  False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   mics_shard_size .............. -1
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   optimizer_legacy_fusion ...... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   optimizer_name ............... None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   optimizer_params ............. None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   pld_enabled .................. False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   pld_params ................... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   prescale_gradients ........... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   scheduler_name ............... None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   scheduler_params ............. None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   seq_parallel_communication_data_type  torch.float32
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   sparse_attention ............. None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   sparse_gradients_enabled ..... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   steps_per_print .............. inf
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   timers_config ................ enabled=True synchronized=True
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   train_batch_size ............. 16
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   train_micro_batch_size_per_gpu  2
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   use_data_before_expert_parallel_  False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   use_node_local_storage ....... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   wall_clock_breakdown ......... False
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   weight_quantization_config ... None
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   world_size ................... 8
[2024-07-03 07:48:51,073] [INFO] [config.py:1004:print]   zero_allow_untested_optimizer  True
[2024-07-03 07:48:51,074] [INFO] [config.py:1004:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-07-03 07:48:51,074] [INFO] [config.py:1004:print]   zero_enabled ................. True
[2024-07-03 07:48:51,074] [INFO] [config.py:1004:print]   zero_force_ds_cpu_optimizer .. True
[2024-07-03 07:48:51,074] [INFO] [config.py:1004:print]   zero_optimization_stage ...... 2
[2024-07-03 07:48:51,074] [INFO] [config.py:990:print_user_config]   json = {
    "train_batch_size": 16, 
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "fp16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "bf16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
07/03/2024 07:48:51 - INFO - __main__ - ***** Running training *****
07/03/2024 07:48:51 - INFO - __main__ -   Num examples = 34
07/03/2024 07:48:51 - INFO - __main__ -   Num Epochs = 134
07/03/2024 07:48:51 - INFO - __main__ -   Instantaneous batch size per device = 2
07/03/2024 07:48:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
07/03/2024 07:48:51 - INFO - __main__ -   Gradient Accumulation steps = 1
07/03/2024 07:48:51 - INFO - __main__ -   Total optimization steps = 400
[2024-07-03 07:49:23,013] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
[2024-07-03 07:49:25,797] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
[2024-07-03 07:49:28,749] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
[2024-07-03 07:49:32,921] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
[2024-07-03 07:49:35,702] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
[2024-07-03 07:49:38,632] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
  0%|          | 0/400 [00:00<?, ?it/s]Steps:   0%|          | 0/400 [00:00<?, ?it/s]Steps:   0%|          | 1/400 [00:32<3:35:00, 32.33s/it]Steps:   0%|          | 1/400 [00:32<3:35:00, 32.33s/it, lr=1e-5, step_loss=1.19]Steps:   0%|          | 2/400 [00:35<1:39:10, 14.95s/it, lr=1e-5, step_loss=1.19]Steps:   0%|          | 2/400 [00:35<1:39:10, 14.95s/it, lr=1e-5, step_loss=2]   Steps:   1%|          | 3/400 [00:38<1:02:40,  9.47s/it, lr=1e-5, step_loss=2]Steps:   1%|          | 3/400 [00:38<1:02:40,  9.47s/it, lr=1e-5, step_loss=1.03]Steps:   1%|          | 4/400 [00:42<48:42,  7.38s/it, lr=1e-5, step_loss=1.03]  Steps:   1%|          | 4/400 [00:42<48:42,  7.38s/it, lr=1e-5, step_loss=1.57]Steps:   1%|▏         | 5/400 [00:45<37:40,  5.72s/it, lr=1e-5, step_loss=1.57]Steps:   1%|▏         | 5/400 [00:45<37:40,  5.72s/it, lr=1e-5, step_loss=1.38]Steps:   2%|▏         | 6/400 [00:47<31:20,  4.77s/it, lr=1e-5, step_loss=1.38]Steps:   2%|▏         | 6/400 [00:47<31:20,  4.77s/it, lr=1e-5  0%|          | 0/400 [00:00<?, ?it/s]Steps:   0%|          | 0/400 [00:00<?, ?it/s]Steps:   0%|          | 1/400 [00:31<3:30:30, 31.65s/it]Steps:   0%|          | 1/400 [00:31<3:30:30, 31.65s/it, lr=1e-5, step_loss=1.16]Steps:   0%|          | 2/400 [00:34<1:37:19, 14.67s/it, lr=1e-5, step_loss=1.16]Steps:   0%|          | 2/400 [00:34<1:37:19, 14.67s/it, lr=1e-5, step_loss=2.02]Steps:   1%|          | 3/400 [00:37<1:01:40,  9.32s/it, lr=1e-5, step_loss=2.02]Steps:   1%|          | 3/400 [00:37<1:01:40,  9.32s/it, lr=1e-5, step_loss=1.02]Steps:   1%|          | 4/400 [00:41<48:06,  7.29s/it, lr=1e-5, step_loss=1.02]  Steps:   1%|          | 4/400 [00:41<48:06,  7.29s/it, lr=1e-5, step_loss=1.49]Steps:   1%|▏         | 5/400 [00:44<37:16,  5.66s/it, lr=1e-5, step_loss=1.49]Steps:   1%|▏         | 5/400 [00:44<37:16,  5.66s/it, lr=1e-5, step_loss=1.46]Steps:   2%|▏         | 6/400 [00:47<31:05,  4.73s/it, lr=1e-5, step_loss=1.46]Steps:   2%|▏         | 6/400 [00:47<31:05,  4.73s/it, lr=1[2024-07-03 07:49:42,737] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
[2024-07-03 07:49:45,522] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
[2024-07-03 07:49:48,467] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
[2024-07-03 07:49:52,517] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
[2024-07-03 07:49:55,295] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
[2024-07-03 07:49:58,231] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
[2024-07-03 07:50:02,251] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
, step_loss=2.71]Steps:   2%|▏         | 7/400 [00:52<29:49,  4.55s/it, lr=1e-5, step_loss=2.71]Steps:   2%|▏         | 7/400 [00:52<29:49,  4.55s/it, lr=1e-5, step_loss=2.14]Steps:   2%|▏         | 8/400 [00:54<26:04,  3.99s/it, lr=1e-5, step_loss=2.14]Steps:   2%|▏         | 8/400 [00:54<26:04,  3.99s/it, lr=1e-5, step_loss=0.312]Steps:   2%|▏         | 9/400 [00:57<23:52,  3.66s/it, lr=1e-5, step_loss=0.312]Steps:   2%|▏         | 9/400 [00:57<23:52,  3.66s/it, lr=1e-5, step_loss=2.3]  Steps:   2%|▎         | 10/400 [01:01<24:35,  3.78s/it, lr=1e-5, step_loss=2.3]Steps:   2%|▎         | 10/400 [01:01<24:35,  3.78s/it, lr=1e-5, step_loss=1.04]Steps:   3%|▎         | 11/400 [01:04<22:32,  3.48s/it, lr=1e-5, step_loss=1.04]Steps:   3%|▎         | 11/400 [01:04<22:32,  3.48s/it, lr=1e-5, step_loss=1.84]Steps:   3%|▎         | 12/400 [01:07<21:24,  3.31s/it, lr=1e-5, step_loss=1.84]Steps:   3%|▎         | 12/400 [01:07<21:24,  3.31s/it, lr=1e-5, step_loss=2.35]Steps:   3%|e-5, step_loss=2.77]Steps:   2%|▏         | 7/400 [00:51<29:39,  4.53s/it, lr=1e-5, step_loss=2.77]Steps:   2%|▏         | 7/400 [00:51<29:39,  4.53s/it, lr=1e-5, step_loss=2.18]Steps:   2%|▏         | 8/400 [00:54<25:57,  3.97s/it, lr=1e-5, step_loss=2.18]Steps:   2%|▏         | 8/400 [00:54<25:57,  3.97s/it, lr=1e-5, step_loss=0.316]Steps:   2%|▏         | 9/400 [00:57<23:47,  3.65s/it, lr=1e-5, step_loss=0.316]Steps:   2%|▏         | 9/400 [00:57<23:47,  3.65s/it, lr=1e-5, step_loss=2.23] Steps:   2%|▎         | 10/400 [01:01<24:32,  3.77s/it, lr=1e-5, step_loss=2.23]Steps:   2%|▎         | 10/400 [01:01<24:32,  3.77s/it, lr=1e-5, step_loss=1.09]Steps:   3%|▎         | 11/400 [01:03<22:29,  3.47s/it, lr=1e-5, step_loss=1.09]Steps:   3%|▎         | 11/400 [01:03<22:29,  3.47s/it, lr=1e-5, step_loss=1.82]Steps:   3%|▎         | 12/400 [01:06<21:23,  3.31s/it, lr=1e-5, step_loss=1.82]Steps:   3%|▎         | 12/400 [01:06<21:23,  3.31s/it, lr=1e-5, step_loss=2.33]Steps:   3[2024-07-03 07:50:05,030] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
[2024-07-03 07:50:06,729] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
[2024-07-03 07:50:10,778] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
[2024-07-03 07:50:13,557] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
         | 13/400 [01:11<22:44,  3.53s/it, lr=1e-5, step_loss=2.35]Steps:   3%|▎         | 13/400 [01:11<22:44,  3.53s/it, lr=1e-5, step_loss=2.36]Steps:   4%|▎         | 14/400 [01:14<21:13,  3.30s/it, lr=1e-5, step_loss=2.36]Steps:   4%|▎         | 14/400 [01:14<21:13,  3.30s/it, lr=1e-5, step_loss=2.27]Steps:   4%|▍         | 15/400 [01:16<18:04,  2.82s/it, lr=1e-5, step_loss=2.27]Steps:   4%|▍         | 15/400 [01:16<18:04,  2.82s/it, lr=1e-5, step_loss=1.47]Steps:   4%|▍         | 16/400 [01:20<20:24,  3.19s/it, lr=1e-5, step_loss=1.47]Steps:   4%|▍         | 16/400 [01:20<20:24,  3.19s/it, lr=1e-5, step_loss=2.42]Steps:   4%|▍         | 17/400 [01:22<19:33,  3.07s/it, lr=1e-5, step_loss=2.42]Steps:   4%|▍         | 17/400 [01:22<19:33,  3.07s/it, lr=1e-5, step_loss=2.43]Steps:   4%|▍         | 18/400 [01:27<22:59,  3.61s/it, lr=1e-5, step_loss=2.43]Steps:   4%|▍         | 18/400 [01:27<22:59,  3.61s/it, lr=1e-5, step_loss=1.02]Steps:   5%|▍         | 19/400 [01:33<27%|▎         | 13/400 [01:10<22:43,  3.52s/it, lr=1e-5, step_loss=2.33]Steps:   3%|▎         | 13/400 [01:10<22:43,  3.52s/it, lr=1e-5, step_loss=2.3] Steps:   4%|▎         | 14/400 [01:13<21:13,  3.30s/it, lr=1e-5, step_loss=2.3]Steps:   4%|▎         | 14/400 [01:13<21:13,  3.30s/it, lr=1e-5, step_loss=2.29]Steps:   4%|▍         | 15/400 [01:15<18:04,  2.82s/it, lr=1e-5, step_loss=2.29]Steps:   4%|▍         | 15/400 [01:15<18:04,  2.82s/it, lr=1e-5, step_loss=1.51]Steps:   4%|▍         | 16/400 [01:19<20:23,  3.19s/it, lr=1e-5, step_loss=1.51]Steps:   4%|▍         | 16/400 [01:19<20:23,  3.19s/it, lr=1e-5, step_loss=2.37]Steps:   4%|▍         | 17/400 [01:22<19:33,  3.06s/it, lr=1e-5, step_loss=2.37]Steps:   4%|▍         | 17/400 [01:22<19:33,  3.06s/it, lr=1e-5, step_loss=2.43]Steps:   4%|▍         | 18/400 [01:27<22:59,  3.61s/it, lr=1e-5, step_loss=2.43]Steps:   4%|▍         | 18/400 [01:27<22:59,  3.61s/it, lr=1e-5, step_loss=1.03]Steps:   5%|▍         | 19/400 [01:33:47,  4.38s/it, lr=1e-5, step_loss=1.02]Steps:   5%|▍         | 19/400 [01:33<27:47,  4.38s/it, lr=1e-5, step_loss=0.9] Steps:   5%|▌         | 20/400 [01:38<28:17,  4.47s/it, lr=1e-5, step_loss=0.9]Steps:   5%|▌         | 20/400 [01:38<28:17,  4.47s/it, lr=1e-5, step_loss=1.81]Steps:   5%|▌         | 21/400 [01:43<28:57,  4.58s/it, lr=1e-5, step_loss=1.81]Steps:   5%|▌         | 21/400 [01:43<28:57,  4.58s/it, lr=1e-5, step_loss=1.97]Steps:   6%|▌         | 22/400 [01:49<31:22,  4.98s/it, lr=1e-5, step_loss=1.97]Steps:   6%|▌         | 22/400 [01:49<31:22,  4.98s/it, lr=1e-5, step_loss=0.849]Steps:   6%|▌         | 23/400 [01:54<30:43,  4.89s/it, lr=1e-5, step_loss=0.849]Steps:   6%|▌         | 23/400 [01:54<30:43,  4.89s/it, lr=1e-5, step_loss=1.22] Steps:   6%|▌         | 24/400 [01:58<30:36,  4.88s/it, lr=1e-5, step_loss=1.22]Steps:   6%|▌         | 24/400 [01:58<30:36,  4.88s/it, lr=1e-5, step_loss=1.78]Steps:   6%|▋         | 25/400 [02:04<32:35,  5.21s/it, lr=1e-5, s<27:47,  4.38s/it, lr=1e-5, step_loss=1.03]Steps:   5%|▍         | 19/400 [01:33<27:47,  4.38s/it, lr=1e-5, step_loss=0.888]Steps:   5%|▌         | 20/400 [01:37<28:17,  4.47s/it, lr=1e-5, step_loss=0.888]Steps:   5%|▌         | 20/400 [01:37<28:17,  4.47s/it, lr=1e-5, step_loss=1.77] Steps:   5%|▌         | 21/400 [01:42<28:57,  4.58s/it, lr=1e-5, step_loss=1.77]Steps:   5%|▌         | 21/400 [01:42<28:57,  4.58s/it, lr=1e-5, step_loss=1.95]Steps:   6%|▌         | 22/400 [01:48<31:22,  4.98s/it, lr=1e-5, step_loss=1.95]Steps:   6%|▌         | 22/400 [01:48<31:22,  4.98s/it, lr=1e-5, step_loss=0.863]Steps:   6%|▌         | 23/400 [01:53<30:43,  4.89s/it, lr=1e-5, step_loss=0.863]Steps:   6%|▌         | 23/400 [01:53<30:43,  4.89s/it, lr=1e-5, step_loss=1.2]  Steps:   6%|▌         | 24/400 [01:58<30:36,  4.88s/it, lr=1e-5, step_loss=1.2]Steps:   6%|▌         | 24/400 [01:58<30:36,  4.88s/it, lr=1e-5, step_loss=1.8]Steps:   6%|▋         | 25/400 [02:04<32:35,  5.22s/it, lr=1etep_loss=1.78]Steps:   6%|▋         | 25/400 [02:04<32:35,  5.21s/it, lr=1e-5, step_loss=0.398]Steps:   6%|▋         | 26/400 [02:09<31:28,  5.05s/it, lr=1e-5, step_loss=0.398]Steps:   6%|▋         | 26/400 [02:09<31:28,  5.05s/it, lr=1e-5, step_loss=0.642]Steps:   7%|▋         | 27/400 [02:13<28:41,  4.62s/it, lr=1e-5, step_loss=0.642]Steps:   7%|▋         | 27/400 [02:13<28:41,  4.62s/it, lr=1e-5, step_loss=0.683]Steps:   7%|▋         | 28/400 [02:19<31:05,  5.01s/it, lr=1e-5, step_loss=0.683]Steps:   7%|▋         | 28/400 [02:19<31:05,  5.01s/it, lr=1e-5, step_loss=0.913]Steps:   7%|▋         | 29/400 [02:23<30:21,  4.91s/it, lr=1e-5, step_loss=0.913]Steps:   7%|▋         | 29/400 [02:23<30:21,  4.91s/it, lr=1e-5, step_loss=1.95] Steps:   8%|▊         | 30/400 [02:28<30:07,  4.88s/it, lr=1e-5, step_loss=1.95]Steps:   8%|▊         | 30/400 [02:28<30:07,  4.88s/it, lr=1e-5, step_loss=1.77]Steps:   8%|▊         | 31/400 [02:34<32:20,  5.26s/it, lr=1e-5, step_loss=1.77]Step-5, step_loss=1.8]Steps:   6%|▋         | 25/400 [02:04<32:35,  5.22s/it, lr=1e-5, step_loss=0.395]Steps:   6%|▋         | 26/400 [02:08<31:28,  5.05s/it, lr=1e-5, step_loss=0.395]Steps:   6%|▋         | 26/400 [02:08<31:28,  5.05s/it, lr=1e-5, step_loss=0.664]Steps:   7%|▋         | 27/400 [02:12<28:41,  4.62s/it, lr=1e-5, step_loss=0.664]Steps:   7%|▋         | 27/400 [02:12<28:41,  4.62s/it, lr=1e-5, step_loss=0.66] Steps:   7%|▋         | 28/400 [02:18<31:05,  5.01s/it, lr=1e-5, step_loss=0.66]Steps:   7%|▋         | 28/400 [02:18<31:05,  5.01s/it, lr=1e-5, step_loss=0.944]Steps:   7%|▋         | 29/400 [02:23<30:21,  4.91s/it, lr=1e-5, step_loss=0.944]Steps:   7%|▋         | 29/400 [02:23<30:21,  4.91s/it, lr=1e-5, step_loss=1.87] Steps:   8%|▊         | 30/400 [02:27<30:07,  4.88s/it, lr=1e-5, step_loss=1.87]Steps:   8%|▊         | 30/400 [02:27<30:07,  4.88s/it, lr=1e-5, step_loss=1.83]Steps:   8%|▊         | 31/400 [02:34<32:20,  5.26s/it, lr=1e-5, step_loss=1.83]Ss:   8%|▊         | 31/400 [02:34<32:20,  5.26s/it, lr=1e-5, step_loss=1.11]Steps:   8%|▊         | 32/400 [02:39<31:10,  5.08s/it, lr=1e-5, step_loss=1.11]Steps:   8%|▊         | 32/400 [02:39<31:10,  5.08s/it, lr=1e-5, step_loss=0.449]Steps:   8%|▊         | 33/400 [02:44<30:37,  5.01s/it, lr=1e-5, step_loss=0.449]Steps:   8%|▊         | 33/400 [02:44<30:37,  5.01s/it, lr=1e-5, step_loss=0.855]Steps:   8%|▊         | 34/400 [02:50<32:13,  5.28s/it, lr=1e-5, step_loss=0.855]Steps:   8%|▊         | 34/400 [02:50<32:13,  5.28s/it, lr=1e-5, step_loss=0.939]Steps:   9%|▉         | 35/400 [02:54<31:01,  5.10s/it, lr=1e-5, step_loss=0.939]Steps:   9%|▉         | 35/400 [02:54<31:01,  5.10s/it, lr=1e-5, step_loss=0.928]Steps:   9%|▉         | 36/400 [02:59<30:25,  5.01s/it, lr=1e-5, step_loss=0.928]Steps:   9%|▉         | 36/400 [02:59<30:25,  5.01s/it, lr=1e-5, step_loss=0.168]Steps:   9%|▉         | 37/400 [03:05<32:05,  5.30s/it, lr=1e-5, step_loss=0.168]Steps:   9%|▉       teps:   8%|▊         | 31/400 [02:34<32:20,  5.26s/it, lr=1e-5, step_loss=1.18]Steps:   8%|▊         | 32/400 [02:38<31:10,  5.08s/it, lr=1e-5, step_loss=1.18]Steps:   8%|▊         | 32/400 [02:38<31:10,  5.08s/it, lr=1e-5, step_loss=0.434]Steps:   8%|▊         | 33/400 [02:43<30:37,  5.01s/it, lr=1e-5, step_loss=0.434]Steps:   8%|▊         | 33/400 [02:43<30:37,  5.01s/it, lr=1e-5, step_loss=0.862]Steps:   8%|▊         | 34/400 [02:49<32:13,  5.28s/it, lr=1e-5, step_loss=0.862]Steps:   8%|▊         | 34/400 [02:49<32:13,  5.28s/it, lr=1e-5, step_loss=0.943]Steps:   9%|▉         | 35/400 [02:54<31:01,  5.10s/it, lr=1e-5, step_loss=0.943]Steps:   9%|▉         | 35/400 [02:54<31:01,  5.10s/it, lr=1e-5, step_loss=0.897]Steps:   9%|▉         | 36/400 [02:58<30:25,  5.01s/it, lr=1e-5, step_loss=0.897]Steps:   9%|▉         | 36/400 [02:58<30:25,  5.01s/it, lr=1e-5, step_loss=0.166]Steps:   9%|▉         | 37/400 [03:04<32:05,  5.30s/it, lr=1e-5, step_loss=0.166]Steps:   9%|▉      | 37/400 [03:05<32:05,  5.30s/it, lr=1e-5, step_loss=0.937]Steps:  10%|▉         | 38/400 [03:10<30:52,  5.12s/it, lr=1e-5, step_loss=0.937]Steps:  10%|▉         | 38/400 [03:10<30:52,  5.12s/it, lr=1e-5, step_loss=1.22] Steps:  10%|▉         | 39/400 [03:15<30:18,  5.04s/it, lr=1e-5, step_loss=1.22]Steps:  10%|▉         | 39/400 [03:15<30:18,  5.04s/it, lr=1e-5, step_loss=0.572]Steps:  10%|█         | 40/400 [03:21<32:02,  5.34s/it, lr=1e-5, step_loss=0.572]Steps:  10%|█         | 40/400 [03:21<32:02,  5.34s/it, lr=1e-5, step_loss=0.907]Steps:  10%|█         | 41/400 [03:25<30:45,  5.14s/it, lr=1e-5, step_loss=0.907]Steps:  10%|█         | 41/400 [03:25<30:45,  5.14s/it, lr=1e-5, step_loss=0.88] Steps:  10%|█         | 42/400 [03:30<30:08,  5.05s/it, lr=1e-5, step_loss=0.88]Steps:  10%|█         | 42/400 [03:30<30:08,  5.05s/it, lr=1e-5, step_loss=1.29]Steps:  11%|█         | 43/400 [03:36<31:47,  5.34s/it, lr=1e-5, step_loss=1.29]Steps:  11%|█         | 43/400 [03:36<31     | 37/400 [03:04<32:05,  5.30s/it, lr=1e-5, step_loss=0.905]Steps:  10%|▉         | 38/400 [03:09<30:52,  5.12s/it, lr=1e-5, step_loss=0.905]Steps:  10%|▉         | 38/400 [03:09<30:52,  5.12s/it, lr=1e-5, step_loss=1.21] Steps:  10%|▉         | 39/400 [03:14<30:18,  5.04s/it, lr=1e-5, step_loss=1.21]Steps:  10%|▉         | 39/400 [03:14<30:18,  5.04s/it, lr=1e-5, step_loss=0.648]Steps:  10%|█         | 40/400 [03:20<32:02,  5.34s/it, lr=1e-5, step_loss=0.648]Steps:  10%|█         | 40/400 [03:20<32:02,  5.34s/it, lr=1e-5, step_loss=0.991]Steps:  10%|█         | 41/400 [03:25<30:45,  5.14s/it, lr=1e-5, step_loss=0.991]Steps:  10%|█         | 41/400 [03:25<30:45,  5.14s/it, lr=1e-5, step_loss=0.841]Steps:  10%|█         | 42/400 [03:30<30:08,  5.05s/it, lr=1e-5, step_loss=0.841]Steps:  10%|█         | 42/400 [03:30<30:08,  5.05s/it, lr=1e-5, step_loss=1.37] Steps:  11%|█         | 43/400 [03:36<31:47,  5.34s/it, lr=1e-5, step_loss=1.37]Steps:  11%|█         | 43/400 [03::47,  5.34s/it, lr=1e-5, step_loss=1.13]Steps:  11%|█         | 44/400 [03:40<28:18,  4.77s/it, lr=1e-5, step_loss=1.13]Steps:  11%|█         | 44/400 [03:40<28:18,  4.77s/it, lr=1e-5, step_loss=0.512]Steps:  11%|█▏        | 45/400 [03:45<28:20,  4.79s/it, lr=1e-5, step_loss=0.512]Steps:  11%|█▏        | 45/400 [03:45<28:20,  4.79s/it, lr=1e-5, step_loss=0.765]Steps:  12%|█▏        | 46/400 [03:51<30:31,  5.17s/it, lr=1e-5, step_loss=0.765]Steps:  12%|█▏        | 46/400 [03:51<30:31,  5.17s/it, lr=1e-5, step_loss=0.617]Steps:  12%|█▏        | 47/400 [03:54<27:21,  4.65s/it, lr=1e-5, step_loss=0.617]Steps:  12%|█▏        | 47/400 [03:54<27:21,  4.65s/it, lr=1e-5, step_loss=0.872]Steps:  12%|█▏        | 48/400 [03:59<27:36,  4.71s/it, lr=1e-5, step_loss=0.872]Steps:  12%|█▏        | 48/400 [03:59<27:36,  4.71s/it, lr=1e-5, step_loss=0.859]Steps:  12%|█▏        | 49/400 [04:05<29:42,  5.08s/it, lr=1e-5, step_loss=0.859]Steps:  12%|█▏        | 49/400 [04:05<36<31:47,  5.34s/it, lr=1e-5, step_loss=1.21]Steps:  11%|█         | 44/400 [03:39<28:18,  4.77s/it, lr=1e-5, step_loss=1.21]Steps:  11%|█         | 44/400 [03:39<28:18,  4.77s/it, lr=1e-5, step_loss=0.521]Steps:  11%|█▏        | 45/400 [03:44<28:20,  4.79s/it, lr=1e-5, step_loss=0.521]Steps:  11%|█▏        | 45/400 [03:44<28:20,  4.79s/it, lr=1e-5, step_loss=0.794]Steps:  12%|█▏        | 46/400 [03:50<30:31,  5.17s/it, lr=1e-5, step_loss=0.794]Steps:  12%|█▏        | 46/400 [03:50<30:31,  5.17s/it, lr=1e-5, step_loss=0.694]Steps:  12%|█▏        | 47/400 [03:53<27:21,  4.65s/it, lr=1e-5, step_loss=0.694]Steps:  12%|█▏        | 47/400 [03:53<27:21,  4.65s/it, lr=1e-5, step_loss=0.858]Steps:  12%|█▏        | 48/400 [03:58<27:36,  4.71s/it, lr=1e-5, step_loss=0.858]Steps:  12%|█▏        | 48/400 [03:58<27:36,  4.71s/it, lr=1e-5, step_loss=0.875]Steps:  12%|█▏        | 49/400 [04:04<29:42,  5.08s/it, lr=1e-5, step_loss=0.875]Steps:  12%|█▏        | 49/400 [029:42,  5.08s/it, lr=1e-5, step_loss=1.1]  Steps:  12%|█▎        | 50/400 [04:09<28:57,  4.96s/it, lr=1e-5, step_loss=1.1]Steps:  12%|█▎        | 50/400 [04:09<28:57,  4.96s/it, lr=1e-5, step_loss=1.25]Steps:  13%|█▎        | 51/400 [04:14<28:41,  4.93s/it, lr=1e-5, step_loss=1.25]Steps:  13%|█▎        | 51/400 [04:14<28:41,  4.93s/it, lr=1e-5, step_loss=0.371]Steps:  13%|█▎        | 52/400 [04:20<30:15,  5.22s/it, lr=1e-5, step_loss=0.371]Steps:  13%|█▎        | 52/400 [04:20<30:15,  5.22s/it, lr=1e-5, step_loss=1.21] Steps:  13%|█▎        | 53/400 [04:25<29:14,  5.06s/it, lr=1e-5, step_loss=1.21]Steps:  13%|█▎        | 53/400 [04:25<29:14,  5.06s/it, lr=1e-5, step_loss=0.579]Steps:  14%|█▎        | 54/400 [04:30<28:45,  4.99s/it, lr=1e-5, step_loss=0.579]Steps:  14%|█▎        | 54/400 [04:30<28:45,  4.99s/it, lr=1e-5, step_loss=0.996]Steps:  14%|█▍        | 55/400 [04:36<30:16,  5.26s/it, lr=1e-5, step_loss=0.996]Steps:  14%|█▍        | 55/400 [04:4:04<29:42,  5.08s/it, lr=1e-5, step_loss=1.1]  Steps:  12%|█▎        | 50/400 [04:09<28:57,  4.96s/it, lr=1e-5, step_loss=1.1]Steps:  12%|█▎        | 50/400 [04:09<28:57,  4.96s/it, lr=1e-5, step_loss=1.29]Steps:  13%|█▎        | 51/400 [04:14<28:41,  4.93s/it, lr=1e-5, step_loss=1.29]Steps:  13%|█▎        | 51/400 [04:14<28:41,  4.93s/it, lr=1e-5, step_loss=0.429]Steps:  13%|█▎        | 52/400 [04:20<30:15,  5.22s/it, lr=1e-5, step_loss=0.429]Steps:  13%|█▎        | 52/400 [04:20<30:15,  5.22s/it, lr=1e-5, step_loss=1.22] Steps:  13%|█▎        | 53/400 [04:24<29:14,  5.06s/it, lr=1e-5, step_loss=1.22]Steps:  13%|█▎        | 53/400 [04:24<29:14,  5.06s/it, lr=1e-5, step_loss=0.565]Steps:  14%|█▎        | 54/400 [04:29<28:45,  4.99s/it, lr=1e-5, step_loss=0.565]Steps:  14%|█▎        | 54/400 [04:29<28:45,  4.99s/it, lr=1e-5, step_loss=0.896]Steps:  14%|█▍        | 55/400 [04:35<30:16,  5.26s/it, lr=1e-5, step_loss=0.896]Steps:  14%|█▍        | 55/40036<30:16,  5.26s/it, lr=1e-5, step_loss=0.832]Steps:  14%|█▍        | 56/400 [04:40<29:08,  5.08s/it, lr=1e-5, step_loss=0.832]Steps:  14%|█▍        | 56/400 [04:40<29:08,  5.08s/it, lr=1e-5, step_loss=0.875]Steps:  14%|█▍        | 57/400 [04:45<28:36,  5.00s/it, lr=1e-5, step_loss=0.875]Steps:  14%|█▍        | 57/400 [04:45<28:36,  5.00s/it, lr=1e-5, step_loss=1.21] Steps:  14%|█▍        | 58/400 [04:51<30:37,  5.37s/it, lr=1e-5, step_loss=1.21]Steps:  14%|█▍        | 58/400 [04:51<30:37,  5.37s/it, lr=1e-5, step_loss=0.916]Steps:  15%|█▍        | 59/400 [04:56<29:19,  5.16s/it, lr=1e-5, step_loss=0.916]Steps:  15%|█▍        | 59/400 [04:56<29:19,  5.16s/it, lr=1e-5, step_loss=0.77] Steps:  15%|█▌        | 60/400 [05:01<28:40,  5.06s/it, lr=1e-5, step_loss=0.77]Steps:  15%|█▌        | 60/400 [05:01<28:40,  5.06s/it, lr=1e-5, step_loss=0.617]Steps:  15%|█▌        | 61/400 [05:07<30:21,  5.37s/it, lr=1e-5, step_loss=0.617]Steps:  15%|█▌        | 61/40 [04:35<30:16,  5.26s/it, lr=1e-5, step_loss=0.83] Steps:  14%|█▍        | 56/400 [04:40<29:08,  5.08s/it, lr=1e-5, step_loss=0.83]Steps:  14%|█▍        | 56/400 [04:40<29:08,  5.08s/it, lr=1e-5, step_loss=0.835]Steps:  14%|█▍        | 57/400 [04:44<28:36,  5.00s/it, lr=1e-5, step_loss=0.835]Steps:  14%|█▍        | 57/400 [04:44<28:36,  5.00s/it, lr=1e-5, step_loss=1.2]  Steps:  14%|█▍        | 58/400 [04:51<30:37,  5.37s/it, lr=1e-5, step_loss=1.2]Steps:  14%|█▍        | 58/400 [04:51<30:37,  5.37s/it, lr=1e-5, step_loss=0.958]Steps:  15%|█▍        | 59/400 [04:55<29:19,  5.16s/it, lr=1e-5, step_loss=0.958]Steps:  15%|█▍        | 59/400 [04:55<29:19,  5.16s/it, lr=1e-5, step_loss=0.737]Steps:  15%|█▌        | 60/400 [05:00<28:40,  5.06s/it, lr=1e-5, step_loss=0.737]Steps:  15%|█▌        | 60/400 [05:00<28:40,  5.06s/it, lr=1e-5, step_loss=0.667]Steps:  15%|█▌        | 61/400 [05:06<30:21,  5.37s/it, lr=1e-5, step_loss=0.667]Steps:  15%|█▌        | 61/400 [05:06<30:21,  5.37s/it, lr=1e-5, step_loss=0.623]Steps:  16%|█▌        | 62/400 [05:11<29:17,  5.20s/it, lr=1e-5, step_loss=0.623]Steps:  16%|█▌        | 62/400 [05:11<29:17,  5.20s/it, lr=1e-5, step_loss=0.85] Steps:  16%|█▌        | 63/400 [05:16<28:34,  5.09s/it, lr=1e-5, step_loss=0.85]Steps:  16%|█▌        | 63/400 [05:16<28:34,  5.09s/it, lr=1e-5, step_loss=0.384]07/03/2024 07:54:07 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 07:54:07 - INFO - __main__ - removing checkpoints: reference_unet-210.pth
07/03/2024 07:54:12 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 07:54:12 - INFO - __main__ - removing checkpoints: denoising_unet-210.pth
07/03/2024 07:54:19 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 07:54:19 - INFO - __main__ - removing checkpoints: pose_guider-210.pth
0 [05:07<30:21,  5.37s/it, lr=1e-5, step_loss=0.557]Steps:  16%|█▌        | 62/400 [05:12<29:17,  5.20s/it, lr=1e-5, step_loss=0.557]Steps:  16%|█▌        | 62/400 [05:12<29:17,  5.20s/it, lr=1e-5, step_loss=0.892]Steps:  16%|█▌        | 63/400 [05:17<28:34,  5.09s/it, lr=1e-5, step_loss=0.892]Steps:  16%|█▌        | 63/400 [05:17<28:34,  5.09s/it, lr=1e-5, step_loss=0.471]Steps:  16%|█▌        | 64/400 [05:53<1:21:43, 14.59s/it, lr=1e-5, step_loss=0.471]Steps:  16%|█▌        | 64/400 [05:53<1:21:43, 14.59s/it, lr=1e-5, step_loss=0.634]Steps:  16%|█▋        | 65/400 [05:58<1:04:58, 11.64s/it, lr=1e-5, step_loss=0.634]Steps:  16%|█▋        | 65/400 [05:58<1:04:58, 11.64s/it, lr=1e-5, step_loss=0.889]Steps:  16%|█▋        | 66/400 [06:03<53:26,  9.60s/it, lr=1e-5, step_loss=0.889]  Steps:  16%|█▋        | 66/400 [06:03<53:26,  9.60s/it, lr=1e-5, step_loss=0.504]Steps:  17%|█▋        | 67/400 [06:09<47:13,  8.51s/it, lr=1e-5, step_loss=0.504]Steps:  17%|█Steps:  16%|█▌        | 64/400 [05:53<1:21:43, 14.59s/it, lr=1e-5, step_loss=0.384]Steps:  16%|█▌        | 64/400 [05:53<1:21:43, 14.59s/it, lr=1e-5, step_loss=0.674]Steps:  16%|█▋        | 65/400 [05:57<1:04:58, 11.64s/it, lr=1e-5, step_loss=0.674]Steps:  16%|█▋        | 65/400 [05:57<1:04:58, 11.64s/it, lr=1e-5, step_loss=0.878]Steps:  16%|█▋        | 66/400 [06:02<53:26,  9.60s/it, lr=1e-5, step_loss=0.878]  Steps:  16%|█▋        | 66/400 [06:02<53:26,  9.60s/it, lr=1e-5, step_loss=0.584]Steps:  17%|█▋        | 67/400 [06:08<47:13,  8.51s/it, lr=1e-5, step_loss=0.584]Steps:  17%|█▋        | 67/400 [06:08<47:13,  8.51s/it, lr=1e-5, step_loss=0.821]Steps:  17%|█▋        | 68/400 [06:13<40:42,  7.36s/it, lr=1e-5, step_loss=0.821]Steps:  17%|█▋        | 68/400 [06:13<40:42,  7.36s/it, lr=1e-5, step_loss=0.705]Steps:  17%|█▋        | 69/400 [06:18<36:28,  6.61s/it, lr=1e-5, step_loss=0.705]Steps:  17%|█▋        | 69/400 [06:18<36:28,  6.61s/it, lr=1e-5▋        | 67/400 [06:09<47:13,  8.51s/it, lr=1e-5, step_loss=0.877]Steps:  17%|█▋        | 68/400 [06:14<40:42,  7.36s/it, lr=1e-5, step_loss=0.877]Steps:  17%|█▋        | 68/400 [06:14<40:42,  7.36s/it, lr=1e-5, step_loss=0.705]Steps:  17%|█▋        | 69/400 [06:18<36:28,  6.61s/it, lr=1e-5, step_loss=0.705]Steps:  17%|█▋        | 69/400 [06:18<36:28,  6.61s/it, lr=1e-5, step_loss=0.428]Steps:  18%|█▊        | 70/400 [06:24<35:11,  6.40s/it, lr=1e-5, step_loss=0.428]Steps:  18%|█▊        | 70/400 [06:24<35:11,  6.40s/it, lr=1e-5, step_loss=0.708]Steps:  18%|█▊        | 71/400 [06:29<32:14,  5.88s/it, lr=1e-5, step_loss=0.708]Steps:  18%|█▊        | 71/400 [06:29<32:14,  5.88s/it, lr=1e-5, step_loss=0.787]Steps:  18%|█▊        | 72/400 [06:34<30:28,  5.58s/it, lr=1e-5, step_loss=0.787]Steps:  18%|█▊        | 72/400 [06:34<30:28,  5.58s/it, lr=1e-5, step_loss=0.89] Steps:  18%|█▊        | 73/400 [06:40<31:15,  5.74s/it, lr=1e-5, step_loss=0.89]Steps:  , step_loss=0.452]Steps:  18%|█▊        | 70/400 [06:24<35:11,  6.40s/it, lr=1e-5, step_loss=0.452]Steps:  18%|█▊        | 70/400 [06:24<35:11,  6.40s/it, lr=1e-5, step_loss=0.863]Steps:  18%|█▊        | 71/400 [06:28<32:14,  5.88s/it, lr=1e-5, step_loss=0.863]Steps:  18%|█▊        | 71/400 [06:28<32:14,  5.88s/it, lr=1e-5, step_loss=0.718]Steps:  18%|█▊        | 72/400 [06:33<30:28,  5.58s/it, lr=1e-5, step_loss=0.718]Steps:  18%|█▊        | 72/400 [06:33<30:28,  5.58s/it, lr=1e-5, step_loss=0.908]Steps:  18%|█▊        | 73/400 [06:39<31:15,  5.74s/it, lr=1e-5, step_loss=0.908]Steps:  18%|█▊        | 73/400 [06:39<31:15,  5.74s/it, lr=1e-5, step_loss=0.57] Steps:  18%|█▊        | 74/400 [06:44<29:25,  5.41s/it, lr=1e-5, step_loss=0.57]Steps:  18%|█▊        | 74/400 [06:44<29:25,  5.41s/it, lr=1e-5, step_loss=0.382]Steps:  19%|█▉        | 75/400 [06:49<28:25,  5.25s/it, lr=1e-5, step_loss=0.382]Steps:  19%|█▉        | 75/400 [06:49<28:25,  5.25s/it, 18%|█▊        | 73/400 [06:40<31:15,  5.74s/it, lr=1e-5, step_loss=0.542]Steps:  18%|█▊        | 74/400 [06:45<29:25,  5.41s/it, lr=1e-5, step_loss=0.542]Steps:  18%|█▊        | 74/400 [06:45<29:25,  5.41s/it, lr=1e-5, step_loss=0.336]Steps:  19%|█▉        | 75/400 [06:50<28:25,  5.25s/it, lr=1e-5, step_loss=0.336]Steps:  19%|█▉        | 75/400 [06:50<28:25,  5.25s/it, lr=1e-5, step_loss=0.935]Steps:  19%|█▉        | 76/400 [06:55<29:25,  5.45s/it, lr=1e-5, step_loss=0.935]Steps:  19%|█▉        | 76/400 [06:55<29:25,  5.45s/it, lr=1e-5, step_loss=0.708]Steps:  19%|█▉        | 77/400 [07:00<28:05,  5.22s/it, lr=1e-5, step_loss=0.708]Steps:  19%|█▉        | 77/400 [07:00<28:05,  5.22s/it, lr=1e-5, step_loss=0.959]Steps:  20%|█▉        | 78/400 [07:05<27:24,  5.11s/it, lr=1e-5, step_loss=0.959]Steps:  20%|█▉        | 78/400 [07:05<27:24,  5.11s/it, lr=1e-5, step_loss=0.5]  Steps:  20%|█▉        | 79/400 [07:10<26:57,  5.04s/it, lr=1e-5, step_loss=0.5]Stlr=1e-5, step_loss=0.969]Steps:  19%|█▉        | 76/400 [06:55<29:25,  5.45s/it, lr=1e-5, step_loss=0.969]Steps:  19%|█▉        | 76/400 [06:55<29:25,  5.45s/it, lr=1e-5, step_loss=0.645]Steps:  19%|█▉        | 77/400 [06:59<28:05,  5.22s/it, lr=1e-5, step_loss=0.645]Steps:  19%|█▉        | 77/400 [06:59<28:05,  5.22s/it, lr=1e-5, step_loss=0.966]Steps:  20%|█▉        | 78/400 [07:04<27:24,  5.11s/it, lr=1e-5, step_loss=0.966]Steps:  20%|█▉        | 78/400 [07:04<27:24,  5.11s/it, lr=1e-5, step_loss=0.505]Steps:  20%|█▉        | 79/400 [07:09<26:57,  5.04s/it, lr=1e-5, step_loss=0.505]Steps:  20%|█▉        | 79/400 [07:09<26:57,  5.04s/it, lr=1e-5, step_loss=0.979]Steps:  20%|██        | 80/400 [07:14<26:17,  4.93s/it, lr=1e-5, step_loss=0.979]Steps:  20%|██        | 80/400 [07:14<26:17,  4.93s/it, lr=1e-5, step_loss=0.417]Steps:  20%|██        | 81/400 [07:19<26:03,  4.90s/it, lr=1e-5, step_loss=0.417]Steps:  20%|██        | 81/400 [07:19<26:03,  4.eps:  20%|█▉        | 79/400 [07:10<26:57,  5.04s/it, lr=1e-5, step_loss=0.938]Steps:  20%|██        | 80/400 [07:15<26:17,  4.93s/it, lr=1e-5, step_loss=0.938]Steps:  20%|██        | 80/400 [07:15<26:17,  4.93s/it, lr=1e-5, step_loss=0.432]Steps:  20%|██        | 81/400 [07:19<26:03,  4.90s/it, lr=1e-5, step_loss=0.432]Steps:  20%|██        | 81/400 [07:19<26:03,  4.90s/it, lr=1e-5, step_loss=0.506]Steps:  20%|██        | 82/400 [07:26<28:03,  5.29s/it, lr=1e-5, step_loss=0.506]Steps:  20%|██        | 82/400 [07:26<28:03,  5.29s/it, lr=1e-5, step_loss=0.505]Steps:  21%|██        | 83/400 [07:30<26:59,  5.11s/it, lr=1e-5, step_loss=0.505]Steps:  21%|██        | 83/400 [07:30<26:59,  5.11s/it, lr=1e-5, step_loss=0.394]Steps:  21%|██        | 84/400 [07:35<26:27,  5.02s/it, lr=1e-5, step_loss=0.394]Steps:  21%|██        | 84/400 [07:35<26:27,  5.02s/it, lr=1e-5, step_loss=0.448]Steps:  21%|██▏       | 85/400 [07:41<27:57,  5.32s/it, lr=1e-5, step_loss90s/it, lr=1e-5, step_loss=0.543]Steps:  20%|██        | 82/400 [07:25<28:03,  5.29s/it, lr=1e-5, step_loss=0.543]Steps:  20%|██        | 82/400 [07:25<28:03,  5.29s/it, lr=1e-5, step_loss=0.492]Steps:  21%|██        | 83/400 [07:30<26:59,  5.11s/it, lr=1e-5, step_loss=0.492]Steps:  21%|██        | 83/400 [07:30<26:59,  5.11s/it, lr=1e-5, step_loss=0.345]Steps:  21%|██        | 84/400 [07:34<26:27,  5.02s/it, lr=1e-5, step_loss=0.345]Steps:  21%|██        | 84/400 [07:34<26:27,  5.02s/it, lr=1e-5, step_loss=0.521]Steps:  21%|██▏       | 85/400 [07:40<27:57,  5.32s/it, lr=1e-5, step_loss=0.521]Steps:  21%|██▏       | 85/400 [07:40<27:57,  5.32s/it, lr=1e-5, step_loss=0.706]Steps:  22%|██▏       | 86/400 [07:45<26:52,  5.14s/it, lr=1e-5, step_loss=0.706]Steps:  22%|██▏       | 86/400 [07:45<26:52,  5.14s/it, lr=1e-5, step_loss=0.719]Steps:  22%|██▏       | 87/400 [07:50<26:19,  5.04s/it, lr=1e-5, step_loss=0.719]Steps:  22%|██▏       | 87/4=0.448]Steps:  21%|██▏       | 85/400 [07:41<27:57,  5.32s/it, lr=1e-5, step_loss=0.679]Steps:  22%|██▏       | 86/400 [07:46<26:52,  5.14s/it, lr=1e-5, step_loss=0.679]Steps:  22%|██▏       | 86/400 [07:46<26:52,  5.14s/it, lr=1e-5, step_loss=0.743]Steps:  22%|██▏       | 87/400 [07:51<26:19,  5.04s/it, lr=1e-5, step_loss=0.743]Steps:  22%|██▏       | 87/400 [07:51<26:19,  5.04s/it, lr=1e-5, step_loss=0.448]Steps:  22%|██▏       | 88/400 [07:57<27:52,  5.36s/it, lr=1e-5, step_loss=0.448]Steps:  22%|██▏       | 88/400 [07:57<27:52,  5.36s/it, lr=1e-5, step_loss=0.416]Steps:  22%|██▏       | 89/400 [08:01<26:43,  5.16s/it, lr=1e-5, step_loss=0.416]Steps:  22%|██▏       | 89/400 [08:01<26:43,  5.16s/it, lr=1e-5, step_loss=0.393]Steps:  22%|██▎       | 90/400 [08:05<24:14,  4.69s/it, lr=1e-5, step_loss=0.393]Steps:  22%|██▎       | 90/400 [08:05<24:14,  4.69s/it, lr=1e-5, step_loss=1.03] Steps:  23%|██▎       | 91/400 [08:11<26:000 [07:50<26:19,  5.04s/it, lr=1e-5, step_loss=0.388]Steps:  22%|██▏       | 88/400 [07:56<27:52,  5.36s/it, lr=1e-5, step_loss=0.388]Steps:  22%|██▏       | 88/400 [07:56<27:52,  5.36s/it, lr=1e-5, step_loss=0.377]Steps:  22%|██▏       | 89/400 [08:01<26:43,  5.16s/it, lr=1e-5, step_loss=0.377]Steps:  22%|██▏       | 89/400 [08:01<26:43,  5.16s/it, lr=1e-5, step_loss=0.399]Steps:  22%|██▎       | 90/400 [08:04<24:14,  4.69s/it, lr=1e-5, step_loss=0.399]Steps:  22%|██▎       | 90/400 [08:04<24:14,  4.69s/it, lr=1e-5, step_loss=1.03] Steps:  23%|██▎       | 91/400 [08:10<26:08,  5.08s/it, lr=1e-5, step_loss=1.03]Steps:  23%|██▎       | 91/400 [08:10<26:08,  5.08s/it, lr=1e-5, step_loss=0.146]Steps:  23%|██▎       | 92/400 [08:15<25:26,  4.95s/it, lr=1e-5, step_loss=0.146]Steps:  23%|██▎       | 92/400 [08:15<25:26,  4.95s/it, lr=1e-5, step_loss=0.483]Steps:  23%|██▎       | 93/400 [08:20<25:12,  4.93s/it, lr=1e-5, step_loss=0.483]Ste8,  5.08s/it, lr=1e-5, step_loss=1.03]Steps:  23%|██▎       | 91/400 [08:11<26:08,  5.08s/it, lr=1e-5, step_loss=0.188]Steps:  23%|██▎       | 92/400 [08:16<25:26,  4.96s/it, lr=1e-5, step_loss=0.188]Steps:  23%|██▎       | 92/400 [08:16<25:26,  4.96s/it, lr=1e-5, step_loss=0.464]Steps:  23%|██▎       | 93/400 [08:21<25:12,  4.93s/it, lr=1e-5, step_loss=0.464]Steps:  23%|██▎       | 93/400 [08:21<25:12,  4.93s/it, lr=1e-5, step_loss=0.488]Steps:  24%|██▎       | 94/400 [08:26<26:38,  5.22s/it, lr=1e-5, step_loss=0.488]Steps:  24%|██▎       | 94/400 [08:26<26:38,  5.22s/it, lr=1e-5, step_loss=0.437]Steps:  24%|██▍       | 95/400 [08:31<25:43,  5.06s/it, lr=1e-5, step_loss=0.437]Steps:  24%|██▍       | 95/400 [08:31<25:43,  5.06s/it, lr=1e-5, step_loss=0.332]Steps:  24%|██▍       | 96/400 [08:35<23:26,  4.63s/it, lr=1e-5, step_loss=0.332]Steps:  24%|██▍       | 96/400 [08:35<23:26,  4.63s/it, lr=1e-5, step_loss=0.293]Steps:  24%|█ps:  23%|██▎       | 93/400 [08:20<25:12,  4.93s/it, lr=1e-5, step_loss=0.505]Steps:  24%|██▎       | 94/400 [08:26<26:38,  5.22s/it, lr=1e-5, step_loss=0.505]Steps:  24%|██▎       | 94/400 [08:26<26:38,  5.22s/it, lr=1e-5, step_loss=0.447]Steps:  24%|██▍       | 95/400 [08:30<25:43,  5.06s/it, lr=1e-5, step_loss=0.447]Steps:  24%|██▍       | 95/400 [08:30<25:43,  5.06s/it, lr=1e-5, step_loss=0.321]Steps:  24%|██▍       | 96/400 [08:34<23:26,  4.63s/it, lr=1e-5, step_loss=0.321]Steps:  24%|██▍       | 96/400 [08:34<23:26,  4.63s/it, lr=1e-5, step_loss=0.253]Steps:  24%|██▍       | 97/400 [08:40<25:30,  5.05s/it, lr=1e-5, step_loss=0.253]Steps:  24%|██▍       | 97/400 [08:40<25:30,  5.05s/it, lr=1e-5, step_loss=0.785]Steps:  24%|██▍       | 98/400 [08:45<24:51,  4.94s/it, lr=1e-5, step_loss=0.785]Steps:  24%|██▍       | 98/400 [08:45<24:51,  4.94s/it, lr=1e-5, step_loss=0.198]Steps:  25%|██▍       | 99/400 [08:50<24:36,  4.90s/i▍       | 97/400 [08:41<25:30,  5.05s/it, lr=1e-5, step_loss=0.293]Steps:  24%|██▍       | 97/400 [08:41<25:30,  5.05s/it, lr=1e-5, step_loss=0.718]Steps:  24%|██▍       | 98/400 [08:45<24:51,  4.94s/it, lr=1e-5, step_loss=0.718]Steps:  24%|██▍       | 98/400 [08:45<24:51,  4.94s/it, lr=1e-5, step_loss=0.183]Steps:  25%|██▍       | 99/400 [08:50<24:36,  4.90s/it, lr=1e-5, step_loss=0.183]Steps:  25%|██▍       | 99/400 [08:50<24:36,  4.90s/it, lr=1e-5, step_loss=0.398]Steps:  25%|██▌       | 100/400 [08:56<26:25,  5.29s/it, lr=1e-5, step_loss=0.398]Steps:  25%|██▌       | 100/400 [08:56<26:25,  5.29s/it, lr=1e-5, step_loss=0.399]Steps:  25%|██▌       | 101/400 [09:01<25:28,  5.11s/it, lr=1e-5, step_loss=0.399]Steps:  25%|██▌       | 101/400 [09:01<25:28,  5.11s/it, lr=1e-5, step_loss=0.386]Steps:  26%|██▌       | 102/400 [09:06<24:58,  5.03s/it, lr=1e-5, step_loss=0.386]Steps:  26%|██▌       | 102/400 [09:06<24:58,  5.03s/it, lr=1et, lr=1e-5, step_loss=0.198]Steps:  25%|██▍       | 99/400 [08:50<24:36,  4.90s/it, lr=1e-5, step_loss=0.384]Steps:  25%|██▌       | 100/400 [08:56<26:26,  5.29s/it, lr=1e-5, step_loss=0.384]Steps:  25%|██▌       | 100/400 [08:56<26:26,  5.29s/it, lr=1e-5, step_loss=0.381]Steps:  25%|██▌       | 101/400 [09:00<25:28,  5.11s/it, lr=1e-5, step_loss=0.381]Steps:  25%|██▌       | 101/400 [09:00<25:28,  5.11s/it, lr=1e-5, step_loss=0.39] Steps:  26%|██▌       | 102/400 [09:05<24:58,  5.03s/it, lr=1e-5, step_loss=0.39]Steps:  26%|██▌       | 102/400 [09:05<24:58,  5.03s/it, lr=1e-5, step_loss=0.191]Steps:  26%|██▌       | 103/400 [09:11<26:36,  5.38s/it, lr=1e-5, step_loss=0.191]Steps:  26%|██▌       | 103/400 [09:12<26:36,  5.38s/it, lr=1e-5, step_loss=0.687]Steps:  26%|██▌       | 104/400 [09:16<25:27,  5.16s/it, lr=1e-5, step_loss=0.687]Steps:  26%|██▌       | 104/400 [09:16<25:27,  5.16s/it, lr=1e-5, step_loss=0.638]Steps:  26%|██-5, step_loss=0.173]Steps:  26%|██▌       | 103/400 [09:12<26:36,  5.38s/it, lr=1e-5, step_loss=0.173]Steps:  26%|██▌       | 103/400 [09:12<26:36,  5.38s/it, lr=1e-5, step_loss=0.685]Steps:  26%|██▌       | 104/400 [09:17<25:27,  5.16s/it, lr=1e-5, step_loss=0.685]Steps:  26%|██▌       | 104/400 [09:17<25:27,  5.16s/it, lr=1e-5, step_loss=0.635]Steps:  26%|██▋       | 105/400 [09:22<24:53,  5.06s/it, lr=1e-5, step_loss=0.635]Steps:  26%|██▋       | 105/400 [09:22<24:53,  5.06s/it, lr=1e-5, step_loss=0.351]Steps:  26%|██▋       | 106/400 [09:28<26:36,  5.43s/it, lr=1e-5, step_loss=0.351]Steps:  26%|██▋       | 106/400 [09:28<26:36,  5.43s/it, lr=1e-5, step_loss=0.375]Steps:  27%|██▋       | 107/400 [09:33<25:26,  5.21s/it, lr=1e-5, step_loss=0.375]Steps:  27%|██▋       | 107/400 [09:33<25:26,  5.21s/it, lr=1e-5, step_loss=0.358]Steps:  27%|██▋       | 108/400 [09:37<24:48,  5.10s/it, lr=1e-5, step_loss=0.358]Steps:  27%|██▋   ▋       | 105/400 [09:21<24:53,  5.06s/it, lr=1e-5, step_loss=0.638]Steps:  26%|██▋       | 105/400 [09:21<24:53,  5.06s/it, lr=1e-5, step_loss=0.35] Steps:  26%|██▋       | 106/400 [09:27<26:36,  5.43s/it, lr=1e-5, step_loss=0.35]Steps:  26%|██▋       | 106/400 [09:27<26:36,  5.43s/it, lr=1e-5, step_loss=0.392]Steps:  27%|██▋       | 107/400 [09:32<25:26,  5.21s/it, lr=1e-5, step_loss=0.392]Steps:  27%|██▋       | 107/400 [09:32<25:26,  5.21s/it, lr=1e-5, step_loss=0.387]Steps:  27%|██▋       | 108/400 [09:37<24:48,  5.10s/it, lr=1e-5, step_loss=0.387]Steps:  27%|██▋       | 108/400 [09:37<24:48,  5.10s/it, lr=1e-5, step_loss=0.177]Steps:  27%|██▋       | 109/400 [09:43<26:38,  5.49s/it, lr=1e-5, step_loss=0.177]Steps:  27%|██▋       | 109/400 [09:43<26:38,  5.49s/it, lr=1e-5, step_loss=0.228]Steps:  28%|██▊       | 110/400 [09:48<25:21,  5.25s/it, lr=1e-5, step_loss=0.228]Steps:  28%|██▊       | 110/400 [09:48<25:21,  5.25s/it, l    | 108/400 [09:37<24:48,  5.10s/it, lr=1e-5, step_loss=0.186]Steps:  27%|██▋       | 109/400 [09:44<26:38,  5.49s/it, lr=1e-5, step_loss=0.186]Steps:  27%|██▋       | 109/400 [09:44<26:38,  5.49s/it, lr=1e-5, step_loss=0.22] Steps:  28%|██▊       | 110/400 [09:49<25:21,  5.25s/it, lr=1e-5, step_loss=0.22]Steps:  28%|██▊       | 110/400 [09:49<25:21,  5.25s/it, lr=1e-5, step_loss=0.29]Steps:  28%|██▊       | 111/400 [09:53<24:41,  5.13s/it, lr=1e-5, step_loss=0.29]Steps:  28%|██▊       | 111/400 [09:53<24:41,  5.13s/it, lr=1e-5, step_loss=0.147]Steps:  28%|██▊       | 112/400 [09:59<25:35,  5.33s/it, lr=1e-5, step_loss=0.147]Steps:  28%|██▊       | 112/400 [09:59<25:35,  5.33s/it, lr=1e-5, step_loss=0.0891]Steps:  28%|██▊       | 113/400 [10:04<24:32,  5.13s/it, lr=1e-5, step_loss=0.0891]Steps:  28%|██▊       | 113/400 [10:04<24:32,  5.13s/it, lr=1e-5, step_loss=0.424] Steps:  28%|██▊       | 114/400 [10:09<24:03,  5.05s/it, lr=1e-r=1e-5, step_loss=0.317]Steps:  28%|██▊       | 111/400 [09:53<24:41,  5.13s/it, lr=1e-5, step_loss=0.317]Steps:  28%|██▊       | 111/400 [09:53<24:41,  5.13s/it, lr=1e-5, step_loss=0.121]Steps:  28%|██▊       | 112/400 [09:59<25:35,  5.33s/it, lr=1e-5, step_loss=0.121]Steps:  28%|██▊       | 112/400 [09:59<25:35,  5.33s/it, lr=1e-5, step_loss=0.124]Steps:  28%|██▊       | 113/400 [10:03<24:32,  5.13s/it, lr=1e-5, step_loss=0.124]Steps:  28%|██▊       | 113/400 [10:03<24:32,  5.13s/it, lr=1e-5, step_loss=0.399]Steps:  28%|██▊       | 114/400 [10:08<24:03,  5.05s/it, lr=1e-5, step_loss=0.399]Steps:  28%|██▊       | 114/400 [10:08<24:03,  5.05s/it, lr=1e-5, step_loss=0.565]Steps:  29%|██▉       | 115/400 [10:14<25:26,  5.36s/it, lr=1e-5, step_loss=0.565]Steps:  29%|██▉       | 115/400 [10:14<25:26,  5.36s/it, lr=1e-5, step_loss=0.66] Steps:  29%|██▉       | 116/400 [10:19<24:35,  5.20s/it, lr=1e-5, step_loss=0.66]Steps:  29%|██▉5, step_loss=0.424]Steps:  28%|██▊       | 114/400 [10:09<24:03,  5.05s/it, lr=1e-5, step_loss=0.581]Steps:  29%|██▉       | 115/400 [10:15<25:26,  5.36s/it, lr=1e-5, step_loss=0.581]Steps:  29%|██▉       | 115/400 [10:15<25:26,  5.36s/it, lr=1e-5, step_loss=0.577]Steps:  29%|██▉       | 116/400 [10:20<24:35,  5.20s/it, lr=1e-5, step_loss=0.577]Steps:  29%|██▉       | 116/400 [10:20<24:35,  5.20s/it, lr=1e-5, step_loss=0.622]Steps:  29%|██▉       | 117/400 [10:24<24:01,  5.09s/it, lr=1e-5, step_loss=0.622]Steps:  29%|██▉       | 117/400 [10:24<24:01,  5.09s/it, lr=1e-5, step_loss=0.286]Steps:  30%|██▉       | 118/400 [10:30<25:11,  5.36s/it, lr=1e-5, step_loss=0.286]Steps:  30%|██▉       | 118/400 [10:30<25:11,  5.36s/it, lr=1e-5, step_loss=0.489]Steps:  30%|██▉       | 119/400 [10:34<22:24,  4.79s/it, lr=1e-5, step_loss=0.489]Steps:  30%|██▉       | 119/400 [10:34<22:24,  4.79s/it, lr=1e-5, step_loss=0.532]Steps:  30%|███           | 116/400 [10:19<24:35,  5.20s/it, lr=1e-5, step_loss=0.645]Steps:  29%|██▉       | 117/400 [10:24<24:01,  5.09s/it, lr=1e-5, step_loss=0.645]Steps:  29%|██▉       | 117/400 [10:24<24:01,  5.09s/it, lr=1e-5, step_loss=0.248]Steps:  30%|██▉       | 118/400 [10:30<25:11,  5.36s/it, lr=1e-5, step_loss=0.248]Steps:  30%|██▉       | 118/400 [10:30<25:11,  5.36s/it, lr=1e-5, step_loss=0.475]Steps:  30%|██▉       | 119/400 [10:33<22:24,  4.79s/it, lr=1e-5, step_loss=0.475]Steps:  30%|██▉       | 119/400 [10:33<22:24,  4.79s/it, lr=1e-5, step_loss=0.542]Steps:  30%|███       | 120/400 [10:38<22:25,  4.80s/it, lr=1e-5, step_loss=0.542]Steps:  30%|███       | 120/400 [10:38<22:25,  4.80s/it, lr=1e-5, step_loss=0.106]Steps:  30%|███       | 121/400 [10:44<24:06,  5.19s/it, lr=1e-5, step_loss=0.106]Steps:  30%|███       | 121/400 [10:44<24:06,  5.19s/it, lr=1e-5, step_loss=0.212]Steps:  30%|███       | 122/400 [10:49<23:18,  5.03s/it, lr=   | 120/400 [10:39<22:25,  4.80s/it, lr=1e-5, step_loss=0.532]Steps:  30%|███       | 120/400 [10:39<22:25,  4.80s/it, lr=1e-5, step_loss=0.0846]Steps:  30%|███       | 121/400 [10:45<24:06,  5.19s/it, lr=1e-5, step_loss=0.0846]Steps:  30%|███       | 121/400 [10:45<24:06,  5.19s/it, lr=1e-5, step_loss=0.231] Steps:  30%|███       | 122/400 [10:50<23:18,  5.03s/it, lr=1e-5, step_loss=0.231]Steps:  30%|███       | 122/400 [10:50<23:18,  5.03s/it, lr=1e-5, step_loss=0.187]Steps:  31%|███       | 123/400 [10:54<22:57,  4.97s/it, lr=1e-5, step_loss=0.187]Steps:  31%|███       | 123/400 [10:54<22:57,  4.97s/it, lr=1e-5, step_loss=0.381]Steps:  31%|███       | 124/400 [11:00<24:02,  5.23s/it, lr=1e-5, step_loss=0.381]Steps:  31%|███       | 124/400 [11:00<24:02,  5.23s/it, lr=1e-5, step_loss=0.364]Steps:  31%|███▏      | 125/400 [11:05<23:12,  5.06s/it, lr=1e-5, step_loss=0.364]Steps:  31%|███▏      | 125/400 [11:05<23:12,  5.06s/it, 1e-5, step_loss=0.212]Steps:  30%|███       | 122/400 [10:49<23:18,  5.03s/it, lr=1e-5, step_loss=0.241]Steps:  31%|███       | 123/400 [10:54<22:57,  4.97s/it, lr=1e-5, step_loss=0.241]Steps:  31%|███       | 123/400 [10:54<22:57,  4.97s/it, lr=1e-5, step_loss=0.364]Steps:  31%|███       | 124/400 [10:59<24:02,  5.23s/it, lr=1e-5, step_loss=0.364]Steps:  31%|███       | 124/400 [10:59<24:02,  5.23s/it, lr=1e-5, step_loss=0.344]Steps:  31%|███▏      | 125/400 [11:04<23:12,  5.06s/it, lr=1e-5, step_loss=0.344]Steps:  31%|███▏      | 125/400 [11:04<23:12,  5.06s/it, lr=1e-5, step_loss=0.379]Steps:  32%|███▏      | 126/400 [11:08<21:06,  4.62s/it, lr=1e-5, step_loss=0.379]Steps:  32%|███▏      | 126/400 [11:08<21:06,  4.62s/it, lr=1e-5, step_loss=0.657]07/03/2024 07:59:59 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 07:59:59 - INFO - __main__ - removing checkpoints: reference_unet-63.pth
07/03/2024 08:00:04 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:00:04 - INFO - __main__ - removing checkpoints: denoising_unet-63.pth
07/03/2024 08:00:11 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:00:11 - INFO - __main__ - removing checkpoints: pose_guider-63.pth
lr=1e-5, step_loss=0.353]Steps:  32%|███▏      | 126/400 [11:08<21:06,  4.62s/it, lr=1e-5, step_loss=0.353]Steps:  32%|███▏      | 126/400 [11:08<21:06,  4.62s/it, lr=1e-5, step_loss=0.628]Steps:  32%|███▏      | 127/400 [11:51<1:12:20, 15.90s/it, lr=1e-5, step_loss=0.628]Steps:  32%|███▏      | 127/400 [11:51<1:12:20, 15.90s/it, lr=1e-5, step_loss=0.27] Steps:  32%|███▏      | 128/400 [11:55<56:54, 12.55s/it, lr=1e-5, step_loss=0.27]  Steps:  32%|███▏      | 128/400 [11:55<56:54, 12.55s/it, lr=1e-5, step_loss=0.326]Steps:  32%|███▏      | 129/400 [12:00<46:14, 10.24s/it, lr=1e-5, step_loss=0.326]Steps:  32%|███▏      | 129/400 [12:00<46:14, 10.24s/it, lr=1e-5, step_loss=0.294]Steps:  32%|███▎      | 130/400 [12:06<40:26,  8.99s/it, lr=1e-5, step_loss=0.294]Steps:  32%|███▎      | 130/400 [12:06<40:26,  8.99s/it, lr=1e-5, step_loss=0.404]Steps:  33%|███▎      | 131/400 [12:11<34:30,  7.70s/it, lr=1e-5, step_lossSteps:  32%|███▏      | 127/400 [11:50<1:12:20, 15.90s/it, lr=1e-5, step_loss=0.657]Steps:  32%|███▏      | 127/400 [11:50<1:12:20, 15.90s/it, lr=1e-5, step_loss=0.258]Steps:  32%|███▏      | 128/400 [11:55<56:54, 12.55s/it, lr=1e-5, step_loss=0.258]  Steps:  32%|███▏      | 128/400 [11:55<56:54, 12.55s/it, lr=1e-5, step_loss=0.325]Steps:  32%|███▏      | 129/400 [12:00<46:14, 10.24s/it, lr=1e-5, step_loss=0.325]Steps:  32%|███▏      | 129/400 [12:00<46:14, 10.24s/it, lr=1e-5, step_loss=0.323]Steps:  32%|███▎      | 130/400 [12:06<40:26,  8.99s/it, lr=1e-5, step_loss=0.323]Steps:  32%|███▎      | 130/400 [12:06<40:26,  8.99s/it, lr=1e-5, step_loss=0.427]Steps:  33%|███▎      | 131/400 [12:10<34:30,  7.70s/it, lr=1e-5, step_loss=0.427]Steps:  33%|███▎      | 131/400 [12:10<34:30,  7.70s/it, lr=1e-5, step_loss=0.11] Steps:  33%|███▎      | 132/400 [12:15<30:31,  6.84s/it, lr=1e-5, step_loss=0.11]Steps:  33%|█=0.404]Steps:  33%|███▎      | 131/400 [12:11<34:30,  7.70s/it, lr=1e-5, step_loss=0.147]Steps:  33%|███▎      | 132/400 [12:16<30:31,  6.84s/it, lr=1e-5, step_loss=0.147]Steps:  33%|███▎      | 132/400 [12:16<30:31,  6.84s/it, lr=1e-5, step_loss=0.302]Steps:  33%|███▎      | 133/400 [12:22<29:19,  6.59s/it, lr=1e-5, step_loss=0.302]Steps:  33%|███▎      | 133/400 [12:22<29:19,  6.59s/it, lr=1e-5, step_loss=0.106]Steps:  34%|███▎      | 134/400 [12:27<26:40,  6.02s/it, lr=1e-5, step_loss=0.106]Steps:  34%|███▎      | 134/400 [12:27<26:40,  6.02s/it, lr=1e-5, step_loss=0.33] Steps:  34%|███▍      | 135/400 [12:31<25:01,  5.67s/it, lr=1e-5, step_loss=0.33]Steps:  34%|███▍      | 135/400 [12:31<25:01,  5.67s/it, lr=1e-5, step_loss=0.183]Steps:  34%|███▍      | 136/400 [12:37<25:26,  5.78s/it, lr=1e-5, step_loss=0.183]Steps:  34%|███▍      | 136/400 [12:37<25:26,  5.78s/it, lr=1e-5, step_loss=0.438]Steps:  34%|██▎      | 132/400 [12:15<30:31,  6.84s/it, lr=1e-5, step_loss=0.249]Steps:  33%|███▎      | 133/400 [12:21<29:19,  6.59s/it, lr=1e-5, step_loss=0.249]Steps:  33%|███▎      | 133/400 [12:21<29:19,  6.59s/it, lr=1e-5, step_loss=0.142]Steps:  34%|███▎      | 134/400 [12:26<26:40,  6.02s/it, lr=1e-5, step_loss=0.142]Steps:  34%|███▎      | 134/400 [12:26<26:40,  6.02s/it, lr=1e-5, step_loss=0.35] Steps:  34%|███▍      | 135/400 [12:31<25:01,  5.67s/it, lr=1e-5, step_loss=0.35]Steps:  34%|███▍      | 135/400 [12:31<25:01,  5.67s/it, lr=1e-5, step_loss=0.166]Steps:  34%|███▍      | 136/400 [12:37<25:26,  5.78s/it, lr=1e-5, step_loss=0.166]Steps:  34%|███▍      | 136/400 [12:37<25:26,  5.78s/it, lr=1e-5, step_loss=0.444]Steps:  34%|███▍      | 137/400 [12:41<23:53,  5.45s/it, lr=1e-5, step_loss=0.444]Steps:  34%|███▍      | 137/400 [12:41<23:53,  5.45s/it, lr=1e-5, step_loss=0.0877]Steps:  34%|███▍      | 138/400 █▍      | 137/400 [12:42<23:53,  5.45s/it, lr=1e-5, step_loss=0.438]Steps:  34%|███▍      | 137/400 [12:42<23:53,  5.45s/it, lr=1e-5, step_loss=0.081]Steps:  34%|███▍      | 138/400 [12:47<23:00,  5.27s/it, lr=1e-5, step_loss=0.081]Steps:  34%|███▍      | 138/400 [12:47<23:00,  5.27s/it, lr=1e-5, step_loss=0.225]Steps:  35%|███▍      | 139/400 [12:52<22:09,  5.09s/it, lr=1e-5, step_loss=0.225]Steps:  35%|███▍      | 139/400 [12:52<22:09,  5.09s/it, lr=1e-5, step_loss=0.365]Steps:  35%|███▌      | 140/400 [12:56<21:33,  4.98s/it, lr=1e-5, step_loss=0.365]Steps:  35%|███▌      | 140/400 [12:56<21:33,  4.98s/it, lr=1e-5, step_loss=0.205]Steps:  35%|███▌      | 141/400 [13:01<21:18,  4.94s/it, lr=1e-5, step_loss=0.205]Steps:  35%|███▌      | 141/400 [13:01<21:18,  4.94s/it, lr=1e-5, step_loss=0.152]Steps:  36%|███▌      | 142/400 [13:07<22:39,  5.27s/it, lr=1e-5, step_loss=0.152]Steps:  36%|███▌      | 142/400[12:46<23:00,  5.27s/it, lr=1e-5, step_loss=0.0877]Steps:  34%|███▍      | 138/400 [12:46<23:00,  5.27s/it, lr=1e-5, step_loss=0.234] Steps:  35%|███▍      | 139/400 [12:51<22:09,  5.09s/it, lr=1e-5, step_loss=0.234]Steps:  35%|███▍      | 139/400 [12:51<22:09,  5.09s/it, lr=1e-5, step_loss=0.365]Steps:  35%|███▌      | 140/400 [12:56<21:33,  4.98s/it, lr=1e-5, step_loss=0.365]Steps:  35%|███▌      | 140/400 [12:56<21:33,  4.98s/it, lr=1e-5, step_loss=0.2]  Steps:  35%|███▌      | 141/400 [13:00<21:18,  4.94s/it, lr=1e-5, step_loss=0.2]Steps:  35%|███▌      | 141/400 [13:01<21:18,  4.94s/it, lr=1e-5, step_loss=0.16]Steps:  36%|███▌      | 142/400 [13:07<22:39,  5.27s/it, lr=1e-5, step_loss=0.16]Steps:  36%|███▌      | 142/400 [13:07<22:39,  5.27s/it, lr=1e-5, step_loss=0.2] Steps:  36%|███▌      | 143/400 [13:11<21:48,  5.09s/it, lr=1e-5, step_loss=0.2]Steps:  36%|███▌      | 143/400 [13:11<21:48,  5.09s/it, lr= [13:07<22:39,  5.27s/it, lr=1e-5, step_loss=0.212]Steps:  36%|███▌      | 143/400 [13:12<21:48,  5.09s/it, lr=1e-5, step_loss=0.212]Steps:  36%|███▌      | 143/400 [13:12<21:48,  5.09s/it, lr=1e-5, step_loss=0.374]Steps:  36%|███▌      | 144/400 [13:17<21:24,  5.02s/it, lr=1e-5, step_loss=0.374]Steps:  36%|███▌      | 144/400 [13:17<21:24,  5.02s/it, lr=1e-5, step_loss=0.282]Steps:  36%|███▋      | 145/400 [13:23<22:47,  5.36s/it, lr=1e-5, step_loss=0.282]Steps:  36%|███▋      | 145/400 [13:23<22:47,  5.36s/it, lr=1e-5, step_loss=0.322]Steps:  36%|███▋      | 146/400 [13:28<21:50,  5.16s/it, lr=1e-5, step_loss=0.322]Steps:  36%|███▋      | 146/400 [13:28<21:50,  5.16s/it, lr=1e-5, step_loss=0.226]Steps:  37%|███▋      | 147/400 [13:32<21:20,  5.06s/it, lr=1e-5, step_loss=0.226]Steps:  37%|███▋      | 147/400 [13:32<21:20,  5.06s/it, lr=1e-5, step_loss=0.365]Steps:  37%|███▋      | 148/400 [13:38<22:15,  5.30s/i1e-5, step_loss=0.363]Steps:  36%|███▌      | 144/400 [13:16<21:24,  5.02s/it, lr=1e-5, step_loss=0.363]Steps:  36%|███▌      | 144/400 [13:16<21:24,  5.02s/it, lr=1e-5, step_loss=0.307]Steps:  36%|███▋      | 145/400 [13:22<22:47,  5.36s/it, lr=1e-5, step_loss=0.307]Steps:  36%|███▋      | 145/400 [13:22<22:47,  5.36s/it, lr=1e-5, step_loss=0.283]Steps:  36%|███▋      | 146/400 [13:27<21:50,  5.16s/it, lr=1e-5, step_loss=0.283]Steps:  36%|███▋      | 146/400 [13:27<21:50,  5.16s/it, lr=1e-5, step_loss=0.216]Steps:  37%|███▋      | 147/400 [13:32<21:20,  5.06s/it, lr=1e-5, step_loss=0.216]Steps:  37%|███▋      | 147/400 [13:32<21:20,  5.06s/it, lr=1e-5, step_loss=0.413]Steps:  37%|███▋      | 148/400 [13:38<22:15,  5.30s/it, lr=1e-5, step_loss=0.413]Steps:  37%|███▋      | 148/400 [13:38<22:15,  5.30s/it, lr=1e-5, step_loss=0.139]Steps:  37%|███▋      | 149/400 [13:42<21:22,  5.11s/it, lr=1e-5, step_loss=0.139]t, lr=1e-5, step_loss=0.365]Steps:  37%|███▋      | 148/400 [13:38<22:15,  5.30s/it, lr=1e-5, step_loss=0.143]Steps:  37%|███▋      | 149/400 [13:43<21:22,  5.11s/it, lr=1e-5, step_loss=0.143]Steps:  37%|███▋      | 149/400 [13:43<21:22,  5.11s/it, lr=1e-5, step_loss=0.419]Steps:  38%|███▊      | 150/400 [13:48<20:59,  5.04s/it, lr=1e-5, step_loss=0.419]Steps:  38%|███▊      | 150/400 [13:48<20:59,  5.04s/it, lr=1e-5, step_loss=0.223]Steps:  38%|███▊      | 151/400 [13:53<20:29,  4.94s/it, lr=1e-5, step_loss=0.223]Steps:  38%|███▊      | 151/400 [13:53<20:29,  4.94s/it, lr=1e-5, step_loss=0.51] Steps:  38%|███▊      | 152/400 [13:57<20:04,  4.86s/it, lr=1e-5, step_loss=0.51]Steps:  38%|███▊      | 152/400 [13:57<20:04,  4.86s/it, lr=1e-5, step_loss=0.466]Steps:  38%|███▊      | 153/400 [14:02<19:59,  4.86s/it, lr=1e-5, step_loss=0.466]Steps:  38%|███▊      | 153/400 [14:02<19:59,  4.86s/it, lr=1e-5, step_loss=0.Steps:  37%|███▋      | 149/400 [13:42<21:22,  5.11s/it, lr=1e-5, step_loss=0.456]Steps:  38%|███▊      | 150/400 [13:47<20:58,  5.04s/it, lr=1e-5, step_loss=0.456]Steps:  38%|███▊      | 150/400 [13:47<20:58,  5.04s/it, lr=1e-5, step_loss=0.255]Steps:  38%|███▊      | 151/400 [13:52<20:29,  4.94s/it, lr=1e-5, step_loss=0.255]Steps:  38%|███▊      | 151/400 [13:52<20:29,  4.94s/it, lr=1e-5, step_loss=0.489]Steps:  38%|███▊      | 152/400 [13:57<20:04,  4.86s/it, lr=1e-5, step_loss=0.489]Steps:  38%|███▊      | 152/400 [13:57<20:04,  4.86s/it, lr=1e-5, step_loss=0.464]Steps:  38%|███▊      | 153/400 [14:01<19:59,  4.86s/it, lr=1e-5, step_loss=0.464]Steps:  38%|███▊      | 153/400 [14:01<19:59,  4.86s/it, lr=1e-5, step_loss=0.45] Steps:  38%|███▊      | 154/400 [14:07<21:24,  5.22s/it, lr=1e-5, step_loss=0.45]Steps:  38%|███▊      | 154/400 [14:07<21:24,  5.22s/it, lr=1e-5, step_loss=0.363]Steps:  39%|███▉442]Steps:  38%|███▊      | 154/400 [14:08<21:24,  5.22s/it, lr=1e-5, step_loss=0.442]Steps:  38%|███▊      | 154/400 [14:08<21:24,  5.22s/it, lr=1e-5, step_loss=0.309]Steps:  39%|███▉      | 155/400 [14:12<19:07,  4.68s/it, lr=1e-5, step_loss=0.309]Steps:  39%|███▉      | 155/400 [14:12<19:07,  4.68s/it, lr=1e-5, step_loss=0.368]Steps:  39%|███▉      | 156/400 [14:16<19:13,  4.73s/it, lr=1e-5, step_loss=0.368]Steps:  39%|███▉      | 156/400 [14:16<19:13,  4.73s/it, lr=1e-5, step_loss=0.346]Steps:  39%|███▉      | 157/400 [14:22<20:44,  5.12s/it, lr=1e-5, step_loss=0.346]Steps:  39%|███▉      | 157/400 [14:22<20:44,  5.12s/it, lr=1e-5, step_loss=0.243]Steps:  40%|███▉      | 158/400 [14:27<20:06,  4.99s/it, lr=1e-5, step_loss=0.243]Steps:  40%|███▉      | 158/400 [14:27<20:06,  4.99s/it, lr=1e-5, step_loss=0.29] Steps:  40%|███▉      | 159/400 [14:32<19:50,  4.94s/it, lr=1e-5, step_loss=0.29]Steps:  40%|██      | 155/400 [14:11<19:07,  4.69s/it, lr=1e-5, step_loss=0.363]Steps:  39%|███▉      | 155/400 [14:11<19:07,  4.69s/it, lr=1e-5, step_loss=0.359]Steps:  39%|███▉      | 156/400 [14:16<19:13,  4.73s/it, lr=1e-5, step_loss=0.359]Steps:  39%|███▉      | 156/400 [14:16<19:13,  4.73s/it, lr=1e-5, step_loss=0.321]Steps:  39%|███▉      | 157/400 [14:22<20:44,  5.12s/it, lr=1e-5, step_loss=0.321]Steps:  39%|███▉      | 157/400 [14:22<20:44,  5.12s/it, lr=1e-5, step_loss=0.246]Steps:  40%|███▉      | 158/400 [14:26<20:06,  4.99s/it, lr=1e-5, step_loss=0.246]Steps:  40%|███▉      | 158/400 [14:26<20:06,  4.99s/it, lr=1e-5, step_loss=0.264]Steps:  40%|███▉      | 159/400 [14:31<19:50,  4.94s/it, lr=1e-5, step_loss=0.264]Steps:  40%|███▉      | 159/400 [14:31<19:50,  4.94s/it, lr=1e-5, step_loss=0.239]Steps:  40%|████      | 160/400 [14:37<20:58,  5.24s/it, lr=1e-5, step_loss=0.239]Steps:  40%|████      | 160/400 [14:37<▉      | 159/400 [14:32<19:50,  4.94s/it, lr=1e-5, step_loss=0.232]Steps:  40%|████      | 160/400 [14:38<20:58,  5.24s/it, lr=1e-5, step_loss=0.232]Steps:  40%|████      | 160/400 [14:38<20:58,  5.24s/it, lr=1e-5, step_loss=0.239]Steps:  40%|████      | 161/400 [14:43<20:12,  5.07s/it, lr=1e-5, step_loss=0.239]Steps:  40%|████      | 161/400 [14:43<20:12,  5.07s/it, lr=1e-5, step_loss=0.201]Steps:  40%|████      | 162/400 [14:47<19:50,  5.00s/it, lr=1e-5, step_loss=0.201]Steps:  40%|████      | 162/400 [14:47<19:50,  5.00s/it, lr=1e-5, step_loss=0.203]Steps:  41%|████      | 163/400 [14:53<20:57,  5.30s/it, lr=1e-5, step_loss=0.203]Steps:  41%|████      | 163/400 [14:53<20:57,  5.30s/it, lr=1e-5, step_loss=0.0963]Steps:  41%|████      | 164/400 [14:58<20:07,  5.11s/it, lr=1e-5, step_loss=0.0963]Steps:  41%|████      | 164/400 [14:58<20:07,  5.11s/it, lr=1e-5, step_loss=0.062] Steps:  41%|████▏     | 165/420:58,  5.24s/it, lr=1e-5, step_loss=0.23] Steps:  40%|████      | 161/400 [14:42<20:12,  5.07s/it, lr=1e-5, step_loss=0.23]Steps:  40%|████      | 161/400 [14:42<20:12,  5.07s/it, lr=1e-5, step_loss=0.211]Steps:  40%|████      | 162/400 [14:47<19:50,  5.00s/it, lr=1e-5, step_loss=0.211]Steps:  40%|████      | 162/400 [14:47<19:50,  5.00s/it, lr=1e-5, step_loss=0.216]Steps:  41%|████      | 163/400 [14:53<20:57,  5.30s/it, lr=1e-5, step_loss=0.216]Steps:  41%|████      | 163/400 [14:53<20:57,  5.30s/it, lr=1e-5, step_loss=0.0768]Steps:  41%|████      | 164/400 [14:57<20:07,  5.11s/it, lr=1e-5, step_loss=0.0768]Steps:  41%|████      | 164/400 [14:57<20:07,  5.11s/it, lr=1e-5, step_loss=0.0987]Steps:  41%|████▏     | 165/400 [15:02<19:42,  5.03s/it, lr=1e-5, step_loss=0.0987]Steps:  41%|████▏     | 165/400 [15:02<19:42,  5.03s/it, lr=1e-5, step_loss=0.194] Steps:  42%|████▏     | 166/400 [15:08<20:31,  5.26s00 [15:03<19:42,  5.03s/it, lr=1e-5, step_loss=0.062]Steps:  41%|████▏     | 165/400 [15:03<19:42,  5.03s/it, lr=1e-5, step_loss=0.195]Steps:  42%|████▏     | 166/400 [15:09<20:31,  5.26s/it, lr=1e-5, step_loss=0.195]Steps:  42%|████▏     | 166/400 [15:09<20:31,  5.26s/it, lr=1e-5, step_loss=0.149]Steps:  42%|████▏     | 167/400 [15:13<19:45,  5.09s/it, lr=1e-5, step_loss=0.149]Steps:  42%|████▏     | 167/400 [15:13<19:45,  5.09s/it, lr=1e-5, step_loss=0.259]Steps:  42%|████▏     | 168/400 [15:18<19:24,  5.02s/it, lr=1e-5, step_loss=0.259]Steps:  42%|████▏     | 168/400 [15:18<19:24,  5.02s/it, lr=1e-5, step_loss=0.186]Steps:  42%|████▏     | 169/400 [15:24<20:25,  5.31s/it, lr=1e-5, step_loss=0.186]Steps:  42%|████▏     | 169/400 [15:24<20:25,  5.31s/it, lr=1e-5, step_loss=0.199]Steps:  42%|████▎     | 170/400 [15:29<19:37,  5.12s/it, lr=1e-5, step_loss=0.199]Steps:  42%|████▎     | 170/40/it, lr=1e-5, step_loss=0.194]Steps:  42%|████▏     | 166/400 [15:08<20:31,  5.26s/it, lr=1e-5, step_loss=0.106]Steps:  42%|████▏     | 167/400 [15:13<19:45,  5.09s/it, lr=1e-5, step_loss=0.106]Steps:  42%|████▏     | 167/400 [15:13<19:45,  5.09s/it, lr=1e-5, step_loss=0.277]Steps:  42%|████▏     | 168/400 [15:18<19:24,  5.02s/it, lr=1e-5, step_loss=0.277]Steps:  42%|████▏     | 168/400 [15:18<19:24,  5.02s/it, lr=1e-5, step_loss=0.173]Steps:  42%|████▏     | 169/400 [15:24<20:25,  5.31s/it, lr=1e-5, step_loss=0.173]Steps:  42%|████▏     | 169/400 [15:24<20:25,  5.31s/it, lr=1e-5, step_loss=0.23] Steps:  42%|████▎     | 170/400 [15:28<19:37,  5.12s/it, lr=1e-5, step_loss=0.23]Steps:  42%|████▎     | 170/400 [15:28<19:37,  5.12s/it, lr=1e-5, step_loss=0.094]Steps:  43%|████▎     | 171/400 [15:33<19:14,  5.04s/it, lr=1e-5, step_loss=0.094]Steps:  43%|████▎     | 171/400 [15:33<19:14,  5.04s/i0 [15:29<19:37,  5.12s/it, lr=1e-5, step_loss=0.121]Steps:  43%|████▎     | 171/400 [15:34<19:14,  5.04s/it, lr=1e-5, step_loss=0.121]Steps:  43%|████▎     | 171/400 [15:34<19:14,  5.04s/it, lr=1e-5, step_loss=0.173]Steps:  43%|████▎     | 172/400 [15:40<20:12,  5.32s/it, lr=1e-5, step_loss=0.173]Steps:  43%|████▎     | 172/400 [15:40<20:12,  5.32s/it, lr=1e-5, step_loss=0.298]Steps:  43%|████▎     | 173/400 [15:44<19:23,  5.12s/it, lr=1e-5, step_loss=0.298]Steps:  43%|████▎     | 173/400 [15:44<19:23,  5.12s/it, lr=1e-5, step_loss=0.14] Steps:  44%|████▎     | 174/400 [15:49<18:58,  5.04s/it, lr=1e-5, step_loss=0.14]Steps:  44%|████▎     | 174/400 [15:49<18:58,  5.04s/it, lr=1e-5, step_loss=0.231]Steps:  44%|████▍     | 175/400 [15:55<20:08,  5.37s/it, lr=1e-5, step_loss=0.231]Steps:  44%|████▍     | 175/400 [15:55<20:08,  5.37s/it, lr=1e-5, step_loss=0.272]Steps:  44%|████▍     | 176/400 t, lr=1e-5, step_loss=0.163]Steps:  43%|████▎     | 172/400 [15:39<20:12,  5.32s/it, lr=1e-5, step_loss=0.163]Steps:  43%|████▎     | 172/400 [15:39<20:12,  5.32s/it, lr=1e-5, step_loss=0.293]Steps:  43%|████▎     | 173/400 [15:44<19:23,  5.12s/it, lr=1e-5, step_loss=0.293]Steps:  43%|████▎     | 173/400 [15:44<19:23,  5.12s/it, lr=1e-5, step_loss=0.122]Steps:  44%|████▎     | 174/400 [15:49<18:58,  5.04s/it, lr=1e-5, step_loss=0.122]Steps:  44%|████▎     | 174/400 [15:49<18:58,  5.04s/it, lr=1e-5, step_loss=0.276]Steps:  44%|████▍     | 175/400 [15:55<20:08,  5.37s/it, lr=1e-5, step_loss=0.276]Steps:  44%|████▍     | 175/400 [15:55<20:08,  5.37s/it, lr=1e-5, step_loss=0.304]Steps:  44%|████▍     | 176/400 [15:59<19:16,  5.16s/it, lr=1e-5, step_loss=0.304]Steps:  44%|████▍     | 176/400 [15:59<19:16,  5.16s/it, lr=1e-5, step_loss=0.0784]Steps:  44%|████▍     | 177/400 [16:04<18:51,  5.07s/i[16:00<19:16,  5.16s/it, lr=1e-5, step_loss=0.272]Steps:  44%|████▍     | 176/400 [16:00<19:16,  5.16s/it, lr=1e-5, step_loss=0.099]Steps:  44%|████▍     | 177/400 [16:05<18:51,  5.07s/it, lr=1e-5, step_loss=0.099]Steps:  44%|████▍     | 177/400 [16:05<18:51,  5.07s/it, lr=1e-5, step_loss=0.137]Steps:  44%|████▍     | 178/400 [16:11<19:45,  5.34s/it, lr=1e-5, step_loss=0.137]Steps:  44%|████▍     | 178/400 [16:11<19:45,  5.34s/it, lr=1e-5, step_loss=0.122]Steps:  45%|████▍     | 179/400 [16:16<18:56,  5.14s/it, lr=1e-5, step_loss=0.122]Steps:  45%|████▍     | 179/400 [16:16<18:56,  5.14s/it, lr=1e-5, step_loss=0.104]Steps:  45%|████▌     | 180/400 [16:19<17:11,  4.69s/it, lr=1e-5, step_loss=0.104]Steps:  45%|████▌     | 180/400 [16:19<17:11,  4.69s/it, lr=1e-5, step_loss=0.157]Steps:  45%|████▌     | 181/400 [16:25<18:35,  5.09s/it, lr=1e-5, step_loss=0.157]Steps:  45%|████▌     | 181/400 [t, lr=1e-5, step_loss=0.0784]Steps:  44%|████▍     | 177/400 [16:04<18:51,  5.07s/it, lr=1e-5, step_loss=0.141] Steps:  44%|████▍     | 178/400 [16:10<19:45,  5.34s/it, lr=1e-5, step_loss=0.141]Steps:  44%|████▍     | 178/400 [16:10<19:45,  5.34s/it, lr=1e-5, step_loss=0.147]Steps:  45%|████▍     | 179/400 [16:15<18:56,  5.14s/it, lr=1e-5, step_loss=0.147]Steps:  45%|████▍     | 179/400 [16:15<18:56,  5.14s/it, lr=1e-5, step_loss=0.0834]Steps:  45%|████▌     | 180/400 [16:19<17:11,  4.69s/it, lr=1e-5, step_loss=0.0834]Steps:  45%|████▌     | 180/400 [16:19<17:11,  4.69s/it, lr=1e-5, step_loss=0.19]  Steps:  45%|████▌     | 181/400 [16:25<18:35,  5.09s/it, lr=1e-5, step_loss=0.19]Steps:  45%|████▌     | 181/400 [16:25<18:35,  5.09s/it, lr=1e-5, step_loss=0.173]Steps:  46%|████▌     | 182/400 [16:28<16:41,  4.59s/it, lr=1e-5, step_loss=0.173]Steps:  46%|████▌     | 182/400 [16:28<16:41,  4.5916:25<18:35,  5.09s/it, lr=1e-5, step_loss=0.194]Steps:  46%|████▌     | 182/400 [16:29<16:41,  4.60s/it, lr=1e-5, step_loss=0.194]Steps:  46%|████▌     | 182/400 [16:29<16:41,  4.60s/it, lr=1e-5, step_loss=0.312]Steps:  46%|████▌     | 183/400 [16:34<16:53,  4.67s/it, lr=1e-5, step_loss=0.312]Steps:  46%|████▌     | 183/400 [16:34<16:53,  4.67s/it, lr=1e-5, step_loss=0.278]Steps:  46%|████▌     | 184/400 [16:39<18:09,  5.04s/it, lr=1e-5, step_loss=0.278]Steps:  46%|████▌     | 184/400 [16:39<18:09,  5.04s/it, lr=1e-5, step_loss=0.197]Steps:  46%|████▋     | 185/400 [16:44<17:39,  4.93s/it, lr=1e-5, step_loss=0.197]Steps:  46%|████▋     | 185/400 [16:44<17:39,  4.93s/it, lr=1e-5, step_loss=0.205]Steps:  46%|████▋     | 186/400 [16:49<17:28,  4.90s/it, lr=1e-5, step_loss=0.205]Steps:  46%|████▋     | 186/400 [16:49<17:28,  4.90s/it, lr=1e-5, step_loss=0.202]Steps:  47%|████▋     | 187/400 [1s/it, lr=1e-5, step_loss=0.273]Steps:  46%|████▌     | 183/400 [16:33<16:53,  4.67s/it, lr=1e-5, step_loss=0.273]Steps:  46%|████▌     | 183/400 [16:33<16:53,  4.67s/it, lr=1e-5, step_loss=0.28] Steps:  46%|████▌     | 184/400 [16:39<18:09,  5.04s/it, lr=1e-5, step_loss=0.28]Steps:  46%|████▌     | 184/400 [16:39<18:09,  5.04s/it, lr=1e-5, step_loss=0.205]Steps:  46%|████▋     | 185/400 [16:43<17:39,  4.93s/it, lr=1e-5, step_loss=0.205]Steps:  46%|████▋     | 185/400 [16:43<17:39,  4.93s/it, lr=1e-5, step_loss=0.231]Steps:  46%|████▋     | 186/400 [16:48<17:28,  4.90s/it, lr=1e-5, step_loss=0.231]Steps:  46%|████▋     | 186/400 [16:48<17:28,  4.90s/it, lr=1e-5, step_loss=0.2]  Steps:  47%|████▋     | 187/400 [16:54<18:37,  5.25s/it, lr=1e-5, step_loss=0.2]Steps:  47%|████▋     | 187/400 [16:54<18:37,  5.25s/it, lr=1e-5, step_loss=0.217]Steps:  47%|████▋     | 188/400 [16:59<17:56,  5.08s/it, lr=1e-5, step_loss=0.217]Steps:  47%|████▋     | 188/400 [16:59<17:56,  5.08s/it, lr=1e-5, step_loss=0.179]Steps:  47%|████▋     | 189/400 [17:04<17:34,  5.00s/it, lr=1e-5, step_loss=0.179]Steps:  47%|████▋     | 189/400 [17:04<17:34,  5.00s/it, lr=1e-5, step_loss=0.131]07/03/2024 08:05:55 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:05:55 - INFO - __main__ - removing checkpoints: reference_unet-126.pth
07/03/2024 08:06:00 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:06:00 - INFO - __main__ - removing checkpoints: denoising_unet-126.pth
07/03/2024 08:06:07 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:06:07 - INFO - __main__ - removing checkpoints: pose_guider-126.pth
6:55<18:37,  5.25s/it, lr=1e-5, step_loss=0.202]Steps:  47%|████▋     | 187/400 [16:55<18:37,  5.25s/it, lr=1e-5, step_loss=0.233]Steps:  47%|████▋     | 188/400 [17:00<17:56,  5.08s/it, lr=1e-5, step_loss=0.233]Steps:  47%|████▋     | 188/400 [17:00<17:56,  5.08s/it, lr=1e-5, step_loss=0.197]Steps:  47%|████▋     | 189/400 [17:04<17:34,  5.00s/it, lr=1e-5, step_loss=0.197]Steps:  47%|████▋     | 189/400 [17:04<17:34,  5.00s/it, lr=1e-5, step_loss=0.115]Steps:  48%|████▊     | 190/400 [17:42<51:10, 14.62s/it, lr=1e-5, step_loss=0.115]Steps:  48%|████▊     | 190/400 [17:42<51:10, 14.62s/it, lr=1e-5, step_loss=0.126]Steps:  48%|████▊     | 191/400 [17:46<40:35, 11.65s/it, lr=1e-5, step_loss=0.126]Steps:  48%|████▊     | 191/400 [17:46<40:35, 11.65s/it, lr=1e-5, step_loss=0.151]Steps:  48%|████▊     | 192/400 [17:51<33:19,  9.61s/it, lr=1e-5, step_loss=0.151]Steps:  48%|████▊     | 192/400 [17Steps:  48%|████▊     | 190/400 [17:41<51:10, 14.62s/it, lr=1e-5, step_loss=0.131]Steps:  48%|████▊     | 190/400 [17:41<51:10, 14.62s/it, lr=1e-5, step_loss=0.135]Steps:  48%|████▊     | 191/400 [17:46<40:35, 11.65s/it, lr=1e-5, step_loss=0.135]Steps:  48%|████▊     | 191/400 [17:46<40:35, 11.65s/it, lr=1e-5, step_loss=0.164]Steps:  48%|████▊     | 192/400 [17:50<33:19,  9.61s/it, lr=1e-5, step_loss=0.164]Steps:  48%|████▊     | 192/400 [17:50<33:19,  9.61s/it, lr=1e-5, step_loss=0.166]Steps:  48%|████▊     | 193/400 [17:56<29:15,  8.48s/it, lr=1e-5, step_loss=0.166]Steps:  48%|████▊     | 193/400 [17:56<29:15,  8.48s/it, lr=1e-5, step_loss=0.283]Steps:  48%|████▊     | 194/400 [18:01<25:12,  7.34s/it, lr=1e-5, step_loss=0.283]Steps:  48%|████▊     | 194/400 [18:01<25:12,  7.34s/it, lr=1e-5, step_loss=0.11] Steps:  49%|████▉     | 195/400 [18:06<22:32,  6.60s/it, lr=1e-5, step_loss=0.11]S:51<33:19,  9.61s/it, lr=1e-5, step_loss=0.183]Steps:  48%|████▊     | 193/400 [17:57<29:15,  8.48s/it, lr=1e-5, step_loss=0.183]Steps:  48%|████▊     | 193/400 [17:57<29:15,  8.48s/it, lr=1e-5, step_loss=0.3]  Steps:  48%|████▊     | 194/400 [18:02<25:12,  7.34s/it, lr=1e-5, step_loss=0.3]Steps:  48%|████▊     | 194/400 [18:02<25:12,  7.34s/it, lr=1e-5, step_loss=0.11]Steps:  49%|████▉     | 195/400 [18:07<22:32,  6.60s/it, lr=1e-5, step_loss=0.11]Steps:  49%|████▉     | 195/400 [18:07<22:32,  6.60s/it, lr=1e-5, step_loss=0.102]Steps:  49%|████▉     | 196/400 [18:13<21:58,  6.46s/it, lr=1e-5, step_loss=0.102]Steps:  49%|████▉     | 196/400 [18:13<21:58,  6.46s/it, lr=1e-5, step_loss=0.159]Steps:  49%|████▉     | 197/400 [18:17<20:03,  5.93s/it, lr=1e-5, step_loss=0.159]Steps:  49%|████▉     | 197/400 [18:17<20:03,  5.93s/it, lr=1e-5, step_loss=0.2]  Steps:  50%|████▉     | 198/400 [18:22<1teps:  49%|████▉     | 195/400 [18:06<22:32,  6.60s/it, lr=1e-5, step_loss=0.103]Steps:  49%|████▉     | 196/400 [18:12<21:58,  6.46s/it, lr=1e-5, step_loss=0.103]Steps:  49%|████▉     | 196/400 [18:12<21:58,  6.46s/it, lr=1e-5, step_loss=0.145]Steps:  49%|████▉     | 197/400 [18:17<20:03,  5.93s/it, lr=1e-5, step_loss=0.145]Steps:  49%|████▉     | 197/400 [18:17<20:03,  5.93s/it, lr=1e-5, step_loss=0.226]Steps:  50%|████▉     | 198/400 [18:22<18:53,  5.61s/it, lr=1e-5, step_loss=0.226]Steps:  50%|████▉     | 198/400 [18:22<18:53,  5.61s/it, lr=1e-5, step_loss=0.146]Steps:  50%|████▉     | 199/400 [18:28<19:13,  5.74s/it, lr=1e-5, step_loss=0.146]Steps:  50%|████▉     | 199/400 [18:28<19:13,  5.74s/it, lr=1e-5, step_loss=0.16] Steps:  50%|█████     | 200/400 [18:32<18:02,  5.41s/it, lr=1e-5, step_loss=0.16]Steps:  50%|█████     | 200/400 [18:32<18:02,  5.41s/it, lr=1e-5, step_loss=0.101]Ste8:53,  5.61s/it, lr=1e-5, step_loss=0.2]Steps:  50%|████▉     | 198/400 [18:22<18:53,  5.61s/it, lr=1e-5, step_loss=0.145]Steps:  50%|████▉     | 199/400 [18:28<19:13,  5.74s/it, lr=1e-5, step_loss=0.145]Steps:  50%|████▉     | 199/400 [18:28<19:13,  5.74s/it, lr=1e-5, step_loss=0.162]Steps:  50%|█████     | 200/400 [18:33<18:02,  5.41s/it, lr=1e-5, step_loss=0.162]Steps:  50%|█████     | 200/400 [18:33<18:02,  5.41s/it, lr=1e-5, step_loss=0.101]Steps:  50%|█████     | 201/400 [18:38<17:24,  5.25s/it, lr=1e-5, step_loss=0.101]Steps:  50%|█████     | 201/400 [18:38<17:24,  5.25s/it, lr=1e-5, step_loss=0.203]Steps:  50%|█████     | 202/400 [18:44<18:08,  5.50s/it, lr=1e-5, step_loss=0.203]Steps:  50%|█████     | 202/400 [18:44<18:08,  5.50s/it, lr=1e-5, step_loss=0.173]Steps:  51%|█████     | 203/400 [18:49<17:15,  5.26s/it, lr=1e-5, step_loss=0.173]Steps:  51%|█████     | 203/400 [18:49<17:1ps:  50%|█████     | 201/400 [18:37<17:24,  5.25s/it, lr=1e-5, step_loss=0.101]Steps:  50%|█████     | 201/400 [18:37<17:24,  5.25s/it, lr=1e-5, step_loss=0.198]Steps:  50%|█████     | 202/400 [18:43<18:08,  5.50s/it, lr=1e-5, step_loss=0.198]Steps:  50%|█████     | 202/400 [18:43<18:08,  5.50s/it, lr=1e-5, step_loss=0.186]Steps:  51%|█████     | 203/400 [18:48<17:15,  5.26s/it, lr=1e-5, step_loss=0.186]Steps:  51%|█████     | 203/400 [18:48<17:15,  5.26s/it, lr=1e-5, step_loss=0.184]Steps:  51%|█████     | 204/400 [18:53<16:45,  5.13s/it, lr=1e-5, step_loss=0.184]Steps:  51%|█████     | 204/400 [18:53<16:45,  5.13s/it, lr=1e-5, step_loss=0.197]Steps:  51%|█████▏    | 205/400 [18:59<17:32,  5.40s/it, lr=1e-5, step_loss=0.197]Steps:  51%|█████▏    | 205/400 [18:59<17:32,  5.40s/it, lr=1e-5, step_loss=0.202]Steps:  52%|█████▏    | 206/400 [19:03<16:44,  5.18s/it, lr=1e-5, step_loss=0.2025,  5.26s/it, lr=1e-5, step_loss=0.214]Steps:  51%|█████     | 204/400 [18:53<16:45,  5.13s/it, lr=1e-5, step_loss=0.214]Steps:  51%|█████     | 204/400 [18:53<16:45,  5.13s/it, lr=1e-5, step_loss=0.21] Steps:  51%|█████▏    | 205/400 [18:59<17:32,  5.40s/it, lr=1e-5, step_loss=0.21]Steps:  51%|█████▏    | 205/400 [18:59<17:32,  5.40s/it, lr=1e-5, step_loss=0.194]Steps:  52%|█████▏    | 206/400 [19:04<16:44,  5.18s/it, lr=1e-5, step_loss=0.194]Steps:  52%|█████▏    | 206/400 [19:04<16:44,  5.18s/it, lr=1e-5, step_loss=0.284]Steps:  52%|█████▏    | 207/400 [19:09<16:19,  5.08s/it, lr=1e-5, step_loss=0.284]Steps:  52%|█████▏    | 207/400 [19:09<16:19,  5.08s/it, lr=1e-5, step_loss=0.15] Steps:  52%|█████▏    | 208/400 [19:15<17:10,  5.37s/it, lr=1e-5, step_loss=0.15]Steps:  52%|█████▏    | 208/400 [19:15<17:10,  5.37s/it, lr=1e-5, step_loss=0.189]Steps:  52%|█████▏    | 209/]Steps:  52%|█████▏    | 206/400 [19:03<16:44,  5.18s/it, lr=1e-5, step_loss=0.273]Steps:  52%|█████▏    | 207/400 [19:08<16:19,  5.08s/it, lr=1e-5, step_loss=0.273]Steps:  52%|█████▏    | 207/400 [19:08<16:19,  5.08s/it, lr=1e-5, step_loss=0.116]Steps:  52%|█████▏    | 208/400 [19:14<17:10,  5.37s/it, lr=1e-5, step_loss=0.116]Steps:  52%|█████▏    | 208/400 [19:14<17:10,  5.37s/it, lr=1e-5, step_loss=0.171]Steps:  52%|█████▏    | 209/400 [19:19<16:25,  5.16s/it, lr=1e-5, step_loss=0.171]Steps:  52%|█████▏    | 209/400 [19:19<16:25,  5.16s/it, lr=1e-5, step_loss=0.218]Steps:  52%|█████▎    | 210/400 [19:24<16:02,  5.06s/it, lr=1e-5, step_loss=0.218]Steps:  52%|█████▎    | 210/400 [19:24<16:02,  5.06s/it, lr=1e-5, step_loss=0.161]Steps:  53%|█████▎    | 211/400 [19:29<15:42,  4.99s/it, lr=1e-5, step_loss=0.161]Steps:  53%|█████▎    | 211/400 [19:29<15:42,  4.99s/it, lr=400 [19:20<16:25,  5.16s/it, lr=1e-5, step_loss=0.189]Steps:  52%|█████▏    | 209/400 [19:20<16:25,  5.16s/it, lr=1e-5, step_loss=0.209]Steps:  52%|█████▎    | 210/400 [19:24<16:02,  5.06s/it, lr=1e-5, step_loss=0.209]Steps:  52%|█████▎    | 210/400 [19:24<16:02,  5.06s/it, lr=1e-5, step_loss=0.156]Steps:  53%|█████▎    | 211/400 [19:29<15:42,  4.99s/it, lr=1e-5, step_loss=0.156]Steps:  53%|█████▎    | 211/400 [19:29<15:42,  4.99s/it, lr=1e-5, step_loss=0.322]Steps:  53%|█████▎    | 212/400 [19:34<15:21,  4.90s/it, lr=1e-5, step_loss=0.322]Steps:  53%|█████▎    | 212/400 [19:34<15:21,  4.90s/it, lr=1e-5, step_loss=0.111]Steps:  53%|█████▎    | 213/400 [19:39<15:13,  4.89s/it, lr=1e-5, step_loss=0.111]Steps:  53%|█████▎    | 213/400 [19:39<15:13,  4.89s/it, lr=1e-5, step_loss=0.0874]Steps:  54%|█████▎    | 214/400 [19:45<16:10,  5.22s/it, lr=1e-5, step_loss=0.0874]Steps:  54%|█1e-5, step_loss=0.325]Steps:  53%|█████▎    | 212/400 [19:33<15:21,  4.90s/it, lr=1e-5, step_loss=0.325]Steps:  53%|█████▎    | 212/400 [19:33<15:21,  4.90s/it, lr=1e-5, step_loss=0.0743]Steps:  53%|█████▎    | 213/400 [19:38<15:13,  4.89s/it, lr=1e-5, step_loss=0.0743]Steps:  53%|█████▎    | 213/400 [19:38<15:13,  4.89s/it, lr=1e-5, step_loss=0.0937]Steps:  54%|█████▎    | 214/400 [19:44<16:11,  5.22s/it, lr=1e-5, step_loss=0.0937]Steps:  54%|█████▎    | 214/400 [19:44<16:11,  5.22s/it, lr=1e-5, step_loss=0.248] Steps:  54%|█████▍    | 215/400 [19:49<15:36,  5.06s/it, lr=1e-5, step_loss=0.248]Steps:  54%|█████▍    | 215/400 [19:49<15:36,  5.06s/it, lr=1e-5, step_loss=0.176]Steps:  54%|█████▍    | 216/400 [19:54<15:20,  5.00s/it, lr=1e-5, step_loss=0.176]Steps:  54%|█████▍    | 216/400 [19:54<15:20,  5.00s/it, lr=1e-5, step_loss=0.206]Steps:  54%|█████▍    | 217/400 [2███▎    | 214/400 [19:45<16:10,  5.22s/it, lr=1e-5, step_loss=0.241] Steps:  54%|█████▍    | 215/400 [19:50<15:36,  5.06s/it, lr=1e-5, step_loss=0.241]Steps:  54%|█████▍    | 215/400 [19:50<15:36,  5.06s/it, lr=1e-5, step_loss=0.185]Steps:  54%|█████▍    | 216/400 [19:54<15:20,  5.00s/it, lr=1e-5, step_loss=0.185]Steps:  54%|█████▍    | 216/400 [19:54<15:20,  5.00s/it, lr=1e-5, step_loss=0.22] Steps:  54%|█████▍    | 217/400 [20:00<16:10,  5.30s/it, lr=1e-5, step_loss=0.22]Steps:  54%|█████▍    | 217/400 [20:00<16:10,  5.30s/it, lr=1e-5, step_loss=0.113]Steps:  55%|█████▍    | 218/400 [20:05<15:31,  5.12s/it, lr=1e-5, step_loss=0.113]Steps:  55%|█████▍    | 218/400 [20:05<15:31,  5.12s/it, lr=1e-5, step_loss=0.0933]Steps:  55%|█████▍    | 219/400 [20:10<15:12,  5.04s/it, lr=1e-5, step_loss=0.0933]Steps:  55%|█████▍    | 219/400 [20:10<15:12,  5.04s/it, lr=1e-5, step_loss=00:00<16:10,  5.30s/it, lr=1e-5, step_loss=0.206]Steps:  54%|█████▍    | 217/400 [20:00<16:10,  5.30s/it, lr=1e-5, step_loss=0.118]Steps:  55%|█████▍    | 218/400 [20:04<15:31,  5.12s/it, lr=1e-5, step_loss=0.118]Steps:  55%|█████▍    | 218/400 [20:04<15:31,  5.12s/it, lr=1e-5, step_loss=0.122]Steps:  55%|█████▍    | 219/400 [20:09<15:11,  5.04s/it, lr=1e-5, step_loss=0.122]Steps:  55%|█████▍    | 219/400 [20:09<15:11,  5.04s/it, lr=1e-5, step_loss=0.149]Steps:  55%|█████▌    | 220/400 [20:15<15:53,  5.30s/it, lr=1e-5, step_loss=0.149]Steps:  55%|█████▌    | 220/400 [20:15<15:53,  5.30s/it, lr=1e-5, step_loss=0.193]Steps:  55%|█████▌    | 221/400 [20:20<15:15,  5.11s/it, lr=1e-5, step_loss=0.193]Steps:  55%|█████▌    | 221/400 [20:20<15:15,  5.11s/it, lr=1e-5, step_loss=0.139]Steps:  56%|█████▌    | 222/400 [20:25<15:00,  5.06s/it, lr=1e-5, step_loss=0.139]Steps:  56%|████.142] Steps:  55%|█████▌    | 220/400 [20:16<15:53,  5.30s/it, lr=1e-5, step_loss=0.142]Steps:  55%|█████▌    | 220/400 [20:16<15:53,  5.30s/it, lr=1e-5, step_loss=0.189]Steps:  55%|█████▌    | 221/400 [20:21<15:15,  5.11s/it, lr=1e-5, step_loss=0.189]Steps:  55%|█████▌    | 221/400 [20:21<15:15,  5.11s/it, lr=1e-5, step_loss=0.114]Steps:  56%|█████▌    | 222/400 [20:25<15:00,  5.06s/it, lr=1e-5, step_loss=0.114]Steps:  56%|█████▌    | 222/400 [20:25<15:00,  5.06s/it, lr=1e-5, step_loss=0.109]Steps:  56%|█████▌    | 223/400 [20:31<15:43,  5.33s/it, lr=1e-5, step_loss=0.109]Steps:  56%|█████▌    | 223/400 [20:31<15:43,  5.33s/it, lr=1e-5, step_loss=0.0847]Steps:  56%|█████▌    | 224/400 [20:36<15:03,  5.14s/it, lr=1e-5, step_loss=0.0847]Steps:  56%|█████▌    | 224/400 [20:36<15:03,  5.14s/it, lr=1e-5, step_loss=0.131] Steps:  56%|█████▋    | 225/400 [20:41<14:43,  5.05s▌    | 222/400 [20:25<15:00,  5.06s/it, lr=1e-5, step_loss=0.101]Steps:  56%|█████▌    | 223/400 [20:31<15:43,  5.33s/it, lr=1e-5, step_loss=0.101]Steps:  56%|█████▌    | 223/400 [20:31<15:43,  5.33s/it, lr=1e-5, step_loss=0.107]Steps:  56%|█████▌    | 224/400 [20:35<15:03,  5.14s/it, lr=1e-5, step_loss=0.107]Steps:  56%|█████▌    | 224/400 [20:35<15:03,  5.14s/it, lr=1e-5, step_loss=0.155]Steps:  56%|█████▋    | 225/400 [20:40<14:43,  5.05s/it, lr=1e-5, step_loss=0.155]Steps:  56%|█████▋    | 225/400 [20:40<14:43,  5.05s/it, lr=1e-5, step_loss=0.18] Steps:  56%|█████▋    | 226/400 [20:46<15:38,  5.39s/it, lr=1e-5, step_loss=0.18]Steps:  56%|█████▋    | 226/400 [20:46<15:38,  5.39s/it, lr=1e-5, step_loss=0.0905]Steps:  57%|█████▋    | 227/400 [20:51<14:55,  5.18s/it, lr=1e-5, step_loss=0.0905]Steps:  57%|█████▋    | 227/400 [20:51<14:55,  5.18s/it, lr=1e-5, step_loss=0.0826]St/it, lr=1e-5, step_loss=0.131]Steps:  56%|█████▋    | 225/400 [20:41<14:43,  5.05s/it, lr=1e-5, step_loss=0.192]Steps:  56%|█████▋    | 226/400 [20:47<15:38,  5.39s/it, lr=1e-5, step_loss=0.192]Steps:  56%|█████▋    | 226/400 [20:47<15:38,  5.39s/it, lr=1e-5, step_loss=0.096]Steps:  57%|█████▋    | 227/400 [20:52<14:55,  5.18s/it, lr=1e-5, step_loss=0.096]Steps:  57%|█████▋    | 227/400 [20:52<14:55,  5.18s/it, lr=1e-5, step_loss=0.0676]Steps:  57%|█████▋    | 228/400 [20:57<14:33,  5.08s/it, lr=1e-5, step_loss=0.0676]Steps:  57%|█████▋    | 228/400 [20:57<14:33,  5.08s/it, lr=1e-5, step_loss=0.15]  Steps:  57%|█████▋    | 229/400 [21:03<15:15,  5.35s/it, lr=1e-5, step_loss=0.15]Steps:  57%|█████▋    | 229/400 [21:03<15:15,  5.35s/it, lr=1e-5, step_loss=0.213]Steps:  57%|█████▊    | 230/400 [21:07<14:35,  5.15s/it, lr=1e-5, step_loss=0.213]Steps:  57%|█████▊    | 230/4eps:  57%|█████▋    | 228/400 [20:56<14:33,  5.08s/it, lr=1e-5, step_loss=0.0826]Steps:  57%|█████▋    | 228/400 [20:56<14:33,  5.08s/it, lr=1e-5, step_loss=0.162] Steps:  57%|█████▋    | 229/400 [21:02<15:15,  5.35s/it, lr=1e-5, step_loss=0.162]Steps:  57%|█████▋    | 229/400 [21:02<15:15,  5.35s/it, lr=1e-5, step_loss=0.208]Steps:  57%|█████▊    | 230/400 [21:07<14:35,  5.15s/it, lr=1e-5, step_loss=0.208]Steps:  57%|█████▊    | 230/400 [21:07<14:35,  5.15s/it, lr=1e-5, step_loss=0.104]Steps:  58%|█████▊    | 231/400 [21:12<14:15,  5.06s/it, lr=1e-5, step_loss=0.104]Steps:  58%|█████▊    | 231/400 [21:12<14:15,  5.06s/it, lr=1e-5, step_loss=0.151]Steps:  58%|█████▊    | 232/400 [21:18<14:59,  5.35s/it, lr=1e-5, step_loss=0.151]Steps:  58%|█████▊    | 232/400 [21:18<14:59,  5.35s/it, lr=1e-5, step_loss=0.214]Steps:  58%|█████▊    | 233/400 [21:22<14:20,  5.15s/it, lr=1e00 [21:07<14:35,  5.15s/it, lr=1e-5, step_loss=0.0591]Steps:  58%|█████▊    | 231/400 [21:12<14:15,  5.06s/it, lr=1e-5, step_loss=0.0591]Steps:  58%|█████▊    | 231/400 [21:12<14:15,  5.06s/it, lr=1e-5, step_loss=0.143] Steps:  58%|█████▊    | 232/400 [21:18<14:59,  5.35s/it, lr=1e-5, step_loss=0.143]Steps:  58%|█████▊    | 232/400 [21:18<14:59,  5.35s/it, lr=1e-5, step_loss=0.181]Steps:  58%|█████▊    | 233/400 [21:23<14:20,  5.15s/it, lr=1e-5, step_loss=0.181]Steps:  58%|█████▊    | 233/400 [21:23<14:20,  5.15s/it, lr=1e-5, step_loss=0.159]Steps:  58%|█████▊    | 234/400 [21:28<14:00,  5.06s/it, lr=1e-5, step_loss=0.159]Steps:  58%|█████▊    | 234/400 [21:28<14:00,  5.06s/it, lr=1e-5, step_loss=0.118]Steps:  59%|█████▉    | 235/400 [21:34<14:48,  5.39s/it, lr=1e-5, step_loss=0.118]Steps:  59%|█████▉    | 235/400 [21:34<14:48,  5.39s/it, lr=1e-5, step_loss=0.158]Steps:  59%|█-5, step_loss=0.214]Steps:  58%|█████▊    | 233/400 [21:22<14:20,  5.15s/it, lr=1e-5, step_loss=0.153]Steps:  58%|█████▊    | 234/400 [21:27<14:00,  5.06s/it, lr=1e-5, step_loss=0.153]Steps:  58%|█████▊    | 234/400 [21:27<14:00,  5.06s/it, lr=1e-5, step_loss=0.13] Steps:  59%|█████▉    | 235/400 [21:33<14:48,  5.39s/it, lr=1e-5, step_loss=0.13]Steps:  59%|█████▉    | 235/400 [21:33<14:48,  5.39s/it, lr=1e-5, step_loss=0.15]Steps:  59%|█████▉    | 236/400 [21:38<14:08,  5.17s/it, lr=1e-5, step_loss=0.15]Steps:  59%|█████▉    | 236/400 [21:38<14:08,  5.17s/it, lr=1e-5, step_loss=0.138]Steps:  59%|█████▉    | 237/400 [21:43<13:46,  5.07s/it, lr=1e-5, step_loss=0.138]Steps:  59%|█████▉    | 237/400 [21:43<13:46,  5.07s/it, lr=1e-5, step_loss=0.151]Steps:  60%|█████▉    | 238/400 [21:49<14:29,  5.37s/it, lr=1e-5, step_loss=0.151]Steps:  60%|█████▉    | 238/400 [21:49<14:29███▉    | 236/400 [21:39<14:08,  5.17s/it, lr=1e-5, step_loss=0.158]Steps:  59%|█████▉    | 236/400 [21:39<14:08,  5.17s/it, lr=1e-5, step_loss=0.135]Steps:  59%|█████▉    | 237/400 [21:43<13:46,  5.07s/it, lr=1e-5, step_loss=0.135]Steps:  59%|█████▉    | 237/400 [21:43<13:46,  5.07s/it, lr=1e-5, step_loss=0.161]Steps:  60%|█████▉    | 238/400 [21:49<14:29,  5.37s/it, lr=1e-5, step_loss=0.161]Steps:  60%|█████▉    | 238/400 [21:49<14:29,  5.37s/it, lr=1e-5, step_loss=0.191]Steps:  60%|█████▉    | 239/400 [21:54<13:51,  5.17s/it, lr=1e-5, step_loss=0.191]Steps:  60%|█████▉    | 239/400 [21:54<13:51,  5.17s/it, lr=1e-5, step_loss=0.175]Steps:  60%|██████    | 240/400 [21:59<13:31,  5.07s/it, lr=1e-5, step_loss=0.175]Steps:  60%|██████    | 240/400 [21:59<13:31,  5.07s/it, lr=1e-5, step_loss=0.122]Steps:  60%|██████    | 241/400 [22:05<14:04,  5.31s/it, lr=1e-5, step_loss=0.1,  5.37s/it, lr=1e-5, step_loss=0.14] Steps:  60%|█████▉    | 239/400 [21:53<13:51,  5.17s/it, lr=1e-5, step_loss=0.14]Steps:  60%|█████▉    | 239/400 [21:53<13:51,  5.17s/it, lr=1e-5, step_loss=0.145]Steps:  60%|██████    | 240/400 [21:58<13:31,  5.07s/it, lr=1e-5, step_loss=0.145]Steps:  60%|██████    | 240/400 [21:58<13:31,  5.07s/it, lr=1e-5, step_loss=0.108]Steps:  60%|██████    | 241/400 [22:04<14:04,  5.31s/it, lr=1e-5, step_loss=0.108]Steps:  60%|██████    | 241/400 [22:04<14:04,  5.31s/it, lr=1e-5, step_loss=0.113]Steps:  60%|██████    | 242/400 [22:09<13:28,  5.12s/it, lr=1e-5, step_loss=0.113]Steps:  60%|██████    | 242/400 [22:09<13:28,  5.12s/it, lr=1e-5, step_loss=0.151]Steps:  61%|██████    | 243/400 [22:14<13:10,  5.03s/it, lr=1e-5, step_loss=0.151]Steps:  61%|██████    | 243/400 [22:14<13:10,  5.03s/it, lr=1e-5, step_loss=0.102]Steps:  61%|██████    | 22]Steps:  60%|██████    | 241/400 [22:05<14:04,  5.31s/it, lr=1e-5, step_loss=0.0968]Steps:  60%|██████    | 242/400 [22:10<13:28,  5.12s/it, lr=1e-5, step_loss=0.0968]Steps:  60%|██████    | 242/400 [22:10<13:28,  5.12s/it, lr=1e-5, step_loss=0.136] Steps:  61%|██████    | 243/400 [22:14<13:10,  5.03s/it, lr=1e-5, step_loss=0.136]Steps:  61%|██████    | 243/400 [22:14<13:10,  5.03s/it, lr=1e-5, step_loss=0.0985]Steps:  61%|██████    | 244/400 [22:20<13:52,  5.34s/it, lr=1e-5, step_loss=0.0985]Steps:  61%|██████    | 244/400 [22:20<13:52,  5.34s/it, lr=1e-5, step_loss=0.149] Steps:  61%|██████▏   | 245/400 [22:25<13:16,  5.14s/it, lr=1e-5, step_loss=0.149]Steps:  61%|██████▏   | 245/400 [22:25<13:16,  5.14s/it, lr=1e-5, step_loss=0.225]Steps:  62%|██████▏   | 246/400 [22:30<12:58,  5.05s/it, lr=1e-5, step_loss=0.225]Steps:  62%|██████▏   | 246/400 [22:30<12:58244/400 [22:20<13:52,  5.34s/it, lr=1e-5, step_loss=0.102]Steps:  61%|██████    | 244/400 [22:20<13:52,  5.34s/it, lr=1e-5, step_loss=0.149]Steps:  61%|██████▏   | 245/400 [22:24<13:16,  5.14s/it, lr=1e-5, step_loss=0.149]Steps:  61%|██████▏   | 245/400 [22:24<13:16,  5.14s/it, lr=1e-5, step_loss=0.203]Steps:  62%|██████▏   | 246/400 [22:29<12:57,  5.05s/it, lr=1e-5, step_loss=0.203]Steps:  62%|██████▏   | 246/400 [22:29<12:57,  5.05s/it, lr=1e-5, step_loss=0.137]Steps:  62%|██████▏   | 247/400 [22:35<13:40,  5.36s/it, lr=1e-5, step_loss=0.137]Steps:  62%|██████▏   | 247/400 [22:35<13:40,  5.36s/it, lr=1e-5, step_loss=0.133]Steps:  62%|██████▏   | 248/400 [22:40<13:03,  5.15s/it, lr=1e-5, step_loss=0.133]Steps:  62%|██████▏   | 248/400 [22:40<13:03,  5.15s/it, lr=1e-5, step_loss=0.0819]Steps:  62%|██████▏   | 249/400 [22:44<11:47,  4.69s/it, lr=1e-5, step_loss=0.0,  5.05s/it, lr=1e-5, step_loss=0.114]Steps:  62%|██████▏   | 247/400 [22:36<13:40,  5.36s/it, lr=1e-5, step_loss=0.114]Steps:  62%|██████▏   | 247/400 [22:36<13:40,  5.36s/it, lr=1e-5, step_loss=0.126]Steps:  62%|██████▏   | 248/400 [22:41<13:03,  5.15s/it, lr=1e-5, step_loss=0.126]Steps:  62%|██████▏   | 248/400 [22:41<13:03,  5.15s/it, lr=1e-5, step_loss=0.102]Steps:  62%|██████▏   | 249/400 [22:44<11:47,  4.69s/it, lr=1e-5, step_loss=0.102]Steps:  62%|██████▏   | 249/400 [22:44<11:47,  4.69s/it, lr=1e-5, step_loss=0.2]  Steps:  62%|██████▎   | 250/400 [22:50<12:47,  5.11s/it, lr=1e-5, step_loss=0.2]Steps:  62%|██████▎   | 250/400 [22:50<12:47,  5.11s/it, lr=1e-5, step_loss=0.116]Steps:  63%|██████▎   | 251/400 [22:55<12:22,  4.99s/it, lr=1e-5, step_loss=0.116]Steps:  63%|██████▎   | 251/400 [22:55<12:22,  4.99s/it, lr=1e-5, step_loss=0.0774]Steps:  63%|█819]Steps:  62%|██████▏   | 249/400 [22:44<11:47,  4.69s/it, lr=1e-5, step_loss=0.221] Steps:  62%|██████▎   | 250/400 [22:50<12:47,  5.11s/it, lr=1e-5, step_loss=0.221]Steps:  62%|██████▎   | 250/400 [22:50<12:47,  5.11s/it, lr=1e-5, step_loss=0.146]Steps:  63%|██████▎   | 251/400 [22:54<12:22,  4.99s/it, lr=1e-5, step_loss=0.146]Steps:  63%|██████▎   | 251/400 [22:54<12:22,  4.99s/it, lr=1e-5, step_loss=0.0816]Steps:  63%|██████▎   | 252/400 [22:59<12:11,  4.94s/it, lr=1e-5, step_loss=0.0816]Steps:  63%|██████▎   | 252/400 [22:59<12:11,  4.94s/it, lr=1e-5, step_loss=0.0743]07/03/2024 08:11:51 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:11:51 - INFO - __main__ - removing checkpoints: reference_unet-189.pth
07/03/2024 08:11:56 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:11:56 - INFO - __main__ - removing checkpoints: denoising_unet-189.pth
07/03/2024 08:12:02 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:12:02 - INFO - __main__ - removing checkpoints: pose_guider-189.pth
████▎   | 252/400 [23:00<12:11,  4.94s/it, lr=1e-5, step_loss=0.0774]Steps:  63%|██████▎   | 252/400 [23:00<12:11,  4.94s/it, lr=1e-5, step_loss=0.126] Steps:  63%|██████▎   | 253/400 [23:37<35:37, 14.54s/it, lr=1e-5, step_loss=0.126]Steps:  63%|██████▎   | 253/400 [23:37<35:37, 14.54s/it, lr=1e-5, step_loss=0.0716]Steps:  64%|██████▎   | 254/400 [23:42<28:11, 11.59s/it, lr=1e-5, step_loss=0.0716]Steps:  64%|██████▎   | 254/400 [23:42<28:11, 11.59s/it, lr=1e-5, step_loss=0.104] Steps:  64%|██████▍   | 255/400 [23:46<23:07,  9.57s/it, lr=1e-5, step_loss=0.104]Steps:  64%|██████▍   | 255/400 [23:46<23:07,  9.57s/it, lr=1e-5, step_loss=0.184]Steps:  64%|██████▍   | 256/400 [23:52<20:24,  8.50s/it, lr=1e-5, step_loss=0.184]Steps:  64%|██████▍   | 256/400 [23:52<20:24,  8.50s/it, lr=1e-5, step_loss=0.104]Steps:  64%|██████▍   | 257/400 [23:57<17:31,  7.35Steps:  63%|██████▎   | 253/400 [23:36<35:37, 14.54s/it, lr=1e-5, step_loss=0.0743]Steps:  63%|██████▎   | 253/400 [23:36<35:37, 14.54s/it, lr=1e-5, step_loss=0.056] Steps:  64%|██████▎   | 254/400 [23:41<28:11, 11.59s/it, lr=1e-5, step_loss=0.056]Steps:  64%|██████▎   | 254/400 [23:41<28:11, 11.59s/it, lr=1e-5, step_loss=0.106]Steps:  64%|██████▍   | 255/400 [23:46<23:07,  9.57s/it, lr=1e-5, step_loss=0.106]Steps:  64%|██████▍   | 255/400 [23:46<23:07,  9.57s/it, lr=1e-5, step_loss=0.156]Steps:  64%|██████▍   | 256/400 [23:52<20:24,  8.50s/it, lr=1e-5, step_loss=0.156]Steps:  64%|██████▍   | 256/400 [23:52<20:24,  8.50s/it, lr=1e-5, step_loss=0.108]Steps:  64%|██████▍   | 257/400 [23:56<17:31,  7.35s/it, lr=1e-5, step_loss=0.108]Steps:  64%|██████▍   | 257/400 [23:56<17:31,  7.35s/it, lr=1e-5, step_loss=0.0805]Steps:  64%|██████▍   | 258/400 [24:s/it, lr=1e-5, step_loss=0.104]Steps:  64%|██████▍   | 257/400 [23:57<17:31,  7.35s/it, lr=1e-5, step_loss=0.0586]Steps:  64%|██████▍   | 258/400 [24:01<14:44,  6.23s/it, lr=1e-5, step_loss=0.0586]Steps:  64%|██████▍   | 258/400 [24:01<14:44,  6.23s/it, lr=1e-5, step_loss=0.284] Steps:  65%|██████▍   | 259/400 [24:07<14:28,  6.16s/it, lr=1e-5, step_loss=0.284]Steps:  65%|██████▍   | 259/400 [24:07<14:28,  6.16s/it, lr=1e-5, step_loss=0.101]Steps:  65%|██████▌   | 260/400 [24:11<13:21,  5.72s/it, lr=1e-5, step_loss=0.101]Steps:  65%|██████▌   | 260/400 [24:11<13:21,  5.72s/it, lr=1e-5, step_loss=0.0947]Steps:  65%|██████▌   | 261/400 [24:16<12:39,  5.46s/it, lr=1e-5, step_loss=0.0947]Steps:  65%|██████▌   | 261/400 [24:16<12:39,  5.46s/it, lr=1e-5, step_loss=0.209] Steps:  66%|██████▌   | 262/400 [24:22<13:00,  5.65s/it, lr=1e-5, step_loss=0.209]Steps:  66%|█00<14:44,  6.23s/it, lr=1e-5, step_loss=0.0805]Steps:  64%|██████▍   | 258/400 [24:00<14:44,  6.23s/it, lr=1e-5, step_loss=0.236] Steps:  65%|██████▍   | 259/400 [24:06<14:28,  6.16s/it, lr=1e-5, step_loss=0.236]Steps:  65%|██████▍   | 259/400 [24:06<14:28,  6.16s/it, lr=1e-5, step_loss=0.144]Steps:  65%|██████▌   | 260/400 [24:11<13:21,  5.72s/it, lr=1e-5, step_loss=0.144]Steps:  65%|██████▌   | 260/400 [24:11<13:21,  5.72s/it, lr=1e-5, step_loss=0.0569]Steps:  65%|██████▌   | 261/400 [24:16<12:39,  5.46s/it, lr=1e-5, step_loss=0.0569]Steps:  65%|██████▌   | 261/400 [24:16<12:39,  5.46s/it, lr=1e-5, step_loss=0.231] Steps:  66%|██████▌   | 262/400 [24:22<13:00,  5.65s/it, lr=1e-5, step_loss=0.231]Steps:  66%|██████▌   | 262/400 [24:22<13:00,  5.65s/it, lr=1e-5, step_loss=0.178]Steps:  66%|██████▌   | 263/400 [24:26<12:14,  5.36s/it, lr=1e-5, step_loss=0.178]St████▌   | 262/400 [24:22<13:00,  5.65s/it, lr=1e-5, step_loss=0.185]Steps:  66%|██████▌   | 263/400 [24:27<12:14,  5.36s/it, lr=1e-5, step_loss=0.185]Steps:  66%|██████▌   | 263/400 [24:27<12:14,  5.36s/it, lr=1e-5, step_loss=0.152]Steps:  66%|██████▌   | 264/400 [24:32<11:48,  5.21s/it, lr=1e-5, step_loss=0.152]Steps:  66%|██████▌   | 264/400 [24:32<11:48,  5.21s/it, lr=1e-5, step_loss=0.0759]Steps:  66%|██████▋   | 265/400 [24:38<12:13,  5.43s/it, lr=1e-5, step_loss=0.0759]Steps:  66%|██████▋   | 265/400 [24:38<12:13,  5.43s/it, lr=1e-5, step_loss=0.0666]Steps:  66%|██████▋   | 266/400 [24:43<11:37,  5.21s/it, lr=1e-5, step_loss=0.0666]Steps:  66%|██████▋   | 266/400 [24:43<11:37,  5.21s/it, lr=1e-5, step_loss=0.091] Steps:  67%|██████▋   | 267/400 [24:47<11:18,  5.10s/it, lr=1e-5, step_loss=0.091]Steps:  67%|██████▋   | 267/400 [24:47<11:18,  5.10eps:  66%|██████▌   | 263/400 [24:26<12:14,  5.36s/it, lr=1e-5, step_loss=0.18] Steps:  66%|██████▌   | 264/400 [24:31<11:48,  5.21s/it, lr=1e-5, step_loss=0.18]Steps:  66%|██████▌   | 264/400 [24:31<11:48,  5.21s/it, lr=1e-5, step_loss=0.104]Steps:  66%|██████▋   | 265/400 [24:37<12:13,  5.43s/it, lr=1e-5, step_loss=0.104]Steps:  66%|██████▋   | 265/400 [24:37<12:13,  5.43s/it, lr=1e-5, step_loss=0.0875]Steps:  66%|██████▋   | 266/400 [24:42<11:37,  5.20s/it, lr=1e-5, step_loss=0.0875]Steps:  66%|██████▋   | 266/400 [24:42<11:37,  5.20s/it, lr=1e-5, step_loss=0.118] Steps:  67%|██████▋   | 267/400 [24:47<11:18,  5.10s/it, lr=1e-5, step_loss=0.118]Steps:  67%|██████▋   | 267/400 [24:47<11:18,  5.10s/it, lr=1e-5, step_loss=0.155]Steps:  67%|██████▋   | 268/400 [24:53<11:51,  5.39s/it, lr=1e-5, step_loss=0.155]Steps:  67%|██████▋   | 268/400 [24:53<1s/it, lr=1e-5, step_loss=0.165]Steps:  67%|██████▋   | 268/400 [24:53<11:51,  5.39s/it, lr=1e-5, step_loss=0.165]Steps:  67%|██████▋   | 268/400 [24:53<11:51,  5.39s/it, lr=1e-5, step_loss=0.0713]Steps:  67%|██████▋   | 269/400 [24:58<11:18,  5.18s/it, lr=1e-5, step_loss=0.0713]Steps:  67%|██████▋   | 269/400 [24:58<11:18,  5.18s/it, lr=1e-5, step_loss=0.146] Steps:  68%|██████▊   | 270/400 [25:03<11:00,  5.08s/it, lr=1e-5, step_loss=0.146]Steps:  68%|██████▊   | 270/400 [25:03<11:00,  5.08s/it, lr=1e-5, step_loss=0.072]Steps:  68%|██████▊   | 271/400 [25:09<11:30,  5.35s/it, lr=1e-5, step_loss=0.072]Steps:  68%|██████▊   | 271/400 [25:09<11:30,  5.35s/it, lr=1e-5, step_loss=0.0816]Steps:  68%|██████▊   | 272/400 [25:14<10:59,  5.16s/it, lr=1e-5, step_loss=0.0816]Steps:  68%|██████▊   | 272/400 [25:14<10:59,  5.16s/it, lr=1e-5, step_loss=0.0862]Steps:  68%|█1:51,  5.39s/it, lr=1e-5, step_loss=0.117]Steps:  67%|██████▋   | 269/400 [24:57<11:18,  5.18s/it, lr=1e-5, step_loss=0.117]Steps:  67%|██████▋   | 269/400 [24:58<11:18,  5.18s/it, lr=1e-5, step_loss=0.168]Steps:  68%|██████▊   | 270/400 [25:02<11:00,  5.08s/it, lr=1e-5, step_loss=0.168]Steps:  68%|██████▊   | 270/400 [25:02<11:00,  5.08s/it, lr=1e-5, step_loss=0.0835]Steps:  68%|██████▊   | 271/400 [25:08<11:30,  5.35s/it, lr=1e-5, step_loss=0.0835]Steps:  68%|██████▊   | 271/400 [25:08<11:30,  5.35s/it, lr=1e-5, step_loss=0.0795]Steps:  68%|██████▊   | 272/400 [25:13<10:59,  5.16s/it, lr=1e-5, step_loss=0.0795]Steps:  68%|██████▊   | 272/400 [25:13<10:59,  5.16s/it, lr=1e-5, step_loss=0.0959]Steps:  68%|██████▊   | 273/400 [25:17<09:56,  4.70s/it, lr=1e-5, step_loss=0.0959]Steps:  68%|██████▊   | 273/400 [25:17<09:56,  4.70s/it, lr=1e-5, step_loss=0.201] Step████▊   | 273/400 [25:17<09:56,  4.70s/it, lr=1e-5, step_loss=0.0862]Steps:  68%|██████▊   | 273/400 [25:17<09:56,  4.70s/it, lr=1e-5, step_loss=0.204] Steps:  68%|██████▊   | 274/400 [25:23<10:43,  5.10s/it, lr=1e-5, step_loss=0.204]Steps:  68%|██████▊   | 274/400 [25:23<10:43,  5.10s/it, lr=1e-5, step_loss=0.182]Steps:  69%|██████▉   | 275/400 [25:28<10:22,  4.98s/it, lr=1e-5, step_loss=0.182]Steps:  69%|██████▉   | 275/400 [25:28<10:22,  4.98s/it, lr=1e-5, step_loss=0.134]Steps:  69%|██████▉   | 276/400 [25:33<10:12,  4.94s/it, lr=1e-5, step_loss=0.134]Steps:  69%|██████▉   | 276/400 [25:33<10:12,  4.94s/it, lr=1e-5, step_loss=0.0932]Steps:  69%|██████▉   | 277/400 [25:39<10:41,  5.22s/it, lr=1e-5, step_loss=0.0932]Steps:  69%|██████▉   | 277/400 [25:39<10:41,  5.22s/it, lr=1e-5, step_loss=0.126] Steps:  70%|██████▉   | 278/400 [25:43<10:16,  5.05s:  68%|██████▊   | 274/400 [25:23<10:43,  5.10s/it, lr=1e-5, step_loss=0.201]Steps:  68%|██████▊   | 274/400 [25:23<10:43,  5.10s/it, lr=1e-5, step_loss=0.148]Steps:  69%|██████▉   | 275/400 [25:27<10:22,  4.98s/it, lr=1e-5, step_loss=0.148]Steps:  69%|██████▉   | 275/400 [25:27<10:22,  4.98s/it, lr=1e-5, step_loss=0.129]Steps:  69%|██████▉   | 276/400 [25:32<10:12,  4.94s/it, lr=1e-5, step_loss=0.129]Steps:  69%|██████▉   | 276/400 [25:32<10:12,  4.94s/it, lr=1e-5, step_loss=0.0845]Steps:  69%|██████▉   | 277/400 [25:38<10:41,  5.22s/it, lr=1e-5, step_loss=0.0845]Steps:  69%|██████▉   | 277/400 [25:38<10:41,  5.22s/it, lr=1e-5, step_loss=0.168] Steps:  70%|██████▉   | 278/400 [25:43<10:16,  5.05s/it, lr=1e-5, step_loss=0.168]Steps:  70%|██████▉   | 278/400 [25:43<10:16,  5.05s/it, lr=1e-5, step_loss=0.0549]Steps:  70%|██████▉   | 279/400 [25:48<1s/it, lr=1e-5, step_loss=0.126]Steps:  70%|██████▉   | 278/400 [25:43<10:16,  5.05s/it, lr=1e-5, step_loss=0.0575]Steps:  70%|██████▉   | 279/400 [25:48<10:03,  4.99s/it, lr=1e-5, step_loss=0.0575]Steps:  70%|██████▉   | 279/400 [25:48<10:03,  4.99s/it, lr=1e-5, step_loss=0.182] Steps:  70%|███████   | 280/400 [25:54<10:38,  5.32s/it, lr=1e-5, step_loss=0.182]Steps:  70%|███████   | 280/400 [25:54<10:38,  5.32s/it, lr=1e-5, step_loss=0.0986]Steps:  70%|███████   | 281/400 [25:59<10:09,  5.13s/it, lr=1e-5, step_loss=0.0986]Steps:  70%|███████   | 281/400 [25:59<10:09,  5.13s/it, lr=1e-5, step_loss=0.113] Steps:  70%|███████   | 282/400 [26:04<09:55,  5.04s/it, lr=1e-5, step_loss=0.113]Steps:  70%|███████   | 282/400 [26:04<09:55,  5.04s/it, lr=1e-5, step_loss=0.0986]Steps:  71%|███████   | 283/400 [26:10<10:23,  5.33s/it, lr=1e-5, step_loss=0.0986]Steps:  71%|0:03,  4.99s/it, lr=1e-5, step_loss=0.0549]Steps:  70%|██████▉   | 279/400 [25:48<10:03,  4.99s/it, lr=1e-5, step_loss=0.147] Steps:  70%|███████   | 280/400 [25:54<10:38,  5.32s/it, lr=1e-5, step_loss=0.147]Steps:  70%|███████   | 280/400 [25:54<10:38,  5.32s/it, lr=1e-5, step_loss=0.0871]Steps:  70%|███████   | 281/400 [25:58<10:09,  5.13s/it, lr=1e-5, step_loss=0.0871]Steps:  70%|███████   | 281/400 [25:58<10:09,  5.13s/it, lr=1e-5, step_loss=0.102] Steps:  70%|███████   | 282/400 [26:03<09:55,  5.04s/it, lr=1e-5, step_loss=0.102]Steps:  70%|███████   | 282/400 [26:03<09:55,  5.04s/it, lr=1e-5, step_loss=0.127]Steps:  71%|███████   | 283/400 [26:09<10:23,  5.33s/it, lr=1e-5, step_loss=0.127]Steps:  71%|███████   | 283/400 [26:09<10:23,  5.33s/it, lr=1e-5, step_loss=0.116]Steps:  71%|███████   | 284/400 [26:14<09:56,  5.14s/it, lr=1e-5, step_loss=0.116]Steps:██████   | 283/400 [26:10<10:23,  5.33s/it, lr=1e-5, step_loss=0.126] Steps:  71%|███████   | 284/400 [26:15<09:56,  5.14s/it, lr=1e-5, step_loss=0.126]Steps:  71%|███████   | 284/400 [26:15<09:56,  5.14s/it, lr=1e-5, step_loss=0.106]Steps:  71%|███████▏  | 285/400 [26:19<09:40,  5.05s/it, lr=1e-5, step_loss=0.106]Steps:  71%|███████▏  | 285/400 [26:19<09:40,  5.05s/it, lr=1e-5, step_loss=0.0575]Steps:  72%|███████▏  | 286/400 [26:25<10:07,  5.33s/it, lr=1e-5, step_loss=0.0575]Steps:  72%|███████▏  | 286/400 [26:25<10:07,  5.33s/it, lr=1e-5, step_loss=0.1]   Steps:  72%|███████▏  | 287/400 [26:30<09:40,  5.14s/it, lr=1e-5, step_loss=0.1]Steps:  72%|███████▏  | 287/400 [26:30<09:40,  5.14s/it, lr=1e-5, step_loss=0.168]Steps:  72%|███████▏  | 288/400 [26:35<09:25,  5.05s/it, lr=1e-5, step_loss=0.168]Steps:  72%|███████▏  | 288/400 [26:  71%|███████   | 284/400 [26:14<09:56,  5.14s/it, lr=1e-5, step_loss=0.0786]Steps:  71%|███████▏  | 285/400 [26:19<09:40,  5.05s/it, lr=1e-5, step_loss=0.0786]Steps:  71%|███████▏  | 285/400 [26:19<09:40,  5.05s/it, lr=1e-5, step_loss=0.0484]Steps:  72%|███████▏  | 286/400 [26:25<10:07,  5.33s/it, lr=1e-5, step_loss=0.0484]Steps:  72%|███████▏  | 286/400 [26:25<10:07,  5.33s/it, lr=1e-5, step_loss=0.115] Steps:  72%|███████▏  | 287/400 [26:29<09:40,  5.14s/it, lr=1e-5, step_loss=0.115]Steps:  72%|███████▏  | 287/400 [26:29<09:40,  5.14s/it, lr=1e-5, step_loss=0.192]Steps:  72%|███████▏  | 288/400 [26:34<09:25,  5.05s/it, lr=1e-5, step_loss=0.192]Steps:  72%|███████▏  | 288/400 [26:34<09:25,  5.05s/it, lr=1e-5, step_loss=0.125]Steps:  72%|███████▏  | 289/400 [26:40<09:44,  5.26s/it, lr=1e-5, step_loss=0.125]Steps:  72%|███████▏ 35<09:25,  5.05s/it, lr=1e-5, step_loss=0.164]Steps:  72%|███████▏  | 289/400 [26:41<09:44,  5.26s/it, lr=1e-5, step_loss=0.164]Steps:  72%|███████▏  | 289/400 [26:41<09:44,  5.26s/it, lr=1e-5, step_loss=0.084]Steps:  72%|███████▎  | 290/400 [26:45<09:20,  5.09s/it, lr=1e-5, step_loss=0.084]Steps:  72%|███████▎  | 290/400 [26:45<09:20,  5.09s/it, lr=1e-5, step_loss=0.153]Steps:  73%|███████▎  | 291/400 [26:50<09:07,  5.02s/it, lr=1e-5, step_loss=0.153]Steps:  73%|███████▎  | 291/400 [26:50<09:07,  5.02s/it, lr=1e-5, step_loss=0.0644]Steps:  73%|███████▎  | 292/400 [26:56<09:32,  5.30s/it, lr=1e-5, step_loss=0.0644]Steps:  73%|███████▎  | 292/400 [26:56<09:32,  5.30s/it, lr=1e-5, step_loss=0.0919]Steps:  73%|███████▎  | 293/400 [27:01<09:07,  5.11s/it, lr=1e-5, step_loss=0.0919]Steps:  73%|███████▎  | 293/400 [27:01<09:07,  5.11s/it, lr=1e-5,  | 289/400 [26:40<09:44,  5.26s/it, lr=1e-5, step_loss=0.0685]Steps:  72%|███████▎  | 290/400 [26:45<09:20,  5.09s/it, lr=1e-5, step_loss=0.0685]Steps:  72%|███████▎  | 290/400 [26:45<09:20,  5.09s/it, lr=1e-5, step_loss=0.113] Steps:  73%|███████▎  | 291/400 [26:50<09:07,  5.02s/it, lr=1e-5, step_loss=0.113]Steps:  73%|███████▎  | 291/400 [26:50<09:07,  5.02s/it, lr=1e-5, step_loss=0.0745]Steps:  73%|███████▎  | 292/400 [26:56<09:32,  5.30s/it, lr=1e-5, step_loss=0.0745]Steps:  73%|███████▎  | 292/400 [26:56<09:32,  5.30s/it, lr=1e-5, step_loss=0.0762]Steps:  73%|███████▎  | 293/400 [27:00<09:07,  5.11s/it, lr=1e-5, step_loss=0.0762]Steps:  73%|███████▎  | 293/400 [27:00<09:07,  5.11s/it, lr=1e-5, step_loss=0.118] Steps:  74%|███████▎  | 294/400 [27:05<08:54,  5.04s/it, lr=1e-5, step_loss=0.118]Steps:  74%|███████▎  | 294/400 [27:05<08:54,  step_loss=0.143] Steps:  74%|███████▎  | 294/400 [27:06<08:54,  5.04s/it, lr=1e-5, step_loss=0.143]Steps:  74%|███████▎  | 294/400 [27:06<08:54,  5.04s/it, lr=1e-5, step_loss=0.0783]Steps:  74%|███████▍  | 295/400 [27:12<09:19,  5.33s/it, lr=1e-5, step_loss=0.0783]Steps:  74%|███████▍  | 295/400 [27:12<09:19,  5.33s/it, lr=1e-5, step_loss=0.0823]Steps:  74%|███████▍  | 296/400 [27:16<08:54,  5.14s/it, lr=1e-5, step_loss=0.0823]Steps:  74%|███████▍  | 296/400 [27:16<08:54,  5.14s/it, lr=1e-5, step_loss=0.146] Steps:  74%|███████▍  | 297/400 [27:21<08:40,  5.05s/it, lr=1e-5, step_loss=0.146]Steps:  74%|███████▍  | 297/400 [27:21<08:40,  5.05s/it, lr=1e-5, step_loss=0.11] Steps:  74%|███████▍  | 298/400 [27:27<09:07,  5.36s/it, lr=1e-5, step_loss=0.11]Steps:  74%|███████▍  | 298/400 [27:27<09:07,  5.36s/it, lr=1e-5, step_loss=0.0884]Steps:  75%5.04s/it, lr=1e-5, step_loss=0.111]Steps:  74%|███████▍  | 295/400 [27:11<09:19,  5.33s/it, lr=1e-5, step_loss=0.111]Steps:  74%|███████▍  | 295/400 [27:11<09:19,  5.33s/it, lr=1e-5, step_loss=0.0934]Steps:  74%|███████▍  | 296/400 [27:16<08:54,  5.14s/it, lr=1e-5, step_loss=0.0934]Steps:  74%|███████▍  | 296/400 [27:16<08:54,  5.14s/it, lr=1e-5, step_loss=0.126] Steps:  74%|███████▍  | 297/400 [27:21<08:40,  5.05s/it, lr=1e-5, step_loss=0.126]Steps:  74%|███████▍  | 297/400 [27:21<08:40,  5.05s/it, lr=1e-5, step_loss=0.106]Steps:  74%|███████▍  | 298/400 [27:27<09:07,  5.36s/it, lr=1e-5, step_loss=0.106]Steps:  74%|███████▍  | 298/400 [27:27<09:07,  5.36s/it, lr=1e-5, step_loss=0.107]Steps:  75%|███████▍  | 299/400 [27:31<08:41,  5.16s/it, lr=1e-5, step_loss=0.107]Steps:  75%|███████▍  | 299/400 [27:31<08:41,  5.16s/it, lr=1e-5, step_loss=0.|███████▍  | 299/400 [27:32<08:41,  5.16s/it, lr=1e-5, step_loss=0.0884]Steps:  75%|███████▍  | 299/400 [27:32<08:41,  5.16s/it, lr=1e-5, step_loss=0.0873]Steps:  75%|███████▌  | 300/400 [27:37<08:26,  5.07s/it, lr=1e-5, step_loss=0.0873]Steps:  75%|███████▌  | 300/400 [27:37<08:26,  5.07s/it, lr=1e-5, step_loss=0.0737]Steps:  75%|███████▌  | 301/400 [27:43<08:53,  5.39s/it, lr=1e-5, step_loss=0.0737]Steps:  75%|███████▌  | 301/400 [27:43<08:53,  5.39s/it, lr=1e-5, step_loss=0.0771]Steps:  76%|███████▌  | 302/400 [27:48<08:27,  5.18s/it, lr=1e-5, step_loss=0.0771]Steps:  76%|███████▌  | 302/400 [27:48<08:27,  5.18s/it, lr=1e-5, step_loss=0.0898]Steps:  76%|███████▌  | 303/400 [27:53<08:12,  5.08s/it, lr=1e-5, step_loss=0.0898]Steps:  76%|███████▌  | 303/400 [27:53<08:12,  5.08s/it, lr=1e-5, step_loss=0.133] Steps:  76%|███████0567]Steps:  75%|███████▌  | 300/400 [27:36<08:26,  5.07s/it, lr=1e-5, step_loss=0.0567]Steps:  75%|███████▌  | 300/400 [27:36<08:26,  5.07s/it, lr=1e-5, step_loss=0.0701]Steps:  75%|███████▌  | 301/400 [27:42<08:53,  5.39s/it, lr=1e-5, step_loss=0.0701]Steps:  75%|███████▌  | 301/400 [27:42<08:53,  5.39s/it, lr=1e-5, step_loss=0.0779]Steps:  76%|███████▌  | 302/400 [27:47<08:27,  5.18s/it, lr=1e-5, step_loss=0.0779]Steps:  76%|███████▌  | 302/400 [27:47<08:27,  5.18s/it, lr=1e-5, step_loss=0.0975]Steps:  76%|███████▌  | 303/400 [27:52<08:12,  5.08s/it, lr=1e-5, step_loss=0.0975]Steps:  76%|███████▌  | 303/400 [27:52<08:12,  5.08s/it, lr=1e-5, step_loss=0.143] Steps:  76%|███████▌  | 304/400 [27:58<08:30,  5.32s/it, lr=1e-5, step_loss=0.143]Steps:  76%|███████▌  | 304/400 [27:58<08:30,  5.32s/it, lr=1e-5, step_loss=0.105]Steps:  76%|██▌  | 304/400 [27:59<08:30,  5.32s/it, lr=1e-5, step_loss=0.133]Steps:  76%|███████▌  | 304/400 [27:59<08:30,  5.32s/it, lr=1e-5, step_loss=0.0884]Steps:  76%|███████▋  | 305/400 [28:03<08:07,  5.13s/it, lr=1e-5, step_loss=0.0884]Steps:  76%|███████▋  | 305/400 [28:03<08:07,  5.13s/it, lr=1e-5, step_loss=0.118] Steps:  76%|███████▋  | 306/400 [28:08<07:54,  5.05s/it, lr=1e-5, step_loss=0.118]Steps:  76%|███████▋  | 306/400 [28:08<07:54,  5.05s/it, lr=1e-5, step_loss=0.0796]Steps:  77%|███████▋  | 307/400 [28:14<08:14,  5.32s/it, lr=1e-5, step_loss=0.0796]Steps:  77%|███████▋  | 307/400 [28:14<08:14,  5.32s/it, lr=1e-5, step_loss=0.126] Steps:  77%|███████▋  | 308/400 [28:19<07:51,  5.13s/it, lr=1e-5, step_loss=0.126]Steps:  77%|███████▋  | 308/400 [28:19<07:51,  5.13s/it, lr=1e-5, step_loss=0.108]Steps:  77%|███████▋  | 309/400 [28:24<07:38,  ████▋  | 305/400 [28:03<08:07,  5.13s/it, lr=1e-5, step_loss=0.105]Steps:  76%|███████▋  | 305/400 [28:03<08:07,  5.13s/it, lr=1e-5, step_loss=0.101]Steps:  76%|███████▋  | 306/400 [28:07<07:54,  5.05s/it, lr=1e-5, step_loss=0.101]Steps:  76%|███████▋  | 306/400 [28:07<07:54,  5.05s/it, lr=1e-5, step_loss=0.081]Steps:  77%|███████▋  | 307/400 [28:13<08:14,  5.32s/it, lr=1e-5, step_loss=0.081]Steps:  77%|███████▋  | 307/400 [28:13<08:14,  5.32s/it, lr=1e-5, step_loss=0.108]Steps:  77%|███████▋  | 308/400 [28:18<07:51,  5.13s/it, lr=1e-5, step_loss=0.108]Steps:  77%|███████▋  | 308/400 [28:18<07:51,  5.13s/it, lr=1e-5, step_loss=0.083]Steps:  77%|███████▋  | 309/400 [28:23<07:38,  5.04s/it, lr=1e-5, step_loss=0.083]Steps:  77%|███████▋  | 309/400 [28:23<07:38,  5.04s/it, lr=1e-5, step_loss=0.0803]Steps:  78%|███████▊  | 310/400 [28:25.04s/it, lr=1e-5, step_loss=0.108]Steps:  77%|███████▋  | 309/400 [28:24<07:38,  5.04s/it, lr=1e-5, step_loss=0.134]Steps:  78%|███████▊  | 310/400 [28:30<07:59,  5.32s/it, lr=1e-5, step_loss=0.134]Steps:  78%|███████▊  | 310/400 [28:30<07:59,  5.32s/it, lr=1e-5, step_loss=0.0923]Steps:  78%|███████▊  | 311/400 [28:34<07:36,  5.13s/it, lr=1e-5, step_loss=0.0923]Steps:  78%|███████▊  | 311/400 [28:34<07:36,  5.13s/it, lr=1e-5, step_loss=0.0858]Steps:  78%|███████▊  | 312/400 [28:39<07:23,  5.04s/it, lr=1e-5, step_loss=0.0858]Steps:  78%|███████▊  | 312/400 [28:39<07:23,  5.04s/it, lr=1e-5, step_loss=0.143] Steps:  78%|███████▊  | 313/400 [28:45<07:43,  5.32s/it, lr=1e-5, step_loss=0.143]Steps:  78%|███████▊  | 313/400 [28:45<07:43,  5.32s/it, lr=1e-5, step_loss=0.0887]Steps:  78%|███████▊  | 314/400 [28:50<07:20,  5.13s/it, lr=1e-5, step_loss9<07:59,  5.32s/it, lr=1e-5, step_loss=0.0803]Steps:  78%|███████▊  | 310/400 [28:29<07:59,  5.32s/it, lr=1e-5, step_loss=0.0916]Steps:  78%|███████▊  | 311/400 [28:33<07:36,  5.13s/it, lr=1e-5, step_loss=0.0916]Steps:  78%|███████▊  | 311/400 [28:33<07:36,  5.13s/it, lr=1e-5, step_loss=0.0763]Steps:  78%|███████▊  | 312/400 [28:38<07:23,  5.04s/it, lr=1e-5, step_loss=0.0763]Steps:  78%|███████▊  | 312/400 [28:38<07:23,  5.04s/it, lr=1e-5, step_loss=0.149] Steps:  78%|███████▊  | 313/400 [28:44<07:43,  5.32s/it, lr=1e-5, step_loss=0.149]Steps:  78%|███████▊  | 313/400 [28:44<07:43,  5.32s/it, lr=1e-5, step_loss=0.0903]Steps:  78%|███████▊  | 314/400 [28:49<07:20,  5.13s/it, lr=1e-5, step_loss=0.0903]Steps:  78%|███████▊  | 314/400 [28:49<07:20,  5.13s/it, lr=1e-5, step_loss=0.0842]Steps:  79%|███████▉  | 315/400 [28:54<07:08,  5.04s/it, lr=1e-5, step_loss=0.0842]Steps:  79%|███████▉  | 315/400 [28:54<07:08,  5.04s/it, lr=1e-5, step_loss=0.0831]07/03/2024 08:17:45 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:17:45 - INFO - __main__ - removing checkpoints: reference_unet-252.pth
07/03/2024 08:17:50 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:17:50 - INFO - __main__ - removing checkpoints: denoising_unet-252.pth
07/03/2024 08:17:57 - INFO - __main__ - 3 checkpoints already exist, removing 1 checkpoints
07/03/2024 08:17:57 - INFO - __main__ - removing checkpoints: pose_guider-252.pth
=0.0887]Steps:  78%|███████▊  | 314/400 [28:50<07:20,  5.13s/it, lr=1e-5, step_loss=0.0743]Steps:  79%|███████▉  | 315/400 [28:55<07:08,  5.04s/it, lr=1e-5, step_loss=0.0743]Steps:  79%|███████▉  | 315/400 [28:55<07:08,  5.04s/it, lr=1e-5, step_loss=0.0869]Steps:  79%|███████▉  | 316/400 [29:35<21:59, 15.71s/it, lr=1e-5, step_loss=0.0869]Steps:  79%|███████▉  | 316/400 [29:35<21:59, 15.71s/it, lr=1e-5, step_loss=0.124] Steps:  79%|███████▉  | 317/400 [29:39<16:38, 12.03s/it, lr=1e-5, step_loss=0.124]Steps:  79%|███████▉  | 317/400 [29:39<16:38, 12.03s/it, lr=1e-5, step_loss=0.192]Steps:  80%|███████▉  | 318/400 [29:42<12:59,  9.50s/it, lr=1e-5, step_loss=0.192]Steps:  80%|███████▉  | 318/400 [29:42<12:59,  9.50s/it, lr=1e-5, step_loss=0.116]Steps:  80%|███████▉  | 319/400 [29:48<11:26,  8.48s/it, lr=1e-5, step_loss=0.116]Steps:  80%|██Steps:  79%|███████▉  | 316/400 [29:34<21:59, 15.71s/it, lr=1e-5, step_loss=0.0831]Steps:  79%|███████▉  | 316/400 [29:34<21:59, 15.71s/it, lr=1e-5, step_loss=0.161] Steps:  79%|███████▉  | 317/400 [29:38<16:38, 12.03s/it, lr=1e-5, step_loss=0.161]Steps:  79%|███████▉  | 317/400 [29:38<16:38, 12.03s/it, lr=1e-5, step_loss=0.223]Steps:  80%|███████▉  | 318/400 [29:41<12:59,  9.50s/it, lr=1e-5, step_loss=0.223]Steps:  80%|███████▉  | 318/400 [29:41<12:59,  9.50s/it, lr=1e-5, step_loss=0.112]Steps:  80%|███████▉  | 319/400 [29:48<11:26,  8.48s/it, lr=1e-5, step_loss=0.112]Steps:  80%|███████▉  | 319/400 [29:48<11:26,  8.48s/it, lr=1e-5, step_loss=0.0807]Steps:  80%|████████  | 320/400 [29:52<09:47,  7.34s/it, lr=1e-5, step_loss=0.0807]Steps:  80%|████████  | 320/400 [29:52<09:47,  7.34s/it, lr=1e-5, step_loss=0.0835]Steps:  80%|█████████▉  | 319/400 [29:48<11:26,  8.48s/it, lr=1e-5, step_loss=0.11] Steps:  80%|████████  | 320/400 [29:53<09:47,  7.34s/it, lr=1e-5, step_loss=0.11]Steps:  80%|████████  | 320/400 [29:53<09:47,  7.34s/it, lr=1e-5, step_loss=0.118]Steps:  80%|████████  | 321/400 [29:58<08:40,  6.59s/it, lr=1e-5, step_loss=0.118]Steps:  80%|████████  | 321/400 [29:58<08:40,  6.59s/it, lr=1e-5, step_loss=0.0974]Steps:  80%|████████  | 322/400 [30:04<08:22,  6.44s/it, lr=1e-5, step_loss=0.0974]Steps:  80%|████████  | 322/400 [30:04<08:22,  6.44s/it, lr=1e-5, step_loss=0.094] Steps:  81%|████████  | 323/400 [30:09<07:35,  5.91s/it, lr=1e-5, step_loss=0.094]Steps:  81%|████████  | 323/400 [30:09<07:35,  5.91s/it, lr=1e-5, step_loss=0.0853]Steps:  81%|████████  | 324/400 [30:13<07:05,  5.59s/it, lr=1e-5, step_loss=0.0853]Steps:  81%|████████  | 324/400 [3██  | 321/400 [29:57<08:40,  6.59s/it, lr=1e-5, step_loss=0.0835]Steps:  80%|████████  | 321/400 [29:57<08:40,  6.59s/it, lr=1e-5, step_loss=0.104] Steps:  80%|████████  | 322/400 [30:03<08:22,  6.44s/it, lr=1e-5, step_loss=0.104]Steps:  80%|████████  | 322/400 [30:03<08:22,  6.44s/it, lr=1e-5, step_loss=0.12] Steps:  81%|████████  | 323/400 [30:08<07:35,  5.91s/it, lr=1e-5, step_loss=0.12]Steps:  81%|████████  | 323/400 [30:08<07:35,  5.91s/it, lr=1e-5, step_loss=0.062]Steps:  81%|████████  | 324/400 [30:13<07:05,  5.59s/it, lr=1e-5, step_loss=0.062]Steps:  81%|████████  | 324/400 [30:13<07:05,  5.59s/it, lr=1e-5, step_loss=0.113]Steps:  81%|████████▏ | 325/400 [30:19<07:11,  5.75s/it, lr=1e-5, step_loss=0.113]Steps:  81%|████████▏ | 325/400 [30:19<07:11,  5.75s/it, lr=1e-5, step_loss=0.077]Steps:  82%|████████▏ | 326/400 [30:24<0:13<07:05,  5.59s/it, lr=1e-5, step_loss=0.106] Steps:  81%|████████▏ | 325/400 [30:20<07:11,  5.75s/it, lr=1e-5, step_loss=0.106]Steps:  81%|████████▏ | 325/400 [30:20<07:11,  5.75s/it, lr=1e-5, step_loss=0.0565]Steps:  82%|████████▏ | 326/400 [30:24<06:42,  5.43s/it, lr=1e-5, step_loss=0.0565]Steps:  82%|████████▏ | 326/400 [30:24<06:42,  5.43s/it, lr=1e-5, step_loss=0.0844]Steps:  82%|████████▏ | 327/400 [30:29<06:23,  5.25s/it, lr=1e-5, step_loss=0.0844]Steps:  82%|████████▏ | 327/400 [30:29<06:23,  5.25s/it, lr=1e-5, step_loss=0.0985]Steps:  82%|████████▏ | 328/400 [30:35<06:36,  5.51s/it, lr=1e-5, step_loss=0.0985]Steps:  82%|████████▏ | 328/400 [30:35<06:36,  5.51s/it, lr=1e-5, step_loss=0.0665]Steps:  82%|████████▏ | 329/400 [30:40<06:13,  5.26s/it, lr=1e-5, step_loss=0.0665]Steps:  82%|████████▏ | 329/400 [30:40<06:42,  5.43s/it, lr=1e-5, step_loss=0.077]Steps:  82%|████████▏ | 326/400 [30:24<06:42,  5.43s/it, lr=1e-5, step_loss=0.0821]Steps:  82%|████████▏ | 327/400 [30:28<06:23,  5.25s/it, lr=1e-5, step_loss=0.0821]Steps:  82%|████████▏ | 327/400 [30:28<06:23,  5.25s/it, lr=1e-5, step_loss=0.139] Steps:  82%|████████▏ | 328/400 [30:34<06:36,  5.51s/it, lr=1e-5, step_loss=0.139]Steps:  82%|████████▏ | 328/400 [30:34<06:36,  5.51s/it, lr=1e-5, step_loss=0.0722]Steps:  82%|████████▏ | 329/400 [30:39<06:13,  5.26s/it, lr=1e-5, step_loss=0.0722]Steps:  82%|████████▏ | 329/400 [30:39<06:13,  5.26s/it, lr=1e-5, step_loss=0.054] Steps:  82%|████████▎ | 330/400 [30:44<05:59,  5.14s/it, lr=1e-5, step_loss=0.054]Steps:  82%|████████▎ | 330/400 [30:44<05:59,  5.14s/it, lr=1e-5, step_loss=0.0988]Steps:  83%|████████▎ | 331/400 [30:50<06:13, 06:13,  5.26s/it, lr=1e-5, step_loss=0.0908]Steps:  82%|████████▎ | 330/400 [30:45<05:59,  5.14s/it, lr=1e-5, step_loss=0.0908]Steps:  82%|████████▎ | 330/400 [30:45<05:59,  5.14s/it, lr=1e-5, step_loss=0.0704]Steps:  83%|████████▎ | 331/400 [30:51<06:13,  5.42s/it, lr=1e-5, step_loss=0.0704]Steps:  83%|████████▎ | 331/400 [30:51<06:13,  5.42s/it, lr=1e-5, step_loss=0.0791]Steps:  83%|████████▎ | 332/400 [30:55<05:53,  5.19s/it, lr=1e-5, step_loss=0.0791]Steps:  83%|████████▎ | 332/400 [30:55<05:53,  5.19s/it, lr=1e-5, step_loss=0.0636]Steps:  83%|████████▎ | 333/400 [31:00<05:41,  5.09s/it, lr=1e-5, step_loss=0.0636]Steps:  83%|████████▎ | 333/400 [31:00<05:41,  5.09s/it, lr=1e-5, step_loss=0.086] Steps:  84%|████████▎ | 334/400 [31:06<05:53,  5.35s/it, lr=1e-5, step_loss=0.086]Steps:  84%|████████▎ | 334/400 [31:06<05:53 5.42s/it, lr=1e-5, step_loss=0.0988]Steps:  83%|████████▎ | 331/400 [30:50<06:13,  5.42s/it, lr=1e-5, step_loss=0.0598]Steps:  83%|████████▎ | 332/400 [30:55<05:53,  5.19s/it, lr=1e-5, step_loss=0.0598]Steps:  83%|████████▎ | 332/400 [30:55<05:53,  5.19s/it, lr=1e-5, step_loss=0.0676]Steps:  83%|████████▎ | 333/400 [31:00<05:41,  5.09s/it, lr=1e-5, step_loss=0.0676]Steps:  83%|████████▎ | 333/400 [31:00<05:41,  5.09s/it, lr=1e-5, step_loss=0.0898]Steps:  84%|████████▎ | 334/400 [31:06<05:53,  5.35s/it, lr=1e-5, step_loss=0.0898]Steps:  84%|████████▎ | 334/400 [31:06<05:53,  5.35s/it, lr=1e-5, step_loss=0.0578]Steps:  84%|████████▍ | 335/400 [31:09<05:10,  4.78s/it, lr=1e-5, step_loss=0.0578]Steps:  84%|████████▍ | 335/400 [31:09<05:10,  4.78s/it, lr=1e-5, step_loss=0.388] Steps:  84%|████████▍ | 336/400 [31:14<05:06,  4.8,  5.35s/it, lr=1e-5, step_loss=0.0915]Steps:  84%|████████▍ | 335/400 [31:10<05:10,  4.78s/it, lr=1e-5, step_loss=0.0915]Steps:  84%|████████▍ | 335/400 [31:10<05:10,  4.78s/it, lr=1e-5, step_loss=0.287] Steps:  84%|████████▍ | 336/400 [31:15<05:07,  4.80s/it, lr=1e-5, step_loss=0.287]Steps:  84%|████████▍ | 336/400 [31:15<05:07,  4.80s/it, lr=1e-5, step_loss=0.114]Steps:  84%|████████▍ | 337/400 [31:21<05:26,  5.18s/it, lr=1e-5, step_loss=0.114]Steps:  84%|████████▍ | 337/400 [31:21<05:26,  5.18s/it, lr=1e-5, step_loss=0.0815]Steps:  84%|████████▍ | 338/400 [31:25<05:12,  5.04s/it, lr=1e-5, step_loss=0.0815]Steps:  84%|████████▍ | 338/400 [31:25<05:12,  5.04s/it, lr=1e-5, step_loss=0.0689]Steps:  85%|████████▍ | 339/400 [31:29<04:41,  4.61s/it, lr=1e-5, step_loss=0.0689]Steps:  85%|████████▍ | 339/400 [31:29<04:41,  4.610s/it, lr=1e-5, step_loss=0.388]Steps:  84%|████████▍ | 336/400 [31:14<05:06,  4.80s/it, lr=1e-5, step_loss=0.0865]Steps:  84%|████████▍ | 337/400 [31:20<05:26,  5.18s/it, lr=1e-5, step_loss=0.0865]Steps:  84%|████████▍ | 337/400 [31:20<05:26,  5.18s/it, lr=1e-5, step_loss=0.063] Steps:  84%|████████▍ | 338/400 [31:25<05:12,  5.04s/it, lr=1e-5, step_loss=0.063]Steps:  84%|████████▍ | 338/400 [31:25<05:12,  5.04s/it, lr=1e-5, step_loss=0.0644]Steps:  85%|████████▍ | 339/400 [31:28<04:41,  4.61s/it, lr=1e-5, step_loss=0.0644]Steps:  85%|████████▍ | 339/400 [31:28<04:41,  4.61s/it, lr=1e-5, step_loss=0.0728]Steps:  85%|████████▌ | 340/400 [31:33<04:41,  4.69s/it, lr=1e-5, step_loss=0.0728]Steps:  85%|████████▌ | 340/400 [31:33<04:41,  4.69s/it, lr=1e-5, step_loss=0.067] Steps:  85%|████████▌ | 341/400 [31:38<04:36,  4.69s/it,s/it, lr=1e-5, step_loss=0.0906]Steps:  85%|████████▌ | 340/400 [31:34<04:41,  4.69s/it, lr=1e-5, step_loss=0.0906]Steps:  85%|████████▌ | 340/400 [31:34<04:41,  4.69s/it, lr=1e-5, step_loss=0.1]   Steps:  85%|████████▌ | 341/400 [31:38<04:36,  4.69s/it, lr=1e-5, step_loss=0.1]Steps:  85%|████████▌ | 341/400 [31:38<04:36,  4.69s/it, lr=1e-5, step_loss=0.0517]Steps:  86%|████████▌ | 342/400 [31:43<04:34,  4.73s/it, lr=1e-5, step_loss=0.0517]Steps:  86%|████████▌ | 342/400 [31:43<04:34,  4.73s/it, lr=1e-5, step_loss=0.156] Steps:  86%|████████▌ | 343/400 [31:49<04:52,  5.13s/it, lr=1e-5, step_loss=0.156]Steps:  86%|████████▌ | 343/400 [31:49<04:52,  5.13s/it, lr=1e-5, step_loss=0.127]Steps:  86%|████████▌ | 344/400 [31:54<04:39,  4.99s/it, lr=1e-5, step_loss=0.127]Steps:  86%|████████▌ | 344/400 [31:54<04:39,  4.99s/it, lr=1 lr=1e-5, step_loss=0.067]Steps:  85%|████████▌ | 341/400 [31:38<04:36,  4.69s/it, lr=1e-5, step_loss=0.0548]Steps:  86%|████████▌ | 342/400 [31:43<04:34,  4.73s/it, lr=1e-5, step_loss=0.0548]Steps:  86%|████████▌ | 342/400 [31:43<04:34,  4.73s/it, lr=1e-5, step_loss=0.121] Steps:  86%|████████▌ | 343/400 [31:49<04:52,  5.13s/it, lr=1e-5, step_loss=0.121]Steps:  86%|████████▌ | 343/400 [31:49<04:52,  5.13s/it, lr=1e-5, step_loss=0.0909]Steps:  86%|████████▌ | 344/400 [31:53<04:39,  4.99s/it, lr=1e-5, step_loss=0.0909]Steps:  86%|████████▌ | 344/400 [31:53<04:39,  4.99s/it, lr=1e-5, step_loss=0.0709]Steps:  86%|████████▋ | 345/400 [31:58<04:32,  4.95s/it, lr=1e-5, step_loss=0.0709]Steps:  86%|████████▋ | 345/400 [31:58<04:32,  4.95s/it, lr=1e-5, step_loss=0.0858]Steps:  86%|████████▋ | 346/400 [32:04<04:43,  5.25s/it, lr=1ee-5, step_loss=0.0851]Steps:  86%|████████▋ | 345/400 [31:59<04:32,  4.95s/it, lr=1e-5, step_loss=0.0851]Steps:  86%|████████▋ | 345/400 [31:59<04:32,  4.95s/it, lr=1e-5, step_loss=0.0844]Steps:  86%|████████▋ | 346/400 [32:05<04:43,  5.25s/it, lr=1e-5, step_loss=0.0844]Steps:  86%|████████▋ | 346/400 [32:05<04:43,  5.25s/it, lr=1e-5, step_loss=0.0705]Steps:  87%|████████▋ | 347/400 [32:10<04:29,  5.08s/it, lr=1e-5, step_loss=0.0705]Steps:  87%|████████▋ | 347/400 [32:10<04:29,  5.08s/it, lr=1e-5, step_loss=0.118] Steps:  87%|████████▋ | 348/400 [32:13<04:01,  4.64s/it, lr=1e-5, step_loss=0.118]Steps:  87%|████████▋ | 348/400 [32:13<04:01,  4.64s/it, lr=1e-5, step_loss=0.142]Steps:  87%|████████▋ | 349/400 [32:19<04:15,  5.01s/it, lr=1e-5, step_loss=0.142]Steps:  87%|████████▋ | 349/400 [32:19<04:15,  5.01s/it, lr=1e-5, st-5, step_loss=0.0858]Steps:  86%|████████▋ | 346/400 [32:04<04:43,  5.25s/it, lr=1e-5, step_loss=0.077] Steps:  87%|████████▋ | 347/400 [32:09<04:29,  5.08s/it, lr=1e-5, step_loss=0.077]Steps:  87%|████████▋ | 347/400 [32:09<04:29,  5.08s/it, lr=1e-5, step_loss=0.0778]Steps:  87%|████████▋ | 348/400 [32:12<04:01,  4.64s/it, lr=1e-5, step_loss=0.0778]Steps:  87%|████████▋ | 348/400 [32:12<04:01,  4.64s/it, lr=1e-5, step_loss=0.18]  Steps:  87%|████████▋ | 349/400 [32:18<04:15,  5.01s/it, lr=1e-5, step_loss=0.18]Steps:  87%|████████▋ | 349/400 [32:18<04:15,  5.01s/it, lr=1e-5, step_loss=0.0572]Steps:  88%|████████▊ | 350/400 [32:23<04:05,  4.92s/it, lr=1e-5, step_loss=0.0572]Steps:  88%|████████▊ | 350/400 [32:23<04:05,  4.92s/it, lr=1e-5, step_loss=0.0594]Steps:  88%|████████▊ | 351/400 [32:28<03:59,  4.90s/it, lr=1e-5, steep_loss=0.0773]Steps:  88%|████████▊ | 350/400 [32:24<04:05,  4.92s/it, lr=1e-5, step_loss=0.0773]Steps:  88%|████████▊ | 350/400 [32:24<04:05,  4.92s/it, lr=1e-5, step_loss=0.0847]Steps:  88%|████████▊ | 351/400 [32:29<03:59,  4.90s/it, lr=1e-5, step_loss=0.0847]Steps:  88%|████████▊ | 351/400 [32:29<03:59,  4.90s/it, lr=1e-5, step_loss=0.0899]Steps:  88%|████████▊ | 352/400 [32:35<04:12,  5.26s/it, lr=1e-5, step_loss=0.0899]Steps:  88%|████████▊ | 352/400 [32:35<04:12,  5.26s/it, lr=1e-5, step_loss=0.0555]Steps:  88%|████████▊ | 353/400 [32:39<03:59,  5.09s/it, lr=1e-5, step_loss=0.0555]Steps:  88%|████████▊ | 353/400 [32:39<03:59,  5.09s/it, lr=1e-5, step_loss=0.0976]Steps:  88%|████████▊ | 354/400 [32:44<03:50,  5.01s/it, lr=1e-5, step_loss=0.0976]Steps:  88%|████████▊ | 354/400 [32:44<03:50,  5.01s/it, lr=1e-5, step_lp_loss=0.0594]Steps:  88%|████████▊ | 351/400 [32:28<03:59,  4.90s/it, lr=1e-5, step_loss=0.121] Steps:  88%|████████▊ | 352/400 [32:34<04:12,  5.26s/it, lr=1e-5, step_loss=0.121]Steps:  88%|████████▊ | 352/400 [32:34<04:12,  5.26s/it, lr=1e-5, step_loss=0.0595]Steps:  88%|████████▊ | 353/400 [32:39<03:59,  5.09s/it, lr=1e-5, step_loss=0.0595]Steps:  88%|████████▊ | 353/400 [32:39<03:59,  5.09s/it, lr=1e-5, step_loss=0.122] Steps:  88%|████████▊ | 354/400 [32:43<03:50,  5.01s/it, lr=1e-5, step_loss=0.122]Steps:  88%|████████▊ | 354/400 [32:44<03:50,  5.01s/it, lr=1e-5, step_loss=0.0854]Steps:  89%|████████▉ | 355/400 [32:49<03:56,  5.25s/it, lr=1e-5, step_loss=0.0854]Steps:  89%|████████▉ | 355/400 [32:49<03:56,  5.25s/it, lr=1e-5, step_loss=0.0427]Steps:  89%|████████▉ | 356/400 [32:54<03:43,  5.08s/it, lr=1e-5, step_lossoss=0.0891]Steps:  89%|████████▉ | 355/400 [32:50<03:56,  5.25s/it, lr=1e-5, step_loss=0.0891]Steps:  89%|████████▉ | 355/400 [32:50<03:56,  5.25s/it, lr=1e-5, step_loss=0.0787]Steps:  89%|████████▉ | 356/400 [32:55<03:43,  5.08s/it, lr=1e-5, step_loss=0.0787]Steps:  89%|████████▉ | 356/400 [32:55<03:43,  5.08s/it, lr=1e-5, step_loss=0.0938]Steps:  89%|████████▉ | 357/400 [33:00<03:35,  5.01s/it, lr=1e-5, step_loss=0.0938]Steps:  89%|████████▉ | 357/400 [33:00<03:35,  5.01s/it, lr=1e-5, step_loss=0.0602]Steps:  90%|████████▉ | 358/400 [33:06<03:44,  5.34s/it, lr=1e-5, step_loss=0.0602]Steps:  90%|████████▉ | 358/400 [33:06<03:44,  5.34s/it, lr=1e-5, step_loss=0.074] Steps:  90%|████████▉ | 359/400 [33:10<03:30,  5.15s/it, lr=1e-5, step_loss=0.074]Steps:  90%|████████▉ | 359/400 [33:10<03:30,  5.15s/it, lr=1e-5, step_loss=0=0.0427]Steps:  89%|████████▉ | 356/400 [32:54<03:43,  5.08s/it, lr=1e-5, step_loss=0.0643]Steps:  89%|████████▉ | 357/400 [32:59<03:35,  5.01s/it, lr=1e-5, step_loss=0.0643]Steps:  89%|████████▉ | 357/400 [32:59<03:35,  5.01s/it, lr=1e-5, step_loss=0.0843]Steps:  90%|████████▉ | 358/400 [33:05<03:44,  5.34s/it, lr=1e-5, step_loss=0.0843]Steps:  90%|████████▉ | 358/400 [33:05<03:44,  5.34s/it, lr=1e-5, step_loss=0.0592]Steps:  90%|████████▉ | 359/400 [33:10<03:30,  5.15s/it, lr=1e-5, step_loss=0.0592]Steps:  90%|████████▉ | 359/400 [33:10<03:30,  5.15s/it, lr=1e-5, step_loss=0.148] Steps:  90%|█████████ | 360/400 [33:14<03:22,  5.05s/it, lr=1e-5, step_loss=0.148]Steps:  90%|█████████ | 360/400 [33:14<03:22,  5.05s/it, lr=1e-5, step_loss=0.0479]Steps:  90%|█████████ | 361/400 [33:21<03:31,  5.41s/it, lr=1e-5, step_loss=0.04.108]Steps:  90%|█████████ | 360/400 [33:15<03:22,  5.05s/it, lr=1e-5, step_loss=0.108]Steps:  90%|█████████ | 360/400 [33:15<03:22,  5.05s/it, lr=1e-5, step_loss=0.0354]Steps:  90%|█████████ | 361/400 [33:21<03:31,  5.41s/it, lr=1e-5, step_loss=0.0354]Steps:  90%|█████████ | 361/400 [33:21<03:31,  5.41s/it, lr=1e-5, step_loss=0.0606]Steps:  90%|█████████ | 362/400 [33:26<03:17,  5.20s/it, lr=1e-5, step_loss=0.0606]Steps:  90%|█████████ | 362/400 [33:26<03:17,  5.20s/it, lr=1e-5, step_loss=0.0625]Steps:  91%|█████████ | 363/400 [33:31<03:08,  5.09s/it, lr=1e-5, step_loss=0.0625]Steps:  91%|█████████ | 363/400 [33:31<03:08,  5.09s/it, lr=1e-5, step_loss=0.0994]Steps:  91%|█████████ | 364/400 [33:37<03:12,  5.35s/it, lr=1e-5, step_loss=0.0994]Steps:  91%|█████████ | 364/400 [33:37<03:12,  5.35s/it, lr=1e-5, step_loss=0.0591]79]Steps:  90%|█████████ | 361/400 [33:21<03:31,  5.41s/it, lr=1e-5, step_loss=0.0416]Steps:  90%|█████████ | 362/400 [33:25<03:17,  5.20s/it, lr=1e-5, step_loss=0.0416]Steps:  90%|█████████ | 362/400 [33:25<03:17,  5.20s/it, lr=1e-5, step_loss=0.0472]Steps:  91%|█████████ | 363/400 [33:30<03:08,  5.09s/it, lr=1e-5, step_loss=0.0472]Steps:  91%|█████████ | 363/400 [33:30<03:08,  5.09s/it, lr=1e-5, step_loss=0.0904]Steps:  91%|█████████ | 364/400 [33:36<03:12,  5.35s/it, lr=1e-5, step_loss=0.0904]Steps:  91%|█████████ | 364/400 [33:36<03:12,  5.35s/it, lr=1e-5, step_loss=0.105] Steps:  91%|█████████▏| 365/400 [33:41<03:00,  5.16s/it, lr=1e-5, step_loss=0.105]Steps:  91%|█████████▏| 365/400 [33:41<03:00,  5.16s/it, lr=1e-5, step_loss=0.0713]Steps:  92%|█████████▏| 366/400 [33:44<02:39,  4.68s/it, lr=1e-5, step_loss=0.0Steps:  91%|█████████▏| 365/400 [33:42<03:00,  5.15s/it, lr=1e-5, step_loss=0.0591]Steps:  91%|█████████▏| 365/400 [33:42<03:00,  5.15s/it, lr=1e-5, step_loss=0.0559]Steps:  92%|█████████▏| 366/400 [33:45<02:39,  4.68s/it, lr=1e-5, step_loss=0.0559]Steps:  92%|█████████▏| 366/400 [33:45<02:39,  4.68s/it, lr=1e-5, step_loss=0.126] Steps:  92%|█████████▏| 367/400 [33:51<02:48,  5.11s/it, lr=1e-5, step_loss=0.126]Steps:  92%|█████████▏| 367/400 [33:51<02:48,  5.11s/it, lr=1e-5, step_loss=0.0719]Steps:  92%|█████████▏| 368/400 [33:56<02:39,  4.98s/it, lr=1e-5, step_loss=0.0719]Steps:  92%|█████████▏| 368/400 [33:56<02:39,  4.98s/it, lr=1e-5, step_loss=0.048] Steps:  92%|█████████▏| 369/400 [34:01<02:33,  4.94s/it, lr=1e-5, step_loss=0.048]Steps:  92%|█████████▏| 369/400 [34:01<02:33,  4.94s/it, lr=1e-5, ste713]Steps:  92%|█████████▏| 366/400 [33:44<02:39,  4.68s/it, lr=1e-5, step_loss=0.136] Steps:  92%|█████████▏| 367/400 [33:51<02:48,  5.11s/it, lr=1e-5, step_loss=0.136]Steps:  92%|█████████▏| 367/400 [33:51<02:48,  5.11s/it, lr=1e-5, step_loss=0.0708]Steps:  92%|█████████▏| 368/400 [33:55<02:39,  4.98s/it, lr=1e-5, step_loss=0.0708]Steps:  92%|█████████▏| 368/400 [33:55<02:39,  4.98s/it, lr=1e-5, step_loss=0.051] Steps:  92%|█████████▏| 369/400 [34:00<02:33,  4.94s/it, lr=1e-5, step_loss=0.051]Steps:  92%|█████████▏| 369/400 [34:00<02:33,  4.94s/it, lr=1e-5, step_loss=0.0678]Steps:  92%|█████████▎| 370/400 [34:07<02:41,  5.40s/it, lr=1e-5, step_loss=0.0678]Steps:  92%|█████████▎| 370/400 [34:07<02:41,  5.40s/it, lr=1e-5, step_loss=0.0767]Steps:  93%|█████████▎| 371/400 [34:11<02:30,  5.18s/it, lr=1e-5,p_loss=0.064]Steps:  92%|█████████▎| 370/400 [34:07<02:41,  5.40s/it, lr=1e-5, step_loss=0.064]Steps:  92%|█████████▎| 370/400 [34:07<02:41,  5.40s/it, lr=1e-5, step_loss=0.096]Steps:  93%|█████████▎| 371/400 [34:12<02:30,  5.18s/it, lr=1e-5, step_loss=0.096]Steps:  93%|█████████▎| 371/400 [34:12<02:30,  5.18s/it, lr=1e-5, step_loss=0.0478]Steps:  93%|█████████▎| 372/400 [34:17<02:22,  5.09s/it, lr=1e-5, step_loss=0.0478]Steps:  93%|█████████▎| 372/400 [34:17<02:22,  5.09s/it, lr=1e-5, step_loss=0.105] Steps:  93%|█████████▎| 373/400 [34:23<02:26,  5.41s/it, lr=1e-5, step_loss=0.105]Steps:  93%|█████████▎| 373/400 [34:23<02:26,  5.41s/it, lr=1e-5, step_loss=0.0824]Steps:  94%|█████████▎| 374/400 [34:26<02:05,  4.82s/it, lr=1e-5, step_loss=0.0824]Steps:  94%|█████████▎| 374/400 [34:26<02:05,  4.82s/it, l step_loss=0.0767]Steps:  93%|█████████▎| 371/400 [34:11<02:30,  5.18s/it, lr=1e-5, step_loss=0.0526]Steps:  93%|█████████▎| 372/400 [34:16<02:22,  5.09s/it, lr=1e-5, step_loss=0.0526]Steps:  93%|█████████▎| 372/400 [34:16<02:22,  5.09s/it, lr=1e-5, step_loss=0.0917]Steps:  93%|█████████▎| 373/400 [34:22<02:26,  5.41s/it, lr=1e-5, step_loss=0.0917]Steps:  93%|█████████▎| 373/400 [34:22<02:26,  5.41s/it, lr=1e-5, step_loss=0.0687]Steps:  94%|█████████▎| 374/400 [34:26<02:05,  4.82s/it, lr=1e-5, step_loss=0.0687]Steps:  94%|█████████▎| 374/400 [34:26<02:05,  4.82s/it, lr=1e-5, step_loss=0.157] Steps:  94%|█████████▍| 375/400 [34:31<02:00,  4.83s/it, lr=1e-5, step_loss=0.157]Steps:  94%|█████████▍| 375/400 [34:31<02:00,  4.83s/it, lr=1e-5, step_loss=0.0806]Steps:  94%|█████████▍| 376/400 [34:37<02:04,  5.1r=1e-5, step_loss=0.145] Steps:  94%|█████████▍| 375/400 [34:31<02:00,  4.83s/it, lr=1e-5, step_loss=0.145]Steps:  94%|█████████▍| 375/400 [34:31<02:00,  4.83s/it, lr=1e-5, step_loss=0.119]Steps:  94%|█████████▍| 376/400 [34:37<02:04,  5.18s/it, lr=1e-5, step_loss=0.119]Steps:  94%|█████████▍| 376/400 [34:37<02:04,  5.18s/it, lr=1e-5, step_loss=0.0666]Steps:  94%|█████████▍| 377/400 [34:42<01:55,  5.03s/it, lr=1e-5, step_loss=0.0666]Steps:  94%|█████████▍| 377/400 [34:42<01:55,  5.03s/it, lr=1e-5, step_loss=0.0887]Steps:  94%|█████████▍| 378/400 [34:47<01:49,  4.99s/it, lr=1e-5, step_loss=0.0887]Steps:  94%|█████████▍| 378/400 [34:47<01:49,  4.99s/it, lr=1e-5, step_loss=0.0425]Steps:  95%|█████████▍| 379/400 [35:19<04:33, 13.00s/it, lr=1e-5, step_loss=0.0425]Steps:  95%|█████████▍| 379/400 [35:19<04:33,8s/it, lr=1e-5, step_loss=0.0806]Steps:  94%|█████████▍| 376/400 [34:37<02:04,  5.18s/it, lr=1e-5, step_loss=0.0441]Steps:  94%|█████████▍| 377/400 [34:41<01:55,  5.03s/it, lr=1e-5, step_loss=0.0441]Steps:  94%|█████████▍| 377/400 [34:41<01:55,  5.03s/it, lr=1e-5, step_loss=0.0831]Steps:  94%|█████████▍| 378/400 [34:46<01:49,  4.99s/it, lr=1e-5, step_loss=0.0831]Steps:  94%|█████████▍| 378/400 [34:46<01:49,  4.99s/it, lr=1e-5, step_loss=0.0669]Steps:  95%|█████████▍| 379/400 [35:18<04:33, 13.00s/it, lr=1e-5, step_loss=0.0669]Steps:  95%|█████████▍| 379/400 [35:18<04:33, 13.00s/it, lr=1e-5, step_loss=0.0719]Steps:  95%|█████████▌| 380/400 [35:23<03:30, 10.53s/it, lr=1e-5, step_loss=0.0719]Steps:  95%|█████████▌| 380/400 [35:23<03:30, 10.53s/it, lr=1e-5, step_loss=0.0615]Steps:  95%|█████████▌| 381/400 [3 13.00s/it, lr=1e-5, step_loss=0.0695]Steps:  95%|█████████▌| 380/400 [35:23<03:30, 10.53s/it, lr=1e-5, step_loss=0.0695]Steps:  95%|█████████▌| 380/400 [35:23<03:30, 10.53s/it, lr=1e-5, step_loss=0.0747]Steps:  95%|█████████▌| 381/400 [35:28<02:47,  8.82s/it, lr=1e-5, step_loss=0.0747]Steps:  95%|█████████▌| 381/400 [35:28<02:47,  8.82s/it, lr=1e-5, step_loss=0.0592]Steps:  96%|█████████▌| 382/400 [35:34<02:24,  8.01s/it, lr=1e-5, step_loss=0.0592]Steps:  96%|█████████▌| 382/400 [35:34<02:24,  8.01s/it, lr=1e-5, step_loss=0.0909]Steps:  96%|█████████▌| 383/400 [35:39<01:59,  7.01s/it, lr=1e-5, step_loss=0.0909]Steps:  96%|█████████▌| 383/400 [35:39<01:59,  7.01s/it, lr=1e-5, step_loss=0.0979]Steps:  96%|█████████▌| 384/400 [35:44<01:41,  6.36s/it, lr=1e-5, step_loss=0.0979]Steps:  96%|█████████▌| 384/45:27<02:47,  8.82s/it, lr=1e-5, step_loss=0.0615]Steps:  95%|█████████▌| 381/400 [35:27<02:47,  8.82s/it, lr=1e-5, step_loss=0.0508]Steps:  96%|█████████▌| 382/400 [35:34<02:24,  8.01s/it, lr=1e-5, step_loss=0.0508]Steps:  96%|█████████▌| 382/400 [35:34<02:24,  8.01s/it, lr=1e-5, step_loss=0.104] Steps:  96%|█████████▌| 383/400 [35:38<01:59,  7.01s/it, lr=1e-5, step_loss=0.104]Steps:  96%|█████████▌| 383/400 [35:38<01:59,  7.01s/it, lr=1e-5, step_loss=0.0767]Steps:  96%|█████████▌| 384/400 [35:43<01:41,  6.36s/it, lr=1e-5, step_loss=0.0767]Steps:  96%|█████████▌| 384/400 [35:43<01:41,  6.36s/it, lr=1e-5, step_loss=0.0831]Steps:  96%|█████████▋| 385/400 [35:49<01:34,  6.29s/it, lr=1e-5, step_loss=0.0831]Steps:  96%|█████████▋| 385/400 [35:49<01:34,  6.29s/it, lr=1e-5, step_loss=0.0607]Steps:  96%|█████████00 [35:44<01:41,  6.36s/it, lr=1e-5, step_loss=0.0362]Steps:  96%|█████████▋| 385/400 [35:50<01:34,  6.29s/it, lr=1e-5, step_loss=0.0362]Steps:  96%|█████████▋| 385/400 [35:50<01:34,  6.29s/it, lr=1e-5, step_loss=0.0401]Steps:  96%|█████████▋| 386/400 [35:55<01:21,  5.81s/it, lr=1e-5, step_loss=0.0401]Steps:  96%|█████████▋| 386/400 [35:55<01:21,  5.81s/it, lr=1e-5, step_loss=0.0886]Steps:  97%|█████████▋| 387/400 [35:59<01:11,  5.52s/it, lr=1e-5, step_loss=0.0886]Steps:  97%|█████████▋| 387/400 [35:59<01:11,  5.52s/it, lr=1e-5, step_loss=0.154] Steps:  97%|█████████▋| 388/400 [36:05<01:07,  5.63s/it, lr=1e-5, step_loss=0.154]Steps:  97%|█████████▋| 388/400 [36:05<01:07,  5.63s/it, lr=1e-5, step_loss=0.0658]Steps:  97%|█████████▋| 389/400 [36:10<00:58,  5.35s/it, lr=1e-5, step_loss=0.0658]Steps:  97%|███████▋| 386/400 [35:54<01:21,  5.81s/it, lr=1e-5, step_loss=0.0607]Steps:  96%|█████████▋| 386/400 [35:54<01:21,  5.81s/it, lr=1e-5, step_loss=0.0636]Steps:  97%|█████████▋| 387/400 [35:59<01:11,  5.52s/it, lr=1e-5, step_loss=0.0636]Steps:  97%|█████████▋| 387/400 [35:59<01:11,  5.52s/it, lr=1e-5, step_loss=0.124] Steps:  97%|█████████▋| 388/400 [36:05<01:07,  5.63s/it, lr=1e-5, step_loss=0.124]Steps:  97%|█████████▋| 388/400 [36:05<01:07,  5.63s/it, lr=1e-5, step_loss=0.0733]Steps:  97%|█████████▋| 389/400 [36:09<00:58,  5.35s/it, lr=1e-5, step_loss=0.0733]Steps:  97%|█████████▋| 389/400 [36:09<00:58,  5.35s/it, lr=1e-5, step_loss=0.0454]Steps:  98%|█████████▊| 390/400 [36:14<00:52,  5.21s/it, lr=1e-5, step_loss=0.0454]Steps:  98%|█████████▊| 390/400 [36:14<00:52,  5.21s/it, lr=1e-5, step_loss=0.105] Steps:  98%|█████▋| 389/400 [36:10<00:58,  5.35s/it, lr=1e-5, step_loss=0.0717]Steps:  98%|█████████▊| 390/400 [36:15<00:52,  5.21s/it, lr=1e-5, step_loss=0.0717]Steps:  98%|█████████▊| 390/400 [36:15<00:52,  5.21s/it, lr=1e-5, step_loss=0.126] Steps:  98%|█████████▊| 391/400 [36:21<00:49,  5.47s/it, lr=1e-5, step_loss=0.126]Steps:  98%|█████████▊| 391/400 [36:21<00:49,  5.47s/it, lr=1e-5, step_loss=0.0474]Steps:  98%|█████████▊| 392/400 [36:26<00:41,  5.23s/it, lr=1e-5, step_loss=0.0474]Steps:  98%|█████████▊| 392/400 [36:26<00:41,  5.23s/it, lr=1e-5, step_loss=0.0637]Steps:  98%|█████████▊| 393/400 [36:31<00:35,  5.12s/it, lr=1e-5, step_loss=0.0637]Steps:  98%|█████████▊| 393/400 [36:31<00:35,  5.12s/it, lr=1e-5, step_loss=0.11]  Steps:  98%|█████████▊| 394/400 [36:37<00:32,  5.39s/it, lr=1e-5, step_loss=0.11]Steps:  98%|████████▊| 391/400 [36:20<00:49,  5.47s/it, lr=1e-5, step_loss=0.105]Steps:  98%|█████████▊| 391/400 [36:20<00:49,  5.47s/it, lr=1e-5, step_loss=0.0593]Steps:  98%|█████████▊| 392/400 [36:25<00:41,  5.23s/it, lr=1e-5, step_loss=0.0593]Steps:  98%|█████████▊| 392/400 [36:25<00:41,  5.23s/it, lr=1e-5, step_loss=0.0719]Steps:  98%|█████████▊| 393/400 [36:30<00:35,  5.12s/it, lr=1e-5, step_loss=0.0719]Steps:  98%|█████████▊| 393/400 [36:30<00:35,  5.12s/it, lr=1e-5, step_loss=0.0718]Steps:  98%|█████████▊| 394/400 [36:36<00:32,  5.39s/it, lr=1e-5, step_loss=0.0718]Steps:  98%|█████████▊| 394/400 [36:36<00:32,  5.39s/it, lr=1e-5, step_loss=0.0721]Steps:  99%|█████████▉| 395/400 [36:41<00:25,  5.18s/it, lr=1e-5, step_loss=0.0721]Steps:  99%|█████████▉| 395/400 [36:41<00:25,  5.18s/it, lr=1e-5, step_loss=0.122] Steps:  9██████▊| 394/400 [36:37<00:32,  5.39s/it, lr=1e-5, step_loss=0.044]Steps:  99%|█████████▉| 395/400 [36:41<00:25,  5.18s/it, lr=1e-5, step_loss=0.044]Steps:  99%|█████████▉| 395/400 [36:41<00:25,  5.18s/it, lr=1e-5, step_loss=0.0988]Steps:  99%|█████████▉| 396/400 [36:46<00:20,  5.08s/it, lr=1e-5, step_loss=0.0988]Steps:  99%|█████████▉| 396/400 [36:46<00:20,  5.08s/it, lr=1e-5, step_loss=0.0682]Steps:  99%|█████████▉| 397/400 [36:52<00:16,  5.34s/it, lr=1e-5, step_loss=0.0682]Steps:  99%|█████████▉| 397/400 [36:52<00:16,  5.34s/it, lr=1e-5, step_loss=0.0606]Steps: 100%|█████████▉| 398/400 [36:57<00:10,  5.15s/it, lr=1e-5, step_loss=0.0606]Steps: 100%|█████████▉| 398/400 [36:57<00:10,  5.15s/it, lr=1e-5, step_loss=0.0464]Steps: 100%|█████████▉| 399/400 [37:02<00:05,  5.06s/it, lr=1e-5, step_loss=0.0464]Steps: 9%|█████████▉| 396/400 [36:45<00:20,  5.08s/it, lr=1e-5, step_loss=0.122]Steps:  99%|█████████▉| 396/400 [36:45<00:20,  5.08s/it, lr=1e-5, step_loss=0.071]Steps:  99%|█████████▉| 397/400 [36:51<00:16,  5.34s/it, lr=1e-5, step_loss=0.071]Steps:  99%|█████████▉| 397/400 [36:51<00:16,  5.34s/it, lr=1e-5, step_loss=0.0902]Steps: 100%|█████████▉| 398/400 [36:56<00:10,  5.15s/it, lr=1e-5, step_loss=0.0902]Steps: 100%|█████████▉| 398/400 [36:56<00:10,  5.15s/it, lr=1e-5, step_loss=0.0559]Steps: 100%|█████████▉| 399/400 [37:01<00:05,  5.06s/it, lr=1e-5, step_loss=0.0559]Steps: 100%|█████████▉| 399/400 [37:01<00:05,  5.06s/it, lr=1e-5, step_loss=0.0745]Steps: 100%|██████████| 400/400 [37:07<00:00,  5.36s/it, lr=1e-5, step_loss=0.0745]Steps: 100%|██████████| 400/400 [37:07<00:00,  5.36s/it, lr=1e-5, step_loss=0.05100%|█████████▉| 399/400 [37:02<00:05,  5.06s/it, lr=1e-5, step_loss=0.0957]Steps: 100%|██████████| 400/400 [37:08<00:00,  5.36s/it, lr=1e-5, step_loss=0.0957]Steps: 100%|██████████| 400/400 [37:08<00:00,  5.36s/it, lr=1e-5, step_loss=0.1]   Steps: 100%|██████████| 400/400 [37:08<00:00,  5.57s/it, lr=1e-5, step_loss=0.1]
94]Steps: 100%|██████████| 400/400 [37:07<00:00,  5.57s/it, lr=1e-5, step_loss=0.0594]
